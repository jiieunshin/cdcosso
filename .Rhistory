# measure[f, k] <- rss / (1 - d * S/te_n + .1)^2 / te_n
if(obj$family == "binomial") measure[f, k] <- mean(ifelse(testmu < 0.5, 0, 1) != y[testID])
# if(obj$family == "gaussian") measure[f, k] <- mean((testmu - y[testID])^2)
# if(obj$family == "poisson") measure[f, k] <- mean(KLD(testfhat, y[testID]))
}
}
measure[is.nan(measure)] <- NA
cvm <- apply(measure, 2, mean, na.rm = T)
cvsd <- apply(measure, 2, sd, na.rm = T) / sqrt(nrow(measure)) + 1e-22
cvm[is.nan(cvm)] <- NA
cvsd[is.na(cvsd)] <- 0
# selm = floor(apply(sel, 2, mean))
id = which.min(cvm)[1]
if(one.std){
st1_err = cvm[id] + cvsd[id] # minimum cv err
std.id = max(which(cvm[id:len] <= st1_err & cvm[id] <= cvm[id:len]))
if(is.na(std.id)){
std.id = id
optlambda = lambda_theta[std.id]
} else{
std.id = ifelse(std.id > id, std.id, id)
optlambda = lambda_theta[std.id]
}
} else{
optlambda = lambda_theta[id]
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
max_min <- c(min(cvm - cvsd, na.rm = TRUE), max(cvm + cvsd, na.rm = TRUE))
xrange = log(lambda_theta)
plot(xrange, cvm, main = main, xlab = expression("Log(" * lambda[theta] * ")"), ylab = "generalized cross validation", ylim = max_min, type = 'n')
arrows(xrange, cvm - cvsd, xrange, cvm + cvsd, angle = 90, code = 3, length = 0.1, col = 'gray')
points(xrange, cvm, pch = 15, col = 'red')
abline(v = xrange[id], col = 'darkgrey')
# text(log(lambda_theta), par("usr")[4], labels = selm, pos = 1)
if(one.std) abline(v = xrange[std.id], col = 'darkgrey')
if(algo == "CD"){
theta.new = nng.cd(Gw, uw, theta = init.theta, optlambda, gamma)
# theta.new = .Call("Cnng", Gw, uw, n, d, init.theta, optlambda, gamma)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
if(algo == "QP"){
theta.new = nng.QP(model$zw.new, model$b.new, model$cw.new, model$w.new, G,
init.theta, lambda0, optlambda, gamma, obj)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
return(out)
}
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit1, x, y, wt, sspline_cvfit1$optlambda, lambda_theta, gamma, nfolds, obj, one.std, algo)
cv.nng = function(model, x, y, mscale, lambda0, lambda_theta, gamma, nfolds, obj, one.std, algo)
{
n = length(y)
d = length(mscale)
IDmat = model$IDmat
# solve theta
G <- matrix(0, nrow(model$R[, ,1]), d)
for (j in 1:d) {
G[, j] = model$R[, , j] %*% model$c.new * (mscale[j]^(-2))
}
Gw = G * sqrt(model$w.new)
uw = model$zw.new - model$b.new * sqrt(model$w.new) - (n/2) * lambda0 * model$cw.new
init.theta = as.vector(glmnet(Gw, uw, family = "gaussian", lambda = lambda_theta[1])$beta)
# init.theta = rep(1, d)
len = length(lambda_theta)
measure <- matrix(0, ncol = len, nrow = nfolds)
l = 0
for (f in 1:nfolds) {
testID <- IDmat[!is.na(IDmat[, f]), f]
trainID <- (1:n)[-testID]
tr_G = G[trainID,]
te_G = G[testID,]
tr_n = length(trainID)
te_n = length(testID)
for (k in 1:len) {
l = l + 1
if(algo == "CD") {
# theta.new = nng.cd(Gw[trainID,], uw[trainID], theta = init.theta, lambda_theta[k], gamma)
theta.new = .Call("Cnng", Gw[trainID,], uw[trainID], tr_n, d, init.theta, lambda_theta[k], gamma)
}
if(algo == "QP") {
theta.new = nng.QP(model$zw.new[trainID], model$b.new, model$cw.new[trainID], model$w.new[trainID], tr_G,
theta = init.theta, lambda0, lambda_theta[k], gamma)
}
testfhat = c(te_G %*% theta.new)
testmu = obj$linkinv(testfhat)
# testw = obj$variance(testmu)
# testz = testfhat + (y[testID] - testmu) / testw
# testzw = testz * sqrt(testw)
# testGw = te_G * sqrt(testw)
# testuw = testzw - model$b.new * sqrt(testw) - (te_n/2) * lambda0 * model$cw.new[testID]
# rss <- t(testuw - testGw %*% theta.new) %*% (testuw - testGw %*% theta.new) + .1
# l1 = gamma * sum(abs(theta.new)) + (1-gamma) * norm(theta.new, "2")
# l2 = gamma * sum(abs(ginv(theta.new))) + (1-gamma) * norm(ginv(theta.new), "2")
# S = l1 + l2
# measure[f, k] <- rss / (1 - d * S/te_n + .1)^2 / te_n
if(obj$family == "binomial") measure[f, k] <- mean(ifelse(testmu < 0.5, 0, 1) != y[testID])
# if(obj$family == "gaussian") measure[f, k] <- mean((testmu - y[testID])^2)
# if(obj$family == "poisson") measure[f, k] <- mean(KLD(testfhat, y[testID]))
}
}
measure[is.nan(measure)] <- NA
cvm <- apply(measure, 2, mean, na.rm = T)
cvsd <- apply(measure, 2, sd, na.rm = T) / sqrt(nrow(measure)) + 1e-22
cvm[is.nan(cvm)] <- NA
cvsd[is.na(cvsd)] <- 0
# selm = floor(apply(sel, 2, mean))
id = which.min(cvm)[1]
if(one.std){
st1_err = cvm[id] + cvsd[id] # minimum cv err
std.id = max(which(cvm[id:len] <= st1_err & cvm[id] <= cvm[id:len]))
if(is.na(std.id)){
std.id = id
optlambda = lambda_theta[std.id]
} else{
std.id = ifelse(std.id > id, std.id, id)
optlambda = lambda_theta[std.id]
}
} else{
optlambda = lambda_theta[id]
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
max_min <- c(min(cvm - cvsd, na.rm = TRUE), max(cvm + cvsd, na.rm = TRUE))
xrange = log(lambda_theta)
plot(xrange, cvm, main = main, xlab = expression("Log(" * lambda[theta] * ")"), ylab = "generalized cross validation", ylim = max_min, type = 'n')
arrows(xrange, cvm - cvsd, xrange, cvm + cvsd, angle = 90, code = 3, length = 0.1, col = 'gray')
points(xrange, cvm, pch = 15, col = 'red')
abline(v = xrange[id], col = 'darkgrey')
# text(log(lambda_theta), par("usr")[4], labels = selm, pos = 1)
if(one.std) abline(v = xrange[std.id], col = 'darkgrey')
if(algo == "CD"){
# theta.new = nng.cd(Gw, uw, theta = init.theta, optlambda, gamma)
theta.new = .Call("Cnng", Gw, uw, n, d, init.theta, optlambda, gamma)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
if(algo == "QP"){
theta.new = nng.QP(model$zw.new, model$b.new, model$cw.new, model$w.new, G,
init.theta, lambda0, optlambda, gamma, obj)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
return(out)
}
nng.cd = function (Gw, uw, theta, lambda_theta, gamma)
{
n = nrow(Gw)
d = ncol(Gw)
r = lambda_theta * gamma * n
theta.new = rep(0, d)
for(i in 1:20){
for(j in 1:d){
print(2 * sum((uw - Gw[,-j] %*% theta[-j]) * Gw[,j]))
theta.new[j] = 2 * sum((uw - Gw[,-j] %*% theta[-j]) * Gw[,j])
theta.new[j] = ifelse(theta.new[j] > 0 & r < abs(theta.new[j]), theta.new[j], 0)
theta.new[j] = theta.new[j] / (sum(Gw[,j]^2) + n * lambda_theta * (1-gamma)) / 2
loss = abs(theta[j] - theta.new[j])
conv = max(loss) < 1e-20
if(i != 1 & conv) break
theta = theta.new
}
}
if(i == 1 & !conv){
theta = rep(0, d)
}
# else if(sum(theta.new = 0) == d){
#   theta = theta.new / sd(theta.new)
# }
# print(theta)
# if(sum(theta == 0) != d) theta = theta / sd(theta)
return(theta)
}
cv.nng = function(model, x, y, mscale, lambda0, lambda_theta, gamma, nfolds, obj, one.std, algo)
{
n = length(y)
d = length(mscale)
IDmat = model$IDmat
# solve theta
G <- matrix(0, nrow(model$R[, ,1]), d)
for (j in 1:d) {
G[, j] = model$R[, , j] %*% model$c.new * (mscale[j]^(-2))
}
Gw = G * sqrt(model$w.new)
uw = model$zw.new - model$b.new * sqrt(model$w.new) - (n/2) * lambda0 * model$cw.new
init.theta = as.vector(glmnet(Gw, uw, family = "gaussian", lambda = lambda_theta[1])$beta)
# init.theta = rep(1, d)
len = length(lambda_theta)
measure <- matrix(0, ncol = len, nrow = nfolds)
l = 0
for (f in 1:nfolds) {
testID <- IDmat[!is.na(IDmat[, f]), f]
trainID <- (1:n)[-testID]
tr_G = G[trainID,]
te_G = G[testID,]
tr_n = length(trainID)
te_n = length(testID)
for (k in 1:len) {
l = l + 1
if(algo == "CD") {
theta.new = nng.cd(Gw[trainID,], uw[trainID], theta = init.theta, lambda_theta[k], gamma)
# theta.new = .Call("Cnng", Gw[trainID,], uw[trainID], tr_n, d, init.theta, lambda_theta[k], gamma)
}
if(algo == "QP") {
theta.new = nng.QP(model$zw.new[trainID], model$b.new, model$cw.new[trainID], model$w.new[trainID], tr_G,
theta = init.theta, lambda0, lambda_theta[k], gamma)
}
testfhat = c(te_G %*% theta.new)
testmu = obj$linkinv(testfhat)
# testw = obj$variance(testmu)
# testz = testfhat + (y[testID] - testmu) / testw
# testzw = testz * sqrt(testw)
# testGw = te_G * sqrt(testw)
# testuw = testzw - model$b.new * sqrt(testw) - (te_n/2) * lambda0 * model$cw.new[testID]
# rss <- t(testuw - testGw %*% theta.new) %*% (testuw - testGw %*% theta.new) + .1
# l1 = gamma * sum(abs(theta.new)) + (1-gamma) * norm(theta.new, "2")
# l2 = gamma * sum(abs(ginv(theta.new))) + (1-gamma) * norm(ginv(theta.new), "2")
# S = l1 + l2
# measure[f, k] <- rss / (1 - d * S/te_n + .1)^2 / te_n
if(obj$family == "binomial") measure[f, k] <- mean(ifelse(testmu < 0.5, 0, 1) != y[testID])
# if(obj$family == "gaussian") measure[f, k] <- mean((testmu - y[testID])^2)
# if(obj$family == "poisson") measure[f, k] <- mean(KLD(testfhat, y[testID]))
}
}
measure[is.nan(measure)] <- NA
cvm <- apply(measure, 2, mean, na.rm = T)
cvsd <- apply(measure, 2, sd, na.rm = T) / sqrt(nrow(measure)) + 1e-22
cvm[is.nan(cvm)] <- NA
cvsd[is.na(cvsd)] <- 0
# selm = floor(apply(sel, 2, mean))
id = which.min(cvm)[1]
if(one.std){
st1_err = cvm[id] + cvsd[id] # minimum cv err
std.id = max(which(cvm[id:len] <= st1_err & cvm[id] <= cvm[id:len]))
if(is.na(std.id)){
std.id = id
optlambda = lambda_theta[std.id]
} else{
std.id = ifelse(std.id > id, std.id, id)
optlambda = lambda_theta[std.id]
}
} else{
optlambda = lambda_theta[id]
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
max_min <- c(min(cvm - cvsd, na.rm = TRUE), max(cvm + cvsd, na.rm = TRUE))
xrange = log(lambda_theta)
plot(xrange, cvm, main = main, xlab = expression("Log(" * lambda[theta] * ")"), ylab = "generalized cross validation", ylim = max_min, type = 'n')
arrows(xrange, cvm - cvsd, xrange, cvm + cvsd, angle = 90, code = 3, length = 0.1, col = 'gray')
points(xrange, cvm, pch = 15, col = 'red')
abline(v = xrange[id], col = 'darkgrey')
# text(log(lambda_theta), par("usr")[4], labels = selm, pos = 1)
if(one.std) abline(v = xrange[std.id], col = 'darkgrey')
if(algo == "CD"){
theta.new = nng.cd(Gw, uw, theta = init.theta, optlambda, gamma)
# theta.new = .Call("Cnng", Gw, uw, n, d, init.theta, optlambda, gamma)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
if(algo == "QP"){
theta.new = nng.QP(model$zw.new, model$b.new, model$cw.new, model$w.new, G,
init.theta, lambda0, optlambda, gamma, obj)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
return(out)
}
nng.cd = function (Gw, uw, theta, lambda_theta, gamma)
{
n = nrow(Gw)
d = ncol(Gw)
r = lambda_theta * gamma * n
theta.new = rep(0, d)
for(i in 1:20){
for(j in 1:d){
print(2 * sum((uw - Gw[,-j] %*% theta[-j]) * Gw[,j]))
theta.new[j] = 2 * sum((uw - Gw[,-j] %*% theta[-j]) * Gw[,j])
theta.new[j] = ifelse(theta.new[j] > 0 & r < abs(theta.new[j]), theta.new[j], 0)
theta.new[j] = theta.new[j] / (sum(Gw[,j]^2) + n * lambda_theta * (1-gamma)) / 2
loss = abs(theta[j] - theta.new[j])
conv = max(loss) < 1e-20
if(i != 1 & conv) break
theta = theta.new
}
}
if(i == 1 & !conv){
theta = rep(0, d)
}
# else if(sum(theta.new = 0) == d){
#   theta = theta.new / sd(theta.new)
# }
# print(theta)
# if(sum(theta == 0) != d) theta = theta / sd(theta)
return(theta)
}
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit1, x, y, wt, sspline_cvfit1$optlambda, lambda_theta, gamma, nfolds, obj, one.std, algo)
nng.cd = function (Gw, uw, theta, lambda_theta, gamma)
{
n = nrow(Gw)
d = ncol(Gw)
r = lambda_theta * gamma * n
theta.new = rep(0, d)
for(i in 1:20){
print("시작")
for(j in 1:d){
print(2 * sum((uw - Gw[,-j] %*% theta[-j]) * Gw[,j]))
theta.new[j] = 2 * sum((uw - Gw[,-j] %*% theta[-j]) * Gw[,j])
theta.new[j] = ifelse(theta.new[j] > 0 & r < abs(theta.new[j]), theta.new[j], 0)
theta.new[j] = theta.new[j] / (sum(Gw[,j]^2) + n * lambda_theta * (1-gamma)) / 2
loss = abs(theta[j] - theta.new[j])
conv = max(loss) < 1e-20
if(i != 1 & conv) break
theta = theta.new
}
}
if(i == 1 & !conv){
theta = rep(0, d)
}
# else if(sum(theta.new = 0) == d){
#   theta = theta.new / sd(theta.new)
# }
# print(theta)
# if(sum(theta == 0) != d) theta = theta / sd(theta)
return(theta)
}
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit1, x, y, wt, sspline_cvfit1$optlambda, lambda_theta, gamma, nfolds, obj, one.std, algo)
nng.cd = function (Gw, uw, theta, lambda_theta, gamma)
{
n = nrow(Gw)
d = ncol(Gw)
r = lambda_theta * gamma * n
theta.new = rep(0, d)
for(i in 1:20){
for(j in 1:d){
theta.new[j] = 2 * sum((uw - Gw[,-j] %*% theta[-j]) * Gw[,j])
theta.new[j] = ifelse(theta.new[j] > 0 & r < abs(theta.new[j]), theta.new[j], 0)
theta.new[j] = theta.new[j] / (sum(Gw[,j]^2) + n * lambda_theta * (1-gamma)) / 2
loss = abs(theta[j] - theta.new[j])
conv = max(loss) < 1e-20
if(i != 1 & conv) break
theta = theta.new
}
}
if(i == 1 & !conv){
theta = rep(0, d)
}
# else if(sum(theta.new = 0) == d){
#   theta = theta.new / sd(theta.new)
# }
# print(theta)
# if(sum(theta == 0) != d) theta = theta / sd(theta)
return(theta)
}
cv.nng = function(model, x, y, mscale, lambda0, lambda_theta, gamma, nfolds, obj, one.std, algo)
{
n = length(y)
d = length(mscale)
IDmat = model$IDmat
# solve theta
G <- matrix(0, nrow(model$R[, ,1]), d)
for (j in 1:d) {
G[, j] = model$R[, , j] %*% model$c.new * (mscale[j]^(-2))
}
Gw = G * sqrt(model$w.new)
uw = model$zw.new - model$b.new * sqrt(model$w.new) - (n/2) * lambda0 * model$cw.new
init.theta = as.vector(glmnet(Gw, uw, family = "gaussian", lambda = lambda_theta[1])$beta)
# init.theta = rep(1, d)
len = length(lambda_theta)
measure <- matrix(0, ncol = len, nrow = nfolds)
l = 0
for (f in 1:nfolds) {
testID <- IDmat[!is.na(IDmat[, f]), f]
trainID <- (1:n)[-testID]
tr_G = G[trainID,]
te_G = G[testID,]
tr_n = length(trainID)
te_n = length(testID)
for (k in 1:len) {
l = l + 1
if(algo == "CD") {
# theta.new = nng.cd(Gw[trainID,], uw[trainID], theta = init.theta, lambda_theta[k], gamma)
theta.new = .Call("Cnng", Gw[trainID,], uw[trainID], tr_n, d, init.theta, lambda_theta[k], gamma)
}
if(algo == "QP") {
theta.new = nng.QP(model$zw.new[trainID], model$b.new, model$cw.new[trainID], model$w.new[trainID], tr_G,
theta = init.theta, lambda0, lambda_theta[k], gamma)
}
testfhat = c(te_G %*% theta.new)
testmu = obj$linkinv(testfhat)
# testw = obj$variance(testmu)
# testz = testfhat + (y[testID] - testmu) / testw
# testzw = testz * sqrt(testw)
# testGw = te_G * sqrt(testw)
# testuw = testzw - model$b.new * sqrt(testw) - (te_n/2) * lambda0 * model$cw.new[testID]
# rss <- t(testuw - testGw %*% theta.new) %*% (testuw - testGw %*% theta.new) + .1
# l1 = gamma * sum(abs(theta.new)) + (1-gamma) * norm(theta.new, "2")
# l2 = gamma * sum(abs(ginv(theta.new))) + (1-gamma) * norm(ginv(theta.new), "2")
# S = l1 + l2
# measure[f, k] <- rss / (1 - d * S/te_n + .1)^2 / te_n
if(obj$family == "binomial") measure[f, k] <- mean(ifelse(testmu < 0.5, 0, 1) != y[testID])
# if(obj$family == "gaussian") measure[f, k] <- mean((testmu - y[testID])^2)
# if(obj$family == "poisson") measure[f, k] <- mean(KLD(testfhat, y[testID]))
}
}
measure[is.nan(measure)] <- NA
cvm <- apply(measure, 2, mean, na.rm = T)
cvsd <- apply(measure, 2, sd, na.rm = T) / sqrt(nrow(measure)) + 1e-22
cvm[is.nan(cvm)] <- NA
cvsd[is.na(cvsd)] <- 0
# selm = floor(apply(sel, 2, mean))
id = which.min(cvm)[1]
if(one.std){
st1_err = cvm[id] + cvsd[id] # minimum cv err
std.id = max(which(cvm[id:len] <= st1_err & cvm[id] <= cvm[id:len]))
if(is.na(std.id)){
std.id = id
optlambda = lambda_theta[std.id]
} else{
std.id = ifelse(std.id > id, std.id, id)
optlambda = lambda_theta[std.id]
}
} else{
optlambda = lambda_theta[id]
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
max_min <- c(min(cvm - cvsd, na.rm = TRUE), max(cvm + cvsd, na.rm = TRUE))
xrange = log(lambda_theta)
plot(xrange, cvm, main = main, xlab = expression("Log(" * lambda[theta] * ")"), ylab = "generalized cross validation", ylim = max_min, type = 'n')
arrows(xrange, cvm - cvsd, xrange, cvm + cvsd, angle = 90, code = 3, length = 0.1, col = 'gray')
points(xrange, cvm, pch = 15, col = 'red')
abline(v = xrange[id], col = 'darkgrey')
# text(log(lambda_theta), par("usr")[4], labels = selm, pos = 1)
if(one.std) abline(v = xrange[std.id], col = 'darkgrey')
if(algo == "CD"){
# theta.new = nng.cd(Gw, uw, theta = init.theta, optlambda, gamma)
theta.new = .Call("Cnng", Gw, uw, n, d, init.theta, optlambda, gamma)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
if(algo == "QP"){
theta.new = nng.QP(model$zw.new, model$b.new, model$cw.new, model$w.new, G,
init.theta, lambda0, optlambda, gamma, obj)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
return(out)
}
nng.cd = function (Gw, uw, theta, lambda_theta, gamma)
{
n = nrow(Gw)
d = ncol(Gw)
r = lambda_theta * gamma * n
theta.new = rep(0, d)
for(i in 1:20){
for(j in 1:d){
theta.new[j] = 2 * sum((uw - Gw[,-j] %*% theta[-j]) * Gw[,j])
theta.new[j] = ifelse(theta.new[j] > 0 & r < abs(theta.new[j]), theta.new[j], 0)
theta.new[j] = theta.new[j] / (sum(Gw[,j]^2) + n * lambda_theta * (1-gamma)) / 2
loss = abs(theta[j] - theta.new[j])
conv = max(loss) < 1e-20
if(i != 1 & conv) break
theta = theta.new
}
}
if(i == 1 & !conv){
theta = rep(0, d)
}
# else if(sum(theta.new = 0) == d){
#   theta = theta.new / sd(theta.new)
# }
# print(theta)
# if(sum(theta == 0) != d) theta = theta / sd(theta)
return(theta)
}
