rm(Rtheta)
return(out)
}
# solve (theta) - 1st
sspline_cvfit1 = cv.sspline(x, y, rep(1, d)/wt^2, nfolds, lambda0, obj, one.std, type, kparam, algo) ## 초기값 설정. 수정할 함수
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit1, x, y, wt, sspline_cvfit1$optlambda, lambda_theta, gamma, nfolds, obj, one.std, algo)
nng_fit
theta.new = rescale_theta(nng_fit$theta.new, FALSE)
# solve (theta) - 2nd
sspline_cvfit2 = try({cv.sspline(x, y, theta.new/wt^2, nfolds, lambda0, obj, one.std, type, kparam, algo)}) ## 초기값 설정. 수정할 함수
nng_fit = cv.nng(sspline_cvfit2, x, y, wt, sspline_cvfit2$optlambda, lambda_theta, gamma, nfolds, obj, one.std, algo)
theta.new = rescale_theta(nng_fit$theta.new, FALSE)
sspline_cvfit3 = cv.sspline(x, y, theta.new/wt^2, nfolds, lambda0, obj, one.std, type, kparam, algo) ## 초기값 설정. 수정할 함수
sspline.cd = function (R, y, f, lambda0, obj, c.init)
{
# print(as.vector(glmnet(R, y, family = obj$family, lambda = lambda0, alpha = 0)$beta))
n = length(y)
# initialize
mu = obj$linkinv(f)
w = obj$variance(mu)
z = f + (y - mu) / w
b = 0
zw = z * sqrt(w)
Rw = R * w
cw = c.init / sqrt(w)
sw = sqrt(w)
cw.new = rep(0, n)
for(i in 1:20){ # outer iteration
for(j in 1:n){
L = 2 * sum((zw - Rw[,-j] %*% cw[-j] - b * sw) * Rw[,j]) - n * lambda0 * c(Rw[j,-j] %*% cw[-j])
R = 2 * sum(Rw[,j]^2) + n * lambda0 * Rw[j,j]
cw.new[j] = L/R
loss = abs(cw-cw.new)
conv = max(loss) < 1e-6
if(conv) break
cw = cw.new  # if not convergence
}
}
if(i == 1 & !conv) cw.new = cw
cw.new = cw.new
c.new = cw.new * sqrt(w)
b.new = sum((zw - Rw %*% cw.new) * sw) / sum(sw)
return(list(w.new = w, b.new = b.new, c.new = c.new, zw.new = z * w, sw.new = sqrt(w), cw.new = cw.new))
}
# solve (theta) - 1st
sspline_cvfit1 = cv.sspline(x, y, rep(1, d)/wt^2, nfolds, lambda0, obj, one.std, type, kparam, algo) ## 초기값 설정. 수정할 함수
cv.nng = function(model, x, y, mscale, lambda0, lambda_theta, gamma, nfolds, obj, one.std, algo)
{
n = length(y)
d = length(mscale)
IDmat = model$IDmat
# solve theta
G <- matrix(0, nrow(model$R[, ,1]), d)
for (j in 1:d) {
G[, j] = model$R[, , j] %*% model$c.new * (mscale[j]^(-2))
}
Gw = G * sqrt(model$w.new)
uw = model$zw.new - model$b.new * sqrt(model$w.new) - (n/2) * lambda0 * model$cw.new
init.theta = as.vector(glmnet(Gw, uw, family = "gaussian", lambda = lambda_theta[1])$beta)
# init.theta = rep(1, d)
len = length(lambda_theta)
measure <- matrix(0, ncol = len, nrow = nfolds)
l = 0
for (f in 1:nfolds) {
testID <- IDmat[!is.na(IDmat[, f]), f]
trainID <- (1:n)[-testID]
tr_G = G[trainID,]
te_G = G[testID,]
tr_n = length(trainID)
te_n = length(testID)
for (k in 1:len) {
l = l + 1
if(algo == "CD") {
# theta.new = nng.cd(Gw[trainID,], uw[trainID], theta = init.theta, lambda_theta[k], gamma)
theta.new = .Call("Cnng", Gw[trainID,], uw[trainID], tr_n, d, init.theta, lambda_theta[k], gamma)
}
if(algo == "QP") {
theta.new = nng.QP(model$zw.new[trainID], model$b.new, model$cw.new[trainID], model$w.new[trainID], tr_G,
theta = init.theta, lambda0, lambda_theta[k], gamma)
}
testfhat = c(te_G %*% theta.new)
testmu = obj$linkinv(testfhat)
# testw = obj$variance(testmu)
# testz = testfhat + (y[testID] - testmu) / testw
# testzw = testz * sqrt(testw)
# testGw = te_G * sqrt(testw)
# testuw = testzw - model$b.new * sqrt(testw) - (te_n/2) * lambda0 * model$cw.new[testID]
# rss <- t(testuw - testGw %*% theta.new) %*% (testuw - testGw %*% theta.new) + .1
# l1 = gamma * sum(abs(theta.new)) + (1-gamma) * norm(theta.new, "2")
# l2 = gamma * sum(abs(ginv(theta.new))) + (1-gamma) * norm(ginv(theta.new), "2")
# S = l1 + l2
# measure[f, k] <- rss / (1 - d * S/te_n + .1)^2 / te_n
if(obj$family == "binomial") measure[f, k] <- mean(ifelse(testmu < 0.5, 0, 1) != y[testID])
# if(obj$family == "gaussian") measure[f, k] <- mean((testmu - y[testID])^2)
# if(obj$family == "poisson") measure[f, k] <- mean(KLD(testfhat, y[testID]))
}
}
measure[is.nan(measure)] <- NA
cvm <- apply(measure, 2, mean, na.rm = T)
cvsd <- apply(measure, 2, sd, na.rm = T) / sqrt(nrow(measure)) + 1e-22
cvm[is.nan(cvm)] <- NA
cvsd[is.na(cvsd)] <- 0
# selm = floor(apply(sel, 2, mean))
id = which.min(cvm)[1]
if(one.std){
st1_err = cvm[id] + cvsd[id] # minimum cv err
std.id = max(which(cvm[id:len] <= st1_err & cvm[id] <= cvm[id:len]))
if(is.na(std.id)){
std.id = id
optlambda = lambda_theta[std.id]
} else{
std.id = ifelse(std.id > id, std.id, id)
optlambda = lambda_theta[std.id]
}
} else{
optlambda = lambda_theta[id]
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
max_min <- c(min(cvm - cvsd, na.rm = TRUE), max(cvm + cvsd, na.rm = TRUE))
xrange = log(lambda_theta)
plot(xrange, cvm, main = main, xlab = expression("Log(" * lambda[theta] * ")"), ylab = "generalized cross validation", ylim = max_min, type = 'n')
arrows(xrange, cvm - cvsd, xrange, cvm + cvsd, angle = 90, code = 3, length = 0.1, col = 'gray')
points(xrange, cvm, pch = 15, col = 'red')
abline(v = xrange[id], col = 'darkgrey')
# text(log(lambda_theta), par("usr")[4], labels = selm, pos = 1)
if(one.std) abline(v = xrange[std.id], col = 'darkgrey')
if(algo == "CD"){
# theta.new = nng.cd(Gw, uw, theta = init.theta, optlambda, gamma)
theta.new = .Call("Cnng", Gw, uw, n, d, init.theta, optlambda, gamma)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
if(algo == "QP"){
theta.new = nng.QP(model$zw.new, model$b.new, model$cw.new, model$w.new, G,
init.theta, lambda0, optlambda, gamma, obj)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
return(out)
}
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit1, x, y, wt, sspline_cvfit1$optlambda, lambda_theta, gamma, nfolds, obj, one.std, algo)
theta.new = rescale_theta(nng_fit$theta.new, FALSE)
# solve (theta) - 2nd
sspline_cvfit2 = try({cv.sspline(x, y, theta.new/wt^2, nfolds, lambda0, obj, one.std, type, kparam, algo)}) ## 초기값 설정. 수정할 함수
sspline_cvfit2
nng_fit
cv.nng = function(model, x, y, mscale, lambda0, lambda_theta, gamma, nfolds, obj, one.std, algo)
{
n = length(y)
d = length(mscale)
IDmat = model$IDmat
# solve theta
G <- matrix(0, nrow(model$R[, ,1]), d)
for (j in 1:d) {
G[, j] = model$R[, , j] %*% model$c.new * (mscale[j]^(-2))
}
Gw = G * sqrt(model$w.new)
uw = model$zw.new - model$b.new * sqrt(model$w.new) - (n/2) * lambda0 * model$cw.new
# init.theta = as.vector(glmnet(Gw, uw, family = "gaussian", lambda = lambda_theta[1])$beta)
init.theta = rep(1, d)
len = length(lambda_theta)
measure <- matrix(0, ncol = len, nrow = nfolds)
l = 0
for (f in 1:nfolds) {
testID <- IDmat[!is.na(IDmat[, f]), f]
trainID <- (1:n)[-testID]
tr_G = G[trainID,]
te_G = G[testID,]
tr_n = length(trainID)
te_n = length(testID)
for (k in 1:len) {
l = l + 1
if(algo == "CD") {
# theta.new = nng.cd(Gw[trainID,], uw[trainID], theta = init.theta, lambda_theta[k], gamma)
theta.new = .Call("Cnng", Gw[trainID,], uw[trainID], tr_n, d, init.theta, lambda_theta[k], gamma)
}
if(algo == "QP") {
theta.new = nng.QP(model$zw.new[trainID], model$b.new, model$cw.new[trainID], model$w.new[trainID], tr_G,
theta = init.theta, lambda0, lambda_theta[k], gamma)
}
testfhat = c(te_G %*% theta.new)
testmu = obj$linkinv(testfhat)
# testw = obj$variance(testmu)
# testz = testfhat + (y[testID] - testmu) / testw
# testzw = testz * sqrt(testw)
# testGw = te_G * sqrt(testw)
# testuw = testzw - model$b.new * sqrt(testw) - (te_n/2) * lambda0 * model$cw.new[testID]
# rss <- t(testuw - testGw %*% theta.new) %*% (testuw - testGw %*% theta.new) + .1
# l1 = gamma * sum(abs(theta.new)) + (1-gamma) * norm(theta.new, "2")
# l2 = gamma * sum(abs(ginv(theta.new))) + (1-gamma) * norm(ginv(theta.new), "2")
# S = l1 + l2
# measure[f, k] <- rss / (1 - d * S/te_n + .1)^2 / te_n
if(obj$family == "binomial") measure[f, k] <- mean(ifelse(testmu < 0.5, 0, 1) != y[testID])
# if(obj$family == "gaussian") measure[f, k] <- mean((testmu - y[testID])^2)
# if(obj$family == "poisson") measure[f, k] <- mean(KLD(testfhat, y[testID]))
}
}
measure[is.nan(measure)] <- NA
cvm <- apply(measure, 2, mean, na.rm = T)
cvsd <- apply(measure, 2, sd, na.rm = T) / sqrt(nrow(measure)) + 1e-22
cvm[is.nan(cvm)] <- NA
cvsd[is.na(cvsd)] <- 0
# selm = floor(apply(sel, 2, mean))
id = which.min(cvm)[1]
if(one.std){
st1_err = cvm[id] + cvsd[id] # minimum cv err
std.id = max(which(cvm[id:len] <= st1_err & cvm[id] <= cvm[id:len]))
if(is.na(std.id)){
std.id = id
optlambda = lambda_theta[std.id]
} else{
std.id = ifelse(std.id > id, std.id, id)
optlambda = lambda_theta[std.id]
}
} else{
optlambda = lambda_theta[id]
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
max_min <- c(min(cvm - cvsd, na.rm = TRUE), max(cvm + cvsd, na.rm = TRUE))
xrange = log(lambda_theta)
plot(xrange, cvm, main = main, xlab = expression("Log(" * lambda[theta] * ")"), ylab = "generalized cross validation", ylim = max_min, type = 'n')
arrows(xrange, cvm - cvsd, xrange, cvm + cvsd, angle = 90, code = 3, length = 0.1, col = 'gray')
points(xrange, cvm, pch = 15, col = 'red')
abline(v = xrange[id], col = 'darkgrey')
# text(log(lambda_theta), par("usr")[4], labels = selm, pos = 1)
if(one.std) abline(v = xrange[std.id], col = 'darkgrey')
if(algo == "CD"){
# theta.new = nng.cd(Gw, uw, theta = init.theta, optlambda, gamma)
theta.new = .Call("Cnng", Gw, uw, n, d, init.theta, optlambda, gamma)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
if(algo == "QP"){
theta.new = nng.QP(model$zw.new, model$b.new, model$cw.new, model$w.new, G,
init.theta, lambda0, optlambda, gamma, obj)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
return(out)
}
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit1, x, y, wt, sspline_cvfit1$optlambda, lambda_theta, gamma, nfolds, obj, one.std, algo)
nng_fit
cv.nng
cv.nng = function(model, x, y, mscale, lambda0, lambda_theta, gamma, nfolds, obj, one.std, algo)
{
n = length(y)
d = length(mscale)
IDmat = model$IDmat
# solve theta
G <- matrix(0, nrow(model$R[, ,1]), d)
for (j in 1:d) {
G[, j] = model$R[, , j] %*% model$c.new * (mscale[j]^(-2))
}
Gw = G * sqrt(model$w.new)
uw = model$zw.new - model$b.new * sqrt(model$w.new) - (n/2) * lambda0 * model$cw.new
# init.theta = as.vector(glmnet(Gw, uw, family = "gaussian", lambda = lambda_theta[1])$beta)
init.theta = rep(1, d)
len = length(lambda_theta)
measure <- matrix(0, ncol = len, nrow = nfolds)
l = 0
for (f in 1:nfolds) {
testID <- IDmat[!is.na(IDmat[, f]), f]
trainID <- (1:n)[-testID]
tr_G = G[trainID,]
te_G = G[testID,]
tr_n = length(trainID)
te_n = length(testID)
for (k in 1:len) {
l = l + 1
if(algo == "CD") {
theta.new = nng.cd(Gw[trainID,], uw[trainID], theta = init.theta, lambda_theta[k], gamma)
# theta.new = .Call("Cnng", Gw[trainID,], uw[trainID], tr_n, d, init.theta, lambda_theta[k], gamma)
}
if(algo == "QP") {
theta.new = nng.QP(model$zw.new[trainID], model$b.new, model$cw.new[trainID], model$w.new[trainID], tr_G,
theta = init.theta, lambda0, lambda_theta[k], gamma)
}
testfhat = c(te_G %*% theta.new)
testmu = obj$linkinv(testfhat)
# testw = obj$variance(testmu)
# testz = testfhat + (y[testID] - testmu) / testw
# testzw = testz * sqrt(testw)
# testGw = te_G * sqrt(testw)
# testuw = testzw - model$b.new * sqrt(testw) - (te_n/2) * lambda0 * model$cw.new[testID]
# rss <- t(testuw - testGw %*% theta.new) %*% (testuw - testGw %*% theta.new) + .1
# l1 = gamma * sum(abs(theta.new)) + (1-gamma) * norm(theta.new, "2")
# l2 = gamma * sum(abs(ginv(theta.new))) + (1-gamma) * norm(ginv(theta.new), "2")
# S = l1 + l2
# measure[f, k] <- rss / (1 - d * S/te_n + .1)^2 / te_n
if(obj$family == "binomial") measure[f, k] <- mean(ifelse(testmu < 0.5, 0, 1) != y[testID])
# if(obj$family == "gaussian") measure[f, k] <- mean((testmu - y[testID])^2)
# if(obj$family == "poisson") measure[f, k] <- mean(KLD(testfhat, y[testID]))
}
}
measure[is.nan(measure)] <- NA
cvm <- apply(measure, 2, mean, na.rm = T)
cvsd <- apply(measure, 2, sd, na.rm = T) / sqrt(nrow(measure)) + 1e-22
cvm[is.nan(cvm)] <- NA
cvsd[is.na(cvsd)] <- 0
# selm = floor(apply(sel, 2, mean))
id = which.min(cvm)[1]
if(one.std){
st1_err = cvm[id] + cvsd[id] # minimum cv err
std.id = max(which(cvm[id:len] <= st1_err & cvm[id] <= cvm[id:len]))
if(is.na(std.id)){
std.id = id
optlambda = lambda_theta[std.id]
} else{
std.id = ifelse(std.id > id, std.id, id)
optlambda = lambda_theta[std.id]
}
} else{
optlambda = lambda_theta[id]
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
max_min <- c(min(cvm - cvsd, na.rm = TRUE), max(cvm + cvsd, na.rm = TRUE))
xrange = log(lambda_theta)
plot(xrange, cvm, main = main, xlab = expression("Log(" * lambda[theta] * ")"), ylab = "generalized cross validation", ylim = max_min, type = 'n')
arrows(xrange, cvm - cvsd, xrange, cvm + cvsd, angle = 90, code = 3, length = 0.1, col = 'gray')
points(xrange, cvm, pch = 15, col = 'red')
abline(v = xrange[id], col = 'darkgrey')
# text(log(lambda_theta), par("usr")[4], labels = selm, pos = 1)
if(one.std) abline(v = xrange[std.id], col = 'darkgrey')
if(algo == "CD"){
theta.new = nng.cd(Gw, uw, theta = init.theta, optlambda, gamma)
# theta.new = .Call("Cnng", Gw, uw, n, d, init.theta, optlambda, gamma)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
if(algo == "QP"){
theta.new = nng.QP(model$zw.new, model$b.new, model$cw.new, model$w.new, G,
init.theta, lambda0, optlambda, gamma, obj)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
return(out)
}
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit1, x, y, wt, sspline_cvfit1$optlambda, lambda_theta, gamma, nfolds, obj, one.std, algo)
nng_fit
theta.new = rescale_theta(nng_fit$theta.new, FALSE)
# solve (theta) - 2nd
sspline_cvfit2 = try({cv.sspline(x, y, theta.new/wt^2, nfolds, lambda0, obj, one.std, type, kparam, algo)}) ## 초기값 설정. 수정할 함수
nng_fit = cv.nng(sspline_cvfit2, x, y, wt, sspline_cvfit2$optlambda, lambda_theta, gamma, nfolds, obj, one.std, algo)
theta.new = rescale_theta(nng_fit$theta.new, FALSE)
print(nng_fit$theta.new)
sspline_cvfit3 = cv.sspline(x, y, theta.new/wt^2, nfolds, lambda0, obj, one.std, type, kparam, algo) ## 초기값 설정. 수정할 함수
cv.nng = function(model, x, y, mscale, lambda0, lambda_theta, gamma, nfolds, obj, one.std, algo)
{
n = length(y)
d = length(mscale)
IDmat = model$IDmat
# solve theta
G <- matrix(0, nrow(model$R[, ,1]), d)
for (j in 1:d) {
G[, j] = model$R[, , j] %*% model$c.new * (mscale[j]^(-2))
}
Gw = G * sqrt(model$w.new)
uw = model$zw.new - model$b.new * sqrt(model$w.new) - (n/2) * lambda0 * model$cw.new
init.theta = as.vector(glmnet(Gw, uw, family = "gaussian", lambda = lambda_theta[1])$beta)
# init.theta = rep(1, d)
len = length(lambda_theta)
measure <- matrix(0, ncol = len, nrow = nfolds)
l = 0
for (f in 1:nfolds) {
testID <- IDmat[!is.na(IDmat[, f]), f]
trainID <- (1:n)[-testID]
tr_G = G[trainID,]
te_G = G[testID,]
tr_n = length(trainID)
te_n = length(testID)
for (k in 1:len) {
l = l + 1
if(algo == "CD") {
theta.new = nng.cd(Gw[trainID,], uw[trainID], theta = init.theta, lambda_theta[k], gamma)
# theta.new = .Call("Cnng", Gw[trainID,], uw[trainID], tr_n, d, init.theta, lambda_theta[k], gamma)
}
if(algo == "QP") {
theta.new = nng.QP(model$zw.new[trainID], model$b.new, model$cw.new[trainID], model$w.new[trainID], tr_G,
theta = init.theta, lambda0, lambda_theta[k], gamma)
}
testfhat = c(te_G %*% theta.new)
testmu = obj$linkinv(testfhat)
# testw = obj$variance(testmu)
# testz = testfhat + (y[testID] - testmu) / testw
# testzw = testz * sqrt(testw)
# testGw = te_G * sqrt(testw)
# testuw = testzw - model$b.new * sqrt(testw) - (te_n/2) * lambda0 * model$cw.new[testID]
# rss <- t(testuw - testGw %*% theta.new) %*% (testuw - testGw %*% theta.new) + .1
# l1 = gamma * sum(abs(theta.new)) + (1-gamma) * norm(theta.new, "2")
# l2 = gamma * sum(abs(ginv(theta.new))) + (1-gamma) * norm(ginv(theta.new), "2")
# S = l1 + l2
# measure[f, k] <- rss / (1 - d * S/te_n + .1)^2 / te_n
if(obj$family == "binomial") measure[f, k] <- mean(ifelse(testmu < 0.5, 0, 1) != y[testID])
# if(obj$family == "gaussian") measure[f, k] <- mean((testmu - y[testID])^2)
# if(obj$family == "poisson") measure[f, k] <- mean(KLD(testfhat, y[testID]))
}
}
measure[is.nan(measure)] <- NA
cvm <- apply(measure, 2, mean, na.rm = T)
cvsd <- apply(measure, 2, sd, na.rm = T) / sqrt(nrow(measure)) + 1e-22
cvm[is.nan(cvm)] <- NA
cvsd[is.na(cvsd)] <- 0
# selm = floor(apply(sel, 2, mean))
id = which.min(cvm)[1]
if(one.std){
st1_err = cvm[id] + cvsd[id] # minimum cv err
std.id = max(which(cvm[id:len] <= st1_err & cvm[id] <= cvm[id:len]))
if(is.na(std.id)){
std.id = id
optlambda = lambda_theta[std.id]
} else{
std.id = ifelse(std.id > id, std.id, id)
optlambda = lambda_theta[std.id]
}
} else{
optlambda = lambda_theta[id]
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
max_min <- c(min(cvm - cvsd, na.rm = TRUE), max(cvm + cvsd, na.rm = TRUE))
xrange = log(lambda_theta)
plot(xrange, cvm, main = main, xlab = expression("Log(" * lambda[theta] * ")"), ylab = "generalized cross validation", ylim = max_min, type = 'n')
arrows(xrange, cvm - cvsd, xrange, cvm + cvsd, angle = 90, code = 3, length = 0.1, col = 'gray')
points(xrange, cvm, pch = 15, col = 'red')
abline(v = xrange[id], col = 'darkgrey')
# text(log(lambda_theta), par("usr")[4], labels = selm, pos = 1)
if(one.std) abline(v = xrange[std.id], col = 'darkgrey')
if(algo == "CD"){
theta.new = nng.cd(Gw, uw, theta = init.theta, optlambda, gamma)
# theta.new = .Call("Cnng", Gw, uw, n, d, init.theta, optlambda, gamma)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
if(algo == "QP"){
theta.new = nng.QP(model$zw.new, model$b.new, model$cw.new, model$w.new, G,
init.theta, lambda0, optlambda, gamma, obj)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
return(out)
}
# solve (theta) - 1st
sspline_cvfit1 = cv.sspline(x, y, rep(1, d)/wt^2, nfolds, lambda0, obj, one.std, type, kparam, algo) ## 초기값 설정. 수정할 함수
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit1, x, y, wt, sspline_cvfit1$optlambda, lambda_theta, gamma, nfolds, obj, one.std, algo)
theta.new = rescale_theta(nng_fit$theta.new, FALSE)
# solve (theta) - 2nd
sspline_cvfit2 = try({cv.sspline(x, y, theta.new/wt^2, nfolds, lambda0, obj, one.std, type, kparam, algo)}) ## 초기값 설정. 수정할 함수
# if not convergence
if(class(sspline_cvfit2) == "try-error"){
out = list(data = list(x = x, y = y, R = sspline_cvfit1$R, kernel = type, kparam = kparam),
tune = list(lambda0 = lambda0, lambda_theta = lambda_theta, gamma = gamma),
c_step = sspline_cvfit1,
theta_step = nng_fit,
object = obj,
algorithm = algo)
class(out) = "cosso"
cat("cdcosso is not convergence. \n")
return(out)
} else if(!sspline_cvfit2$conv){
out = list(data = list(x = x, y = y, R = sspline_cvfit1$R, kernel = type, kparam = kparam),
tune = list(lambda0 = lambda0, lambda_theta = lambda_theta, gamma = gamma),
c_step = sspline_cvfit1,
theta_step = nng_fit,
object = obj,
algorithm = algo)
class(out) = "cosso"
cat("cdcosso is not convergence. \n")
return(out)
}
nng_fit = cv.nng(sspline_cvfit2, x, y, wt, sspline_cvfit2$optlambda, lambda_theta, gamma, nfolds, obj, one.std, algo)
theta.new = rescale_theta(nng_fit$theta.new, FALSE)
print(nng_fit$theta.new)
