if(algo == "QP") len = length(M)
measure <- matrix(0, ncol = len, nrow = nfolds)
l = 0
for (f in 1:nfolds) {
testID <- IDmat[!is.na(IDmat[, f]), f]
trainID <- (1:n)[-testID]
tr_G = G[trainID,]
te_G = G[testID,]
tr_n = length(trainID)
te_n = length(testID)
for (k in 1:len) {
# init.theta = as.vector(scale(glmnet(x[trainID,], y[trainID], family = "binomial", lambda = lambda_theta[k], gamma = gamma)$beta))
# if(sum(is.nan(init.theta)) == d) init.theta = rep(0, d)
if(algo == "CD") {
# nng.fit = nng.cd(model$zw.new[trainID], model$b.new, model$sw.new[trainID], model$cw.new[trainID], model$w.new[trainID], tr_G,
#                  theta = init.theta, lambda0, lambda_theta[k], gamma)
Gw = apply(tr_G * sqrt(model$w.new[trainID]), 2, rescale)
uw = model$zw.new[trainID] - model$b.new * model$sw.new[trainID] - (tr_n/2) * lambda0 * model$cw.new[trainID]
uw = uw / sd(uw)
theta.new = .Call("Cnng", Gw, uw, init.theta, lambda_theta[k], gamma)
print(theta.new)
if(sum(theta.new == 0) == d){
theta.new = rep(1e-10, d)
} else{
theta.new = theta.new
}
}
if(algo == "QP") {
nng.fit = nng.QP(model$zw.new[trainID], model$b.new, model$sw.new[trainID], model$cw.new[trainID], model$w.new[trainID], tr_G,
theta = init.theta, lambda0, M[k], gamma)
# print(nng.fit)
if(sum(nng.fit$theta.new == 0) == d){
theta.new = rep(1e-10, d)
} else{
theta.new = nng.fit$theta.new
}
}
# sel[f, k] = sum(theta.new > 0)
# print(nng.fit$theta.new)
testfhat = c(te_G %*% theta.new)
testmu = obj$linkinv(testfhat)
testw = obj$variance(testmu)
testz = testfhat + (y[testID] - testmu) / testw
testzw = testz * sqrt(testw)
testGw = te_G * sqrt(testw)
# rss <- t(testzw - testGw %*% theta.new) %*% (testzw - testGw %*% theta.new) + .1
# l1 = gamma * sum(abs(theta.new)) + (1-gamma) * norm(theta.new, "2")
# l2 = gamma * sum(abs(ginv(theta.new))) + (1-gamma) * norm(ginv(theta.new), "2")
# S = l1 + l2
# measure[f, k] <- rss / (1 - d*S/length(testID) + .1)^2 / length(testID)
if(obj$family == "binomial") measure[f, k] <- mean(ifelse(testmu < 0.5, 0, 1) != y[testID])
if(obj$family == "gaussian") measure[f, k] <- mean((testmu - y[testID])^2)
if(obj$family == "poisson") measure[f, k] <- mean(KLD(testfhat, y[testID]))
}
}
# measure[is.nan(measure)] = 1e-30
# mid = colSums(measure) != 0
# measure = measure[,mid]
# if(algo == "CD") lambda_theta = lambda_theta[mid]
# if(algo == "QP") M = M[mid]
cvm <- apply(measure, 2, mean, na.rm = T)
cvsd <- apply(measure, 2, sd, na.rm = T) / sqrt(nrow(measure)) + 1e-22
# selm = floor(apply(sel, 2, mean))
id = which.min(cvm)[1]
if(one.std){
st1_err = cvm[id] + cvsd[id] # minimum cv err
std.id = max(which(cvm[id:len] <= st1_err & cvm[id] <= cvm[id:len]))
std.id = ifelse(std.id > id, std.id, id)
if(algo == "CD") optlambda = lambda_theta[std.id]
if(algo == "QP") optM = M[std.id]
} else{
if(algo == "CD") optlambda = lambda_theta[id]
if(algo == "QP") optM = M[id]
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
max_min <- c(min(cvm - cvsd), max(cvm + cvsd))
if(algo == "CD") xrange = log(lambda_theta)
if(algo == "QP") xrange = log(M)
plot(xrange, cvm, main = main, xlab = expression("Log(" * lambda[theta] * ")"), ylab = "generalized cross validation", ylim = max_min, type = 'n')
arrows(xrange, cvm - cvsd, xrange, cvm + cvsd, angle = 90, code = 3, length = 0.1, col = 'gray')
points(xrange, cvm, pch = 15, col = 'red')
abline(v = xrange[id], col = 'darkgrey')
# text(log(lambda_theta), par("usr")[4], labels = selm, pos = 1)
if(one.std) abline(v = xrange[std.id], col = 'darkgrey')
# init.theta = as.vector(scale(glmnet(x, y, family = "binomial", lambda = optlambda, gamma = 0)$beta))
# if(sum(is.nan(init.theta)) == d) init.theta = rep(0, d)
if(algo == "CD"){
Gw = apply(G * sqrt(model$w.new), 2, rescale)
uw = model$zw.new - model$b.new * model$sw.new - (n/2) * lambda0 * model$cw.new
uw = c(scale(uw))
# theta.new = nng_cpp(Gw, uw, init.theta, optlambda, gamma)
# nng.fit = nng.cd(model$zw.new, model$b.new, model$sw.new, model$cw.new, model$w.new, G,
#                  theta = init.theta, lambda0, optlambda, gamma)
theta.new = .Call("Cnng", Gw, uw, init.theta, optlambda, gamma)
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new)
}
if(algo == "QP"){
nng.fit = nng.QP(model$zw.new, model$b.new, model$sw.new, model$cw.new, model$w.new, G,
init.theta, lambda0, optM, gamma, obj)
out = list(cv_error = measure, optlambda_theta = optM, gamma = gamma, theta.new = nng.fit$theta.new)
}
return(out)
}
cv.nng(sspline_cvfit, x, y, wt, init.theta, optlambda0, lambda_theta, M, gamma, nfolds, obj, one.std, algo)
nng_fit
cv.nng = function(model, x, y, mscale, init.theta, lambda0, lambda_theta, M, gamma, nfolds, obj, one.std, algo)
{
n = length(y)
d = length(mscale)
IDmat = model$IDmat
sdx <- sqrt(drop(rep(1, n) %*% (x^2))/(n - 1))
G <- matrix(0, nrow(model$R[, ,1]), d)
for (j in 1:d) {
G[, j] = model$R[, , j] %*% model$c.new * (mscale[j]^(-2))
}
if(algo == "CD") len = length(lambda_theta)
if(algo == "QP") len = length(M)
measure <- matrix(0, ncol = len, nrow = nfolds)
l = 0
for (f in 1:nfolds) {
testID <- IDmat[!is.na(IDmat[, f]), f]
trainID <- (1:n)[-testID]
tr_G = G[trainID,]
te_G = G[testID,]
tr_n = length(trainID)
te_n = length(testID)
for (k in 1:len) {
# init.theta = as.vector(scale(glmnet(x[trainID,], y[trainID], family = "binomial", lambda = lambda_theta[k], gamma = gamma)$beta))
# if(sum(is.nan(init.theta)) == d) init.theta = rep(0, d)
if(algo == "CD") {
# nng.fit = nng.cd(model$zw.new[trainID], model$b.new, model$sw.new[trainID], model$cw.new[trainID], model$w.new[trainID], tr_G,
#                  theta = init.theta, lambda0, lambda_theta[k], gamma)
Gw = apply(tr_G * sqrt(model$w.new[trainID]), 2, rescale)
uw = model$zw.new[trainID] - model$b.new * model$sw.new[trainID] - (tr_n/2) * lambda0 * model$cw.new[trainID]
uw = uw / sd(uw)
theta.new = .Call("Cnng", Gw, uw, init.theta, lambda_theta[k], gamma)
if(sum(theta.new == 0) == d){
theta.new = rep(1e-10, d)
} else{
theta.new = theta.new / sd(theta.new)
}
}
if(algo == "QP") {
nng.fit = nng.QP(model$zw.new[trainID], model$b.new, model$sw.new[trainID], model$cw.new[trainID], model$w.new[trainID], tr_G,
theta = init.theta, lambda0, M[k], gamma)
# print(nng.fit)
if(sum(nng.fit$theta.new == 0) == d){
theta.new = rep(1e-10, d)
} else{
theta.new = nng.fit$theta.new
}
}
# sel[f, k] = sum(theta.new > 0)
# print(nng.fit$theta.new)
testfhat = c(te_G %*% theta.new)
testmu = obj$linkinv(testfhat)
testw = obj$variance(testmu)
testz = testfhat + (y[testID] - testmu) / testw
testzw = testz * sqrt(testw)
testGw = te_G * sqrt(testw)
# rss <- t(testzw - testGw %*% theta.new) %*% (testzw - testGw %*% theta.new) + .1
# l1 = gamma * sum(abs(theta.new)) + (1-gamma) * norm(theta.new, "2")
# l2 = gamma * sum(abs(ginv(theta.new))) + (1-gamma) * norm(ginv(theta.new), "2")
# S = l1 + l2
# measure[f, k] <- rss / (1 - d*S/length(testID) + .1)^2 / length(testID)
if(obj$family == "binomial") measure[f, k] <- mean(ifelse(testmu < 0.5, 0, 1) != y[testID])
if(obj$family == "gaussian") measure[f, k] <- mean((testmu - y[testID])^2)
if(obj$family == "poisson") measure[f, k] <- mean(KLD(testfhat, y[testID]))
}
}
# measure[is.nan(measure)] = 1e-30
# mid = colSums(measure) != 0
# measure = measure[,mid]
# if(algo == "CD") lambda_theta = lambda_theta[mid]
# if(algo == "QP") M = M[mid]
cvm <- apply(measure, 2, mean, na.rm = T)
cvsd <- apply(measure, 2, sd, na.rm = T) / sqrt(nrow(measure)) + 1e-22
# selm = floor(apply(sel, 2, mean))
id = which.min(cvm)[1]
if(one.std){
st1_err = cvm[id] + cvsd[id] # minimum cv err
std.id = max(which(cvm[id:len] <= st1_err & cvm[id] <= cvm[id:len]))
std.id = ifelse(std.id > id, std.id, id)
if(algo == "CD") optlambda = lambda_theta[std.id]
if(algo == "QP") optM = M[std.id]
} else{
if(algo == "CD") optlambda = lambda_theta[id]
if(algo == "QP") optM = M[id]
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
max_min <- c(min(cvm - cvsd), max(cvm + cvsd))
if(algo == "CD") xrange = log(lambda_theta)
if(algo == "QP") xrange = log(M)
plot(xrange, cvm, main = main, xlab = expression("Log(" * lambda[theta] * ")"), ylab = "generalized cross validation", ylim = max_min, type = 'n')
arrows(xrange, cvm - cvsd, xrange, cvm + cvsd, angle = 90, code = 3, length = 0.1, col = 'gray')
points(xrange, cvm, pch = 15, col = 'red')
abline(v = xrange[id], col = 'darkgrey')
# text(log(lambda_theta), par("usr")[4], labels = selm, pos = 1)
if(one.std) abline(v = xrange[std.id], col = 'darkgrey')
# init.theta = as.vector(scale(glmnet(x, y, family = "binomial", lambda = optlambda, gamma = 0)$beta))
# if(sum(is.nan(init.theta)) == d) init.theta = rep(0, d)
if(algo == "CD"){
Gw = apply(G * sqrt(model$w.new), 2, rescale)
uw = model$zw.new - model$b.new * model$sw.new - (n/2) * lambda0 * model$cw.new
uw = uw / sd(uw)
# theta.new = nng_cpp(Gw, uw, init.theta, optlambda, gamma)
# nng.fit = nng.cd(model$zw.new, model$b.new, model$sw.new, model$cw.new, model$w.new, G,
#                  theta = init.theta, lambda0, optlambda, gamma)
theta.new = .Call("Cnng", Gw, uw, init.theta, optlambda, gamma)
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new)
}
if(algo == "QP"){
nng.fit = nng.QP(model$zw.new, model$b.new, model$sw.new, model$cw.new, model$w.new, G,
init.theta, lambda0, optM, gamma, obj)
out = list(cv_error = measure, optlambda_theta = optM, gamma = gamma, theta.new = nng.fit$theta.new)
}
return(out)
}
cv.nng(sspline_cvfit, x, y, wt, init.theta, optlambda0, lambda_theta, M, gamma, nfolds, obj, one.std, algo)
# solve (theta) - 2nd
if(sum(nng_fit$theta.new == 0) == d){
theta.new = rep(1e-10, d)
} else{
theta.new = nng_fit$theta.new
}
Rtheta <- wsGram(sspline_cvfit$R, theta.new/wt^2)
f.init <- sspline_cvfit$b.new + Rtheta %*% sspline_cvfit$c.new
f.init
f.init / sd(f.init)
Rtheta %*% sspline_cvfit$c.new
sspline_cvfit$b.new
wsGram(sspline_cvfit$R, theta.new/wt^2)
nng_fit$theta.new
theta.new
wsGram(sspline_cvfit$R, theta.new/wt^2)
sspline_cvfit$b.new + Rtheta %*% sspline_cvfit$c.new
cv.nng = function(model, x, y, mscale, init.theta, lambda0, lambda_theta, M, gamma, nfolds, obj, one.std, algo)
{
n = length(y)
d = length(mscale)
IDmat = model$IDmat
sdx <- sqrt(drop(rep(1, n) %*% (x^2))/(n - 1))
G <- matrix(0, nrow(model$R[, ,1]), d)
for (j in 1:d) {
G[, j] = model$R[, , j] %*% model$c.new * (mscale[j]^(-2))
}
if(algo == "CD") len = length(lambda_theta)
if(algo == "QP") len = length(M)
measure <- matrix(0, ncol = len, nrow = nfolds)
l = 0
for (f in 1:nfolds) {
testID <- IDmat[!is.na(IDmat[, f]), f]
trainID <- (1:n)[-testID]
tr_G = G[trainID,]
te_G = G[testID,]
tr_n = length(trainID)
te_n = length(testID)
for (k in 1:len) {
# init.theta = as.vector(scale(glmnet(x[trainID,], y[trainID], family = "binomial", lambda = lambda_theta[k], gamma = gamma)$beta))
# if(sum(is.nan(init.theta)) == d) init.theta = rep(0, d)
if(algo == "CD") {
# nng.fit = nng.cd(model$zw.new[trainID], model$b.new, model$sw.new[trainID], model$cw.new[trainID], model$w.new[trainID], tr_G,
#                  theta = init.theta, lambda0, lambda_theta[k], gamma)
Gw = apply(tr_G * sqrt(model$w.new[trainID]), 2, rescale)
uw = model$zw.new[trainID] - model$b.new * model$sw.new[trainID] - (tr_n/2) * lambda0 * model$cw.new[trainID]
uw = uw / sd(uw)
theta.new = .Call("Cnng", Gw, uw, init.theta, lambda_theta[k], gamma)
if(sum(theta.new == 0) == d){
theta.new = rep(1e-10, d)
} else{
theta.new = scale(theta.new)
}
}
if(algo == "QP") {
nng.fit = nng.QP(model$zw.new[trainID], model$b.new, model$sw.new[trainID], model$cw.new[trainID], model$w.new[trainID], tr_G,
theta = init.theta, lambda0, M[k], gamma)
# print(nng.fit)
if(sum(nng.fit$theta.new == 0) == d){
theta.new = rep(1e-10, d)
} else{
theta.new = nng.fit$theta.new
}
}
# sel[f, k] = sum(theta.new > 0)
# print(nng.fit$theta.new)
testfhat = c(te_G %*% theta.new)
testmu = obj$linkinv(testfhat)
testw = obj$variance(testmu)
testz = testfhat + (y[testID] - testmu) / testw
testzw = testz * sqrt(testw)
testGw = te_G * sqrt(testw)
# rss <- t(testzw - testGw %*% theta.new) %*% (testzw - testGw %*% theta.new) + .1
# l1 = gamma * sum(abs(theta.new)) + (1-gamma) * norm(theta.new, "2")
# l2 = gamma * sum(abs(ginv(theta.new))) + (1-gamma) * norm(ginv(theta.new), "2")
# S = l1 + l2
# measure[f, k] <- rss / (1 - d*S/length(testID) + .1)^2 / length(testID)
if(obj$family == "binomial") measure[f, k] <- mean(ifelse(testmu < 0.5, 0, 1) != y[testID])
if(obj$family == "gaussian") measure[f, k] <- mean((testmu - y[testID])^2)
if(obj$family == "poisson") measure[f, k] <- mean(KLD(testfhat, y[testID]))
}
}
# measure[is.nan(measure)] = 1e-30
# mid = colSums(measure) != 0
# measure = measure[,mid]
# if(algo == "CD") lambda_theta = lambda_theta[mid]
# if(algo == "QP") M = M[mid]
cvm <- apply(measure, 2, mean, na.rm = T)
cvsd <- apply(measure, 2, sd, na.rm = T) / sqrt(nrow(measure)) + 1e-22
# selm = floor(apply(sel, 2, mean))
id = which.min(cvm)[1]
if(one.std){
st1_err = cvm[id] + cvsd[id] # minimum cv err
std.id = max(which(cvm[id:len] <= st1_err & cvm[id] <= cvm[id:len]))
std.id = ifelse(std.id > id, std.id, id)
if(algo == "CD") optlambda = lambda_theta[std.id]
if(algo == "QP") optM = M[std.id]
} else{
if(algo == "CD") optlambda = lambda_theta[id]
if(algo == "QP") optM = M[id]
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
max_min <- c(min(cvm - cvsd), max(cvm + cvsd))
if(algo == "CD") xrange = log(lambda_theta)
if(algo == "QP") xrange = log(M)
plot(xrange, cvm, main = main, xlab = expression("Log(" * lambda[theta] * ")"), ylab = "generalized cross validation", ylim = max_min, type = 'n')
arrows(xrange, cvm - cvsd, xrange, cvm + cvsd, angle = 90, code = 3, length = 0.1, col = 'gray')
points(xrange, cvm, pch = 15, col = 'red')
abline(v = xrange[id], col = 'darkgrey')
# text(log(lambda_theta), par("usr")[4], labels = selm, pos = 1)
if(one.std) abline(v = xrange[std.id], col = 'darkgrey')
# init.theta = as.vector(scale(glmnet(x, y, family = "binomial", lambda = optlambda, gamma = 0)$beta))
# if(sum(is.nan(init.theta)) == d) init.theta = rep(0, d)
if(algo == "CD"){
Gw = apply(G * sqrt(model$w.new), 2, rescale)
uw = model$zw.new - model$b.new * model$sw.new - (n/2) * lambda0 * model$cw.new
uw = uw / sd(uw)
# theta.new = nng_cpp(Gw, uw, init.theta, optlambda, gamma)
# nng.fit = nng.cd(model$zw.new, model$b.new, model$sw.new, model$cw.new, model$w.new, G,
#                  theta = init.theta, lambda0, optlambda, gamma)
theta.new = .Call("Cnng", Gw, uw, init.theta, optlambda, gamma)
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new)
}
if(algo == "QP"){
nng.fit = nng.QP(model$zw.new, model$b.new, model$sw.new, model$cw.new, model$w.new, G,
init.theta, lambda0, optM, gamma, obj)
out = list(cv_error = measure, optlambda_theta = optM, gamma = gamma, theta.new = nng.fit$theta.new)
}
return(out)
}
cv.nng(sspline_cvfit, x, y, wt, init.theta, optlambda0, lambda_theta, M, gamma, nfolds, obj, one.std, algo)
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit, x, y, wt, init.theta, optlambda0, lambda_theta, M, gamma, nfolds, obj, one.std, algo)
# solve (theta) - 2nd
if(sum(nng_fit$theta.new == 0) == d){
theta.new = rep(1e-10, d)
} else{
theta.new = scale(nng_fit$theta.new)
}
Rtheta <- wsGram(sspline_cvfit$R, theta.new/wt^2)
f.init <- sspline_cvfit$b.new + Rtheta %*% sspline_cvfit$c.new
f.init
lambda0
cv.sspline(x, y, theta.new/wt^2, rep(mean(y), n), nfolds, lambda0, obj, one.std, type, kparam, algo) ## 초기값 설정. 수정할 함수
cv.nng = function(model, x, y, mscale, init.theta, lambda0, lambda_theta, M, gamma, nfolds, obj, one.std, algo)
{
n = length(y)
d = length(mscale)
IDmat = model$IDmat
sdx <- sqrt(drop(rep(1, n) %*% (x^2))/(n - 1))
G <- matrix(0, nrow(model$R[, ,1]), d)
for (j in 1:d) {
G[, j] = model$R[, , j] %*% model$c.new * (mscale[j]^(-2))
}
if(algo == "CD") len = length(lambda_theta)
if(algo == "QP") len = length(M)
measure <- matrix(0, ncol = len, nrow = nfolds)
l = 0
for (f in 1:nfolds) {
testID <- IDmat[!is.na(IDmat[, f]), f]
trainID <- (1:n)[-testID]
tr_G = G[trainID,]
te_G = G[testID,]
tr_n = length(trainID)
te_n = length(testID)
for (k in 1:len) {
# init.theta = as.vector(scale(glmnet(x[trainID,], y[trainID], family = "binomial", lambda = lambda_theta[k], gamma = gamma)$beta))
# if(sum(is.nan(init.theta)) == d) init.theta = rep(0, d)
if(algo == "CD") {
# nng.fit = nng.cd(model$zw.new[trainID], model$b.new, model$sw.new[trainID], model$cw.new[trainID], model$w.new[trainID], tr_G,
#                  theta = init.theta, lambda0, lambda_theta[k], gamma)
Gw = apply(tr_G * sqrt(model$w.new[trainID]), 2, rescale)
uw = model$zw.new[trainID] - model$b.new * model$sw.new[trainID] - (tr_n/2) * lambda0 * model$cw.new[trainID]
# uw = uw / sd(uw)
theta.new = .Call("Cnng", Gw, uw, init.theta, lambda_theta[k], gamma)
if(sum(theta.new == 0) == d){
theta.new = rep(1e-10, d)
} else{
theta.new = scale(theta.new)
}
}
if(algo == "QP") {
nng.fit = nng.QP(model$zw.new[trainID], model$b.new, model$sw.new[trainID], model$cw.new[trainID], model$w.new[trainID], tr_G,
theta = init.theta, lambda0, M[k], gamma)
# print(nng.fit)
if(sum(nng.fit$theta.new == 0) == d){
theta.new = rep(1e-10, d)
} else{
theta.new = nng.fit$theta.new
}
}
# sel[f, k] = sum(theta.new > 0)
# print(nng.fit$theta.new)
testfhat = c(te_G %*% theta.new)
testmu = obj$linkinv(testfhat)
testw = obj$variance(testmu)
testz = testfhat + (y[testID] - testmu) / testw
testzw = testz * sqrt(testw)
testGw = te_G * sqrt(testw)
# rss <- t(testzw - testGw %*% theta.new) %*% (testzw - testGw %*% theta.new) + .1
# l1 = gamma * sum(abs(theta.new)) + (1-gamma) * norm(theta.new, "2")
# l2 = gamma * sum(abs(ginv(theta.new))) + (1-gamma) * norm(ginv(theta.new), "2")
# S = l1 + l2
# measure[f, k] <- rss / (1 - d*S/length(testID) + .1)^2 / length(testID)
if(obj$family == "binomial") measure[f, k] <- mean(ifelse(testmu < 0.5, 0, 1) != y[testID])
if(obj$family == "gaussian") measure[f, k] <- mean((testmu - y[testID])^2)
if(obj$family == "poisson") measure[f, k] <- mean(KLD(testfhat, y[testID]))
}
}
# measure[is.nan(measure)] = 1e-30
# mid = colSums(measure) != 0
# measure = measure[,mid]
# if(algo == "CD") lambda_theta = lambda_theta[mid]
# if(algo == "QP") M = M[mid]
cvm <- apply(measure, 2, mean, na.rm = T)
cvsd <- apply(measure, 2, sd, na.rm = T) / sqrt(nrow(measure)) + 1e-22
# selm = floor(apply(sel, 2, mean))
id = which.min(cvm)[1]
if(one.std){
st1_err = cvm[id] + cvsd[id] # minimum cv err
std.id = max(which(cvm[id:len] <= st1_err & cvm[id] <= cvm[id:len]))
std.id = ifelse(std.id > id, std.id, id)
if(algo == "CD") optlambda = lambda_theta[std.id]
if(algo == "QP") optM = M[std.id]
} else{
if(algo == "CD") optlambda = lambda_theta[id]
if(algo == "QP") optM = M[id]
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
max_min <- c(min(cvm - cvsd), max(cvm + cvsd))
if(algo == "CD") xrange = log(lambda_theta)
if(algo == "QP") xrange = log(M)
plot(xrange, cvm, main = main, xlab = expression("Log(" * lambda[theta] * ")"), ylab = "generalized cross validation", ylim = max_min, type = 'n')
arrows(xrange, cvm - cvsd, xrange, cvm + cvsd, angle = 90, code = 3, length = 0.1, col = 'gray')
points(xrange, cvm, pch = 15, col = 'red')
abline(v = xrange[id], col = 'darkgrey')
# text(log(lambda_theta), par("usr")[4], labels = selm, pos = 1)
if(one.std) abline(v = xrange[std.id], col = 'darkgrey')
# init.theta = as.vector(scale(glmnet(x, y, family = "binomial", lambda = optlambda, gamma = 0)$beta))
# if(sum(is.nan(init.theta)) == d) init.theta = rep(0, d)
if(algo == "CD"){
Gw = apply(G * sqrt(model$w.new), 2, rescale)
uw = model$zw.new - model$b.new * model$sw.new - (n/2) * lambda0 * model$cw.new
uw = uw / sd(uw)
# theta.new = nng_cpp(Gw, uw, init.theta, optlambda, gamma)
# nng.fit = nng.cd(model$zw.new, model$b.new, model$sw.new, model$cw.new, model$w.new, G,
#                  theta = init.theta, lambda0, optlambda, gamma)
theta.new = .Call("Cnng", Gw, uw, init.theta, optlambda, gamma)
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new)
}
if(algo == "QP"){
nng.fit = nng.QP(model$zw.new, model$b.new, model$sw.new, model$cw.new, model$w.new, G,
init.theta, lambda0, optM, gamma, obj)
out = list(cv_error = measure, optlambda_theta = optM, gamma = gamma, theta.new = nng.fit$theta.new)
}
return(out)
}
