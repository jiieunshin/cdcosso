cat("kernel:", type, "and d =", d, "\n")
# solve (theta) - 1st
sspline_cvfit = cv.sspline(K, y, rep(1, p)/wt^2, lambda0, obj, one.std, type, kparam, algo, show = FALSE) ## 초기값 설정. 수정할 함수
par(mfrow = c(1,2))
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit, y, wt, sspline_cvfit$optlambda, lambda_theta, gamma, obj, one.std, algo)
theta.new = rescale_theta(nng_fit$theta.new)
# solve (theta) - 2nd
# sspline_cvfit = try({cv.sspline(K, y, theta.new/wt^2, lambda0, obj, one.std, type, kparam, algo, show = TRUE)}) ## 초기값 설정. 수정할 함수
par(mfrow = c(1,1))
if(algo == "CD")
out = list(data = list(x = x, y = y, R = sspline_cvfit$R, kernel = type, kparam = kparam),
tune = list(lambda0 = lambda0, lambda_theta = lambda_theta, gamma = gamma),
c_step = sspline_cvfit,
theta_step = nng_fit,
family = obj$family,
algorithm = algo)
if(algo == "QP")
out = list(data = list(x = x, y = y, R = sspline_cvfit$R, kernel = type, kparam = kparam),
tune = list(lambda0 = lambda0, lambda_theta = lambda_theta, gamma = gamma),
c_step = sspline_cvfit,
theta_step = nng_fit,
family = obj$family,
algorithm = algo)
return(out)
}
#' and generates a predicted value for the test data.
#' This function uses the given test data to calculate predictions from the weights and biases generated by the model.
#'
#' @param n The number of observation of a example dataset.
#' @param p Dimension of a example dataset.
#' @param rho Correlation for first five significance variables.
#' @param response Type of response variable.
#'
#' @return a list containing the predicted value for the test data (f.new) and the transformed value of that predicted value (mu.new).
#' @export
data_generation = function(n, p, rho,
response = c("regression", "classification", "count", "survival", "interaction")){
f1 = function(t) t - 0.5
f2 = function(t) (2 * t - 1)^2 - 0.4
f3 = function(t) sin(2 * pi * t) / (2 - sin(2 * pi * t)) - 0.1
f4 = function(t) 0.1*sin(2 * pi * t) + 0.2*cos(2 * pi * t) + 0.3*sin(2 * pi * t)^2 + 0.4*cos(2 * pi * t)^2 + 0.5*sin(2 * pi * t)^3 - 0.4
f5 = function(t) sin(pi * t^4) + t^4 - 0.5
# f1 = function(t) 3*t - 1.5
# f2 = function(t) pi * sin(pi * t) - 2
# f3 = function(t) (cos(2 * t) + sin(7 * t)) - 0.5
# f4 = function(t) 2 * t^5 - 0.2
# f5 = function(t) (sin(6 * t)^{3} + cos(6 * t)^{9})
if(missing(response))
type = "classification"
response = match.arg(response)
if(missing(n)) n = 200
if(missing(p)) p = 10
if(missing(rho)) rho = 0.5
if(p <= 5) stop("dimension size should be larger than 5.")
Sigma = matrix(rho, 5, 5)
diag(Sigma) = 1
x_sig = pnorm(rmvnorm(n, sigma = Sigma))
x_nois = matrix(pnorm(rnorm(n * (p-5))), n, p-5)
x = cbind(x_sig, x_nois)
# Set the outer margins
# par(oma = c(0, 0, 0, 0))
# Set the inner margin
# par(mar = c(4, 4, 3, 1))
# par(mfrow = c(1,5))
# plot(x[,1], f1(x[,1]), cex = .6, pch = 16, xlab = 'x1', ylab = 'f1')
# plot(x[,2], f2(x[,2]), cex = .6, pch = 16, xlab = 'x2', ylab = 'f2')
# plot(x[,3], f3(x[,3]), cex = .6, pch = 16, xlab = 'x3', ylab = 'f3')
# plot(x[,4], f4(x[,4]), cex = .6, pch = 16, xlab = 'x4', ylab = 'f4')
# plot(x[,5], f5(x[,5]), cex = .6, pch = 16, xlab = 'x5', ylab = 'f5')
# par(mfrow = c(1,1))
f = 5 * f1(x[,1]) + 3 * f2(x[,2]) + 4 * f3(x[,3]) + 6 * f4(x[,4]) + 4 * f5(x[,5])
if(response == "regression"){
f = f + rnorm(n, 0, 1)
out = list(x = x, y = f)
}
if(response == "classification"){
prob = exp(f)/(exp(f) + 1)
y = rbinom(n, 1, prob)
# plot(prob)
# print(table(y))
out = list(x = x, f = f, y = y)
}
if(response == "count"){
mu = exp(f/sqrt(2)/p)
y = rpois(n, mu)
out = list(x = x, f = f, y = y)
}
if(response == 'survival'){
surTime = rexp(n, exp(f))
cenTime = rexp(n, exp(-f) + runif(1, 4, 6))
y = cbind(time = apply(cbind(surTime, cenTime), 1, min), status = 1 * (surTime < cenTime))
out = list(x = x, f = f, y = y)
}
return(out)
}
ll = 0
tr = data_generation(n, p, response = "classification")
tr_x = tr$x
tr_y = tr$y
te = data_generation(te_n, p, response = "classification")
te_x = te$x
te_y = te$y
t1 = system.time({
fit3 = try(cdcosso(tr_x, tr_y, family = 'binomial', gamma = 1, kernel = "spline", scale = F, algo = "QP"), silent = TRUE)
})[3]  # lambda2를 크게 할수록  sparse, gamma를 크게 할수록 sparse
fit3
fit10 = try(cdcosso(tr_x, tr_y, family = 'binomial', gamma = 0.95, kernel = "spline", scale = F, algo = "CD"), silent = TRUE)
fit10
x = tr_x
y = tr_y
family = 'Cox'
gamma = 0.8
kernel = "spline"
one.std = TRUE
scale = T
wt = rep(1, ncol(x))
kparam = 1
nfolds =5
type = 'spline'
algo = "CD"
effect = 'main'
n = length(y)
p = length(wt)
K = make_anovaKernel(x, x, type = type, kparam)
d = K$numK
# solve (theta) - 1st
sspline_cvfit = cv.sspline(K, y, rep(1, p)/wt^2, lambda0, obj, one.std, type, kparam, algo, show = FALSE) ## 초기값 설정. 수정할 함수
lambda0 = exp(seq(log(2^{-22}), log(2^{2}), length.out = 20))
lambda_theta = exp(seq(log(2^{-22}), log(2^{2}), length.out = 20))
# solve (theta) - 1st
sspline_cvfit = cv.sspline(K, y, rep(1, p)/wt^2, lambda0, obj, one.std, type, kparam, algo, show = FALSE) ## 초기값 설정. 수정할 함수
obj="binomial"
# solve (theta) - 1st
sspline_cvfit = cv.sspline(K, y, rep(1, p)/wt^2, lambda0, obj, one.std, type, kparam, algo, show = FALSE) ## 초기값 설정. 수정할 함수
obj=binomial()
# solve (theta) - 1st
sspline_cvfit = cv.sspline(K, y, rep(1, p)/wt^2, lambda0, obj, one.std, type, kparam, algo, show = FALSE) ## 초기값 설정. 수정할 함수
sspline_cvfit
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit, y, wt, sspline_cvfit$optlambda, lambda_theta, gamma, obj, one.std, algo)
model = sspline_cvfit
mscale = wt
lambda0 = sspline_cvfit$optlambda
gamma
algo = "CD"
one.std = F
n = length(y)
d = length(mscale)
# solve theta
G <- matrix(0, nrow(model$R[, ,1]), d)
for (j in 1:d) {
G[, j] = model$R[, , j] %*% model$c.new * (mscale[j]^(-2))
}
Gw = G * sqrt(model$w.new)
uw = model$zw.new - model$b.new * sqrt(model$w.new) - (n/2) * lambda0 * model$cw.new
init.theta = rep(1, d)
len = length(lambda_theta)
measure <- rep(NA, len)
save_theta <- list()
for (k in 1:len) {
if(algo == "CD") {
theta.new = .Call("theta_step", Gw, uw, n, d, init.theta, lambda_theta[k], gamma)
save_theta[[k]] <- theta.new
}
if(algo == "QP") {
theta.new = nng.QP(Gw, uw, theta = init.theta, lambda_theta[k], gamma)
save_theta[[k]] <- theta.new
}
testfhat = c(G %*% theta.new)
testmu = obj$linkinv(testfhat)
XX = model$zw.new - Gw %*% theta.new
num = t(XX) %*% XX
den = (1 - sum(diag( Gw %*% ginv( t(Gw) %*% Gw) %*% t(Gw) )) / n)^2
measure[k] <- as.vector(num / den /n)
}
measure
theta.new
save_theta
c(G %*% theta.new)
measure <- rep(NA, len)
save_theta <- list()
for (k in 1:len) {
if(algo == "CD") {
theta.new = .Call("theta_step", Gw, uw, n, d, init.theta, lambda_theta[k], gamma)
save_theta[[k]] <- theta.new
}
if(algo == "QP") {
theta.new = nng.QP(Gw, uw, theta = init.theta, lambda_theta[k], gamma)
save_theta[[k]] <- theta.new
}
theta.adj = ifelse(theta.new <= 1e-6, 0, theta.new)
XX = model$zw.new - Gw %*% theta.adj
num = t(XX) %*% XX
den = (1 - sum(diag( Gw %*% ginv( t(Gw) %*% Gw) %*% t(Gw) )) / n)^2
measure[k] <- as.vector(num / den /n)
}
measure
save_theta
theta.adj
model$zw.new - Gw %*% theta.adj
t(XX) %*% XX
(1 - sum(diag( Gw %*% ginv( t(Gw) %*% Gw) %*% t(Gw) )) / n)^2
num = t(XX) %*% XX + 1
den = (1 - sum(diag( Gw %*% ginv( t(Gw) %*% Gw) %*% t(Gw) )) / n)^2 + 1
measure[k] <- as.vector(num / den /n)
measure
measure <- rep(NA, len)
save_theta <- list()
for (k in 1:len) {
if(algo == "CD") {
theta.new = .Call("theta_step", Gw, uw, n, d, init.theta, lambda_theta[k], gamma)
save_theta[[k]] <- theta.new
}
if(algo == "QP") {
theta.new = nng.QP(Gw, uw, theta = init.theta, lambda_theta[k], gamma)
save_theta[[k]] <- theta.new
}
theta.adj = ifelse(theta.new <= 1e-6, 0, theta.new)
XX = model$zw.new - Gw %*% theta.adj
num = t(XX) %*% XX + 1
den = (1 - sum(diag( Gw %*% ginv( t(Gw) %*% Gw) %*% t(Gw) )) / n)^2 + 1
measure[k] <- as.vector(num / den /n)
}
measure
cv.sspline = function (K, y, mscale, cand.lambda, obj, one.std, type, kparam, algo, show)
{
cat("-- c-step -- \n")
cat("proceeding... \n")
d = K$numK
n <- length(y)
len = length(cand.lambda)
R = array(NA, c(n, n, d))
for(j in 1:d){
R[, , j] = K$K[[j]]
}
Rtheta <- combine_kernel(R, mscale)
f.init = rep(0.5, n)
measure <- rep(NA, len)
for (k in 1:len) {
if(algo == "CD"){
# initialize
ff = f.init
mu = obj$linkinv(ff)
w = obj$variance(mu)
z = ff + (y - mu) / w
c.init = as.vector(glmnet(Rtheta, y, family = 'gaussian', lambda = cand.lambda[k])$beta)
zw = z * sqrt(w)
Rw = Rtheta * w
cw = c.init / sqrt(w)
sw = sqrt(w)
fit = .Call("c_step", zw, Rw, cw, sw, n, cand.lambda[k], PACKAGE = "cdcosso")
b.new = fit$b.new
c.new = fit$c.new
cw.new = fit$cw.new
}
if(algo == "QP"){
c.init = as.vector(glmnet(Rtheta, y, family = 'gaussian', lambda = cand.lambda[k])$beta)
fit = sspline.QP(Rtheta, y, f.init, cand.lambda[k], obj, c.init)
b.new = fit$b.new
c.new = fit$c.new
cw.new = fit$cw.new
}
if(sum(is.nan(cw.new)) == n){
next
} else{
ff = f.init
mu = obj$linkinv(ff)
w = obj$variance(mu)
Rw = Rtheta * w
# validation
testfhat = c(b.new + Rtheta %*% c.new)
testmu = obj$linkinv(testfhat)
testw = obj$variance(testmu)
XX = fit$zw.new - Rw %*% fit$cw.new - fit$b.new * sqrt(w)
num = t(XX) %*% XX + 1
# den = (1 - sum(diag(Rtheta %*% ginv(Rtheta + diag(w)/cand.lambda[k]))) / n)^2
S = Rw %*% ginv(t(Rw) %*% Rw) %*% t(Rw)
den = (1 - sum(diag(S)) / n)^2 + 1
measure[k] <- as.vector( num / den / n)
}
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
ylab = expression("GCV(" * lambda[0] * ")")
# optimal lambda1
id = which.min(measure)[1]
optlambda = cand.lambda[id]
if(show) plot(log(cand.lambda), measure, main = main, xlab = expression("Log(" * lambda[0] * ")"), ylab = ylab, ylim = range(measure), pch = 15, col = 'red')
if(algo == "CD"){
mu = obj$linkinv(f.init)
w = obj$variance(mu)
z = f.init + (y - mu) / w
c.init = as.vector(glmnet(Rtheta, y, family = 'gaussian', lambda = optlambda)$beta)
zw = z * sqrt(w)
Rw = Rtheta * w
cw = c.init / sqrt(w)
sw = sqrt(w)
fit = .Call("c_step", zw, Rw, cw, sw, n, optlambda, PACKAGE = "cdcosso")
f.new = c(fit$b.new + Rtheta %*% fit$c.new)
mu.new = obj$linkinv(f.new)
w.new = obj$variance(mu.new)
z.new = f.new + (y - mu.new) / w.new
if(obj$family == "binomial") miss <- mean(y != ifelse(mu.new < 0.5, 0, 1))
if(obj$family == "gaussian") miss <- mean((y - f.new)^2)
if(obj$family == "poisson") miss <- mean(poisson()$dev.resids(y, mu.new, rep(1, n)))
cat("training error:", miss, "\n")
out = list(measure = measure, R = R, w.new = w.new, sw.new = sqrt(w.new),
z.new = z.new, zw.new = z.new * sqrt(w.new), b.new = fit$b.new,
cw.new = fit$cw.new, c.new = fit$c.new, optlambda = optlambda, conv = TRUE)
}
if(algo == "QP"){
c.init = as.vector(glmnet(Rtheta, y, family = 'gaussian', lambda = optlambda)$beta)
fit = sspline.QP(Rtheta, y, f.init, optlambda, obj, c.init)
f.new = c(fit$b.new + Rtheta %*% fit$c.new)
mu.new = obj$linkinv(f.new)
w.new = obj$variance(mu.new)
z.new = f.new + (y - mu.new) / w.new
out = list(measure = measure, R = R, w.new = w.new, sw.new = sqrt(w.new),
z.new = z.new, zw.new = z.new * sqrt(w.new), b.new = fit$b.new,
cw.new = fit$cw.new, c.new = fit$c.new, optlambda = optlambda, conv = TRUE)  }
rm(K)
rm(Rtheta)
return(out)
}
sspline.cd = function (R, y, f, lambda0, obj, c.init)
{
n = length(y)
mu = obj$linkinv(f)
# initialize
w = obj$variance(mu)
z = f + (y - mu) / w
b = 0
zw = z * sqrt(w)
Rw = R * w
cw = c.init / sqrt(w)
sw = sqrt(w)
cw.new = rep(0, n)
for(i in 1:10){ # outer iteration
for(j in 1:n){
L = 2 * sum((zw - Rw[,-j] %*% cw[-j] - b * sw) * Rw[,j]) - n * lambda0 * c(Rw[j,-j] %*% cw[-j])
R = 2 * sum(Rw[,j]^2) + n * lambda0 * Rw[j,j]
cw.new[j] = L/R
loss = abs(cw-cw.new)
conv1 = max(loss) < 1e-6
conv2 = min(loss) > 10
if(conv1 | conv2) break
cw[j] = cw.new[j]  # if not convergence
}
if(conv1 | conv2) break
}
if(i == 1 & !conv1) cw.new = cw
cw.new = cw.new
c.new = cw.new * sw
b.new = sum((zw - Rw %*% cw.new) * sw) / sum(sw)
return(list(Rw = Rw, z.new = z, zw.new = zw, w.new = w, sw.new = sw, b.new = b.new, c.new = c.new, cw.new = cw.new))
}
sspline.QP = function (R, y, f, lambda0, obj, c.init)
{
n = length(y)
mu = obj$linkinv(f)
# initialize
w = obj$variance(mu)
z = f + (y - mu) / w
b = 0
zw = z * sqrt(w)
Rw = R * w
cw = c.init / sqrt(w)
sw = sqrt(w)
cw.new = rep(0, n)
for(i in 1:10){ # outer iteration
Dmat = t(R) %*% R + n * lambda0 * R
dvec = as.vector(t(zw - b * sw) %*% R)
cw.new = ginv(Dmat) %*% dvec
loss = abs(cw-cw.new)
conv = max(loss) < 1e-6
if(conv) break
cw = cw.new  # if not convergence
}
cw.new = cw.new
c.new = cw.new * sw
b.new = sum((zw - Rw %*% cw.new) * sw) / sum(sw)
return(list(Rw = Rw, z.new = z, zw.new = zw, w.new = w, sw.new = sw, b.new = b.new, c.new = c.new, cw.new = cw.new))
}
cv.nng = function(model, y, mscale, lambda0, lambda_theta, gamma, obj, one.std, algo)
{
cat("-- theta-step -- \n")
cat("proceeding... \n")
n = length(y)
d = length(mscale)
# solve theta
G <- matrix(0, nrow(model$R[, ,1]), d)
for (j in 1:d) {
G[, j] = model$R[, , j] %*% model$c.new * (mscale[j]^(-2))
}
Gw = G * sqrt(model$w.new)
uw = model$zw.new - model$b.new * sqrt(model$w.new) - (n/2) * lambda0 * model$cw.new
init.theta = rep(1, d)
if(algo == "QP") lambda_theta = exp(seq(log(1e-4), log(40), length.out = length(lambda_theta)))
len = length(lambda_theta)
measure <- rep(NA, len)
save_theta <- list()
for (k in 1:len) {
if(algo == "CD") {
theta.new = .Call("theta_step", Gw, uw, n, d, init.theta, lambda_theta[k], gamma)
save_theta[[k]] <- theta.new
}
if(algo == "QP") {
theta.new = nng.QP(Gw, uw, theta = init.theta, lambda_theta[k], gamma)
save_theta[[k]] <- theta.new
}
theta.adj = ifelse(theta.new <= 1e-6, 0, theta.new)
XX = model$zw.new - Gw %*% theta.adj
num = t(XX) %*% XX + 1
den = (1 - sum(diag( Gw %*% ginv( t(Gw) %*% Gw) %*% t(Gw) )) / n)^2 + 1
measure[k] <- as.vector(num / den /n)
}
# plotting error bar
if(obj$family == 'gaussian'){
main = "Gaussian Family"
}
if(obj$family == 'binomial'){
main = "Binomial Family"
}
if(obj$family == 'poisson'){
main = "Poisson Family"
}
id = which.min(measure)[1]
optlambda = lambda_theta[id]
ylab = expression("GCV(" * lambda[theta] * ")")
xrange = log(lambda_theta)
plot(xrange, measure, main = main, xlab = expression("Log(" * lambda[theta] * ")"), ylab = ylab, ylim = range(measure), pch = 15, col = 'red')
if(algo == "CD"){
print(save_theta)
theta.new = save_theta[[id]]
theta.adj = ifelse(theta.new <= 1e-6, 0, theta.new)
f.new = c(G %*% theta.adj)
mu.new = obj$linkinv(f.new)
if(obj$family == "binomial") miss <- mean(y != ifelse(mu.new < 0.5, 0, 1))
if(obj$family == "gaussian") miss <- mean((y - f.new)^2)
if(obj$family == "poisson") miss <- mean(poisson()$dev.resids(y, mu.new, rep(1, n)))
cat("training error:", miss, "\n")
}
if(algo == "QP"){
theta.new = save_theta[[id]]
}
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new)
return(out)
}
nng.cd = function (Gw, uw, theta, lambda_theta, gamma)
{
n = nrow(Gw)
d = ncol(Gw)
r = lambda_theta * gamma * n
theta.new = rep(0, d)
for(i in 1:10){
for(j in 1:d){
theta.new[j] = 2 * sum((uw - Gw[,-j] %*% theta[-j]) * Gw[,j])
theta.new[j] = ifelse(theta.new[j] > 0 & r < abs(theta.new[j]), theta.new[j], 0)
theta.new[j] = theta.new[j] / (sum(Gw[,j]^2) + n * lambda_theta * (1-gamma)) / 2
loss = abs(theta - theta.new)
conv = max(loss) < 1e-20
if(conv) break
theta[j] = theta.new[j]
}
if(conv) break
}
if(i == 1 & !conv) theta = rep(0, d)
return(theta)
}
nng.QP = function (Gw, uw, theta, lambda_theta, gamma)
{
n = nrow(Gw)
d = ncol(Gw)
r = lambda_theta * gamma * n
theta.new = rep(0, d)
for(i in 1:10){ # outer iteration
Dmat = t(Gw) %*% Gw + diag(n * lambda_theta * gamma, d)
dvec = as.vector(2 * t(uw) %*% Gw)
Amat = t(rbind(diag(1, d), rep(-1, d)))
bvec = c(rep(0, d), -lambda_theta)
theta.new = solve.QP(2 * Dmat, dvec, Amat, bvec)$solution
theta.new[theta.new < 1e-8] = 0
loss = abs(theta - theta.new)
conv = max(loss) < 1e-8
if(conv) break
theta = theta.new
}
return(theta.new)
}
# solve (theta) - 1st
sspline_cvfit = cv.sspline(K, y, rep(1, p)/wt^2, lambda0, obj, one.std, type, kparam, algo, show = FALSE) ## 초기값 설정. 수정할 함수
# solve (theta) - 1st
sspline_cvfit = cv.sspline(K, y, rep(1, p)/wt^2, lambda0, obj, one.std, type, kparam, algo, show = TRUE) ## 초기값 설정. 수정할 함수
lambda0 = exp(seq(log(2^{-22}), log(2^{2}), length.out = 20))
# solve (theta) - 1st
sspline_cvfit = cv.sspline(K, y, rep(1, p)/wt^2, lambda0, obj, one.std, type, kparam, algo, show = TRUE) ## 초기값 설정. 수정할 함수
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit, y, wt, sspline_cvfit$optlambda, lambda_theta, gamma, obj, one.std, algo)
nng_fit
# solve (theta) - 1st
sspline_cvfit = cv.sspline(K, y, rep(1, p)/wt^2, lambda0, obj, one.std, type, kparam, algo, show = TRUE) ## 초기값 설정. 수정할 함수
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit, y, wt, sspline_cvfit$optlambda, lambda_theta, gamma, obj, one.std, algo)
