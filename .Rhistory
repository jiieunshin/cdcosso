#' @param n The number of observation of a example dataset.
#' @param p Dimension of a example dataset.
#' @param rho Correlation for first five significance variables.
#' @param response Type of response variable.
#'
#' @return a list containing the predicted value for the test data (f.new) and the transformed value of that predicted value (mu.new).
#' @export
data_generation = function(n, p, rho,
response = c("regression", "classification", "count", "survival", "interaction")){
f1 = function(t) t - 0.5
f2 = function(t) (2 * t - 1)^2 - 0.4
f3 = function(t) sin(2 * pi * t) / (2 - sin(pi * t))
f4 = function(t) 0.1*sin(2 * pi * t) + 0.2*cos(2 * pi * t) + 0.3*sin(2 * pi * t)^2 + 0.4*cos(2 * pi * t)^2 + 0.5*sin(2 * pi * t)^3 - 0.4
f5 = function(t) sin(pi * t^4) + t^4 - 0.4
if(missing(response))
type = "classification"
response = match.arg(response)
if(missing(n)) n = 200
if(missing(p)) p = 10
if(missing(rho)) rho = 0.5
if(p <= 5) stop("dimension size should be larger than 5.")
Sigma = matrix(rho, 5, 5)
diag(Sigma) = 1
x_sig = rmvnorm(n, sigma = Sigma)
x_nois = matrix(rnorm(n * (p-5)), n, p-5)
x = cbind(x_sig, x_nois)
x = apply(x, 2, pnorm)
# Set the outer margins
# par(oma = c(0, 0, 0, 0))
# Set the inner margin
# par(mar = c(4, 4, 3, 1))
# par(mfrow = c(1,5))
# plot(x[,1], f1(x[,1]), cex = .6, pch = 16, xlab = 'x1', ylab = 'f1')
# plot(x[,2], f2(x[,2]), cex = .6, pch = 16, xlab = 'x2', ylab = 'f2')
# plot(x[,3], f3(x[,3]), cex = .6, pch = 16, xlab = 'x3', ylab = 'f3')
# plot(x[,4], f4(x[,4]), cex = .6, pch = 16, xlab = 'x4', ylab = 'f4')
# plot(x[,5], f5(x[,5]), cex = .6, pch = 16, xlab = 'x5', ylab = 'f5')
# par(mfrow = c(1,1))
f = 5 * f1(x[,1]) + 2 * f2(x[,2]) + 3 * f3(x[,3]) + 6 * f4(x[,4]) + 4 * f5(x[,5])
# f = 5 * f1(x[,1]) + 4 * ((3 * x[, 2] - 2)^2 - 1) + 6 * f5(x[, 3]) + 2 * f4(x[, 4]) + 2 * f3(x[, 5])
if(response == "regression"){
f = f + rnorm(n, 0, 1)
out = list(x = x, y = f)
}
if(response == "classification"){
prob = exp(f)/(exp(f) + 1)
y = rbinom(n, 1, prob)
# plot(prob)
# print(table(y))
out = list(x = x, f = f, y = y)
}
if(response == "count"){
mu = exp(f/sqrt(2)/p)
y = rpois(n, mu)
out = list(x = x, f = f, y = y)
}
if(response == 'survival'){
# Sigma = matrix(1, 8, 8)
# for(j in 1:8){
#   for(k in 1:8){
#     Sigma[j, k] = rho^abs(j-k)
#   }
# }
# x_sig = rtmvnorm(n, mean = rep(0, 8), sigma = Sigma, lower = rep(-2, 8), upper = rep(2, 8))
# x_nois = rtmvnorm(n, mean = rep(0, p-8), sigma = diag(1, p-8, p-8), lower = rep(-2, p-8), upper = rep(2, p-8))
# x = cbind(x_sig, x_nois)
Sigma = matrix(1, 5, 5)
for(j in 1:5){
for(k in 1:5){
Sigma[j, k] = rho^abs(j-k)
}
}
x_sig = rtmvnorm(n, mean = rep(0, 5), sigma = Sigma, lower = rep(-2, 5), upper = rep(2, 5))
x_nois = rtmvnorm(n, mean = rep(0, p-5), sigma = diag(1, p-5, p-5), lower = rep(-2, p-5), upper = rep(2, p-5))
x = cbind(x_sig, x_nois)
x = apply(x, 2, rescale)
f6 = function(t) cos(2 * pi * t) + sin(pi * t)
f = 3 * (3 * x[, 1] - 2)^2 + 8 * cos((3 * x[, 4] - 1.5) * pi / 5) + ifelse(x[, 5] < 0.5, 0, 1) + 2 * f6(x[, 2]) + 13 * exp(x[, 3])
surTime = rexp(n, exp(f))
cenTime = rexp(n, exp(-f) * runif(1, 4, 6))
y = cbind(time = apply(cbind(surTime, cenTime), 1, min), status = 1 * (surTime < cenTime))
# mean(te_y[,"status"])
out = list(x = x, f = f, y = y)
}
return(out)
}
tr = data_generation(n, p, response = "survival")
tr_x = tr$x
tr_y = tr$y
fit10 = try(cdcosso(tr_x, tr_y, family = 'Cox', gamma = 0.95, kernel = "spline", scale = T, algo = "CD",
lambda0 = exp(seq(log(2^{-10}), log(2^{10}), length.out = 20)),
lambda_theta = exp(seq(log(2^{-10}), log(2^{10}), length.out = 20))
), silent = TRUE)
fit10
getc.cd = function(R, Rtheta, mscale, f, c.init, time, status, lambda0, Risk)
{
n = ncol(Rtheta)
# wz = calculate_wz_for_c(c.init, Rtheta, time, status, Risk)
# w = wz$weight
# z = wz$z
# return(list(zw.new = zw, w.new = w, sw.new = sw, b.new = b.new, c.new = c.new, cw.new = cw.new))
c.old = c.init
c.new = rep(0, n)
GH = try(cosso::gradient.Hessian.C(c.old, R, R, time, status, mscale, lambda0, Risk), silent = TRUE)
err = (class(GH) == "try-error") | sum(is.nan(GH$Gradient)) > 0
# while (loop < 15 & iter.diff > 1e-4) {
for(i in 1:1){ # outer iteration
if(err) break
# 2 * n * lambda0 * Rtheta2
Hess = GH$Hessian - 2 * lambda0 * Rtheta
Grad = GH$Gradient - 2 * lambda0 * Rtheta %*% c.old
W = ginv(Hess)
z = (Hess %*% c.old - Grad) / lambda0
for(j in 1:n){
V1 = t(z - Rtheta[ ,-j] %*% c.old[-j]) %*% t(W) %*% Rtheta[, j]
V2 = (Rtheta[j, -j] %*% c.old[-j]) / lambda0
V3 = t(Rtheta[, j]) %*% (t(W) %*% Rtheta[, j])
V4 = Rtheta[j, j] / lambda0
c.new[j] = (V1 - V2) / (V3 + V4)
loss = abs(c.old - c.new)
conv1 = min(loss[loss > 0]) < 1e-20
conv2 = abs(c.old[j] - c.new[j]) > 5
conv3 = sum(exp(Rtheta %*% c.new) == Inf) > 0
# cat("i = ", i, "j = ", j, "loss =", max(loss),  "\n")
if(conv1 | conv2 | conv3) break
c.old[j] = c.new[j]  # if not convergence
}
if(conv1 | conv2 | conv3) break
}
if(i == 1 & (conv1 | conv2 | conv3)) c.new = c.init
print(i)
# zw = z * sqrt(w)
# Rw = Rtheta * w
# cw = c.init
# cw.new = temp = c.init / sqrt(w)
# sw = sqrt(w)
# fit = .Call("cox_c_step", zw, Rw, cw, sw, n, lambda0, PACKAGE = "cdcosso")
# b.new = fit$b.new
# c.new = fit$c.new
# cw.new = fit$cw.new
# z = (Hess %*% c.new - Grad) / lambda0
# loglik = t(z - Rtheta %*% c.new) %*% W %*% (z - Rtheta %*% c.new)
# den = (1 - sum(diag(Rtheta %*% ginv(Rtheta + Hess/lambda0))) / n)^2
# GCV = as.numeric(loglik / den / n)
# print(i)
UHU = Rtheta %*% My_solve(GH$H, t(Rtheta))
ACV_pen = sum(status == 1)/n^2 * (sum(diag(UHU))/(n - 1) - sum(UHU)/(n^2 - n))
ACV = PartialLik(time, status, Risk, Rtheta %*% c.new) + ACV_pen
return(list(z.new = z, w.new = W, c.new = c.new, ACV = ACV, ACV_pen = ACV_pen))
# return(list(z.new = z, zw.new = zw, w.new = w, c.new = c.new, b.new = b.new, cw.new = cw.new, GCV = GCV))
}
fit10 = try(cdcosso(tr_x, tr_y, family = 'Cox', gamma = 0.95, kernel = "spline", scale = T, algo = "CD",
lambda0 = exp(seq(log(2^{-10}), log(2^{10}), length.out = 20)),
lambda_theta = exp(seq(log(2^{-10}), log(2^{10}), length.out = 20))
), silent = TRUE)
fit10
#' and generates a predicted value for the test data.
#' This function uses the given test data to calculate predictions from the weights and biases generated by the model.
#'
#' @param n The number of observation of a example dataset.
#' @param p Dimension of a example dataset.
#' @param rho Correlation for first five significance variables.
#' @param response Type of response variable.
#'
#' @return a list containing the predicted value for the test data (f.new) and the transformed value of that predicted value (mu.new).
#' @export
data_generation = function(n, p, rho,
response = c("regression", "classification", "count", "survival", "interaction")){
f1 = function(t) t - 0.5
f2 = function(t) (2 * t - 1)^2 - 0.4
f3 = function(t) sin(2 * pi * t) / (2 - sin(pi * t))
f4 = function(t) 0.1*sin(2 * pi * t) + 0.2*cos(2 * pi * t) + 0.3*sin(2 * pi * t)^2 + 0.4*cos(2 * pi * t)^2 + 0.5*sin(2 * pi * t)^3 - 0.4
f5 = function(t) sin(pi * t^4) + t^4 - 0.4
if(missing(response))
type = "classification"
response = match.arg(response)
if(missing(n)) n = 200
if(missing(p)) p = 10
if(missing(rho)) rho = 0.5
if(p <= 5) stop("dimension size should be larger than 5.")
Sigma = matrix(rho, 5, 5)
diag(Sigma) = 1
x_sig = rmvnorm(n, sigma = Sigma)
x_nois = matrix(rnorm(n * (p-5)), n, p-5)
x = cbind(x_sig, x_nois)
x = apply(x, 2, pnorm)
# Set the outer margins
# par(oma = c(0, 0, 0, 0))
# Set the inner margin
# par(mar = c(4, 4, 3, 1))
# par(mfrow = c(1,5))
# plot(x[,1], f1(x[,1]), cex = .6, pch = 16, xlab = 'x1', ylab = 'f1')
# plot(x[,2], f2(x[,2]), cex = .6, pch = 16, xlab = 'x2', ylab = 'f2')
# plot(x[,3], f3(x[,3]), cex = .6, pch = 16, xlab = 'x3', ylab = 'f3')
# plot(x[,4], f4(x[,4]), cex = .6, pch = 16, xlab = 'x4', ylab = 'f4')
# plot(x[,5], f5(x[,5]), cex = .6, pch = 16, xlab = 'x5', ylab = 'f5')
# par(mfrow = c(1,1))
f = 5 * f1(x[,1]) + 2 * f2(x[,2]) + 3 * f3(x[,3]) + 6 * f4(x[,4]) + 4 * f5(x[,5])
# f = 5 * f1(x[,1]) + 4 * ((3 * x[, 2] - 2)^2 - 1) + 6 * f5(x[, 3]) + 2 * f4(x[, 4]) + 2 * f3(x[, 5])
if(response == "regression"){
f = f + rnorm(n, 0, 1)
out = list(x = x, y = f)
}
if(response == "classification"){
prob = exp(f)/(exp(f) + 1)
y = rbinom(n, 1, prob)
# plot(prob)
# print(table(y))
out = list(x = x, f = f, y = y)
}
if(response == "count"){
mu = exp(f/sqrt(2)/p)
y = rpois(n, mu)
out = list(x = x, f = f, y = y)
}
if(response == 'survival'){
# Sigma = matrix(1, 8, 8)
# for(j in 1:8){
#   for(k in 1:8){
#     Sigma[j, k] = rho^abs(j-k)
#   }
# }
# x_sig = rtmvnorm(n, mean = rep(0, 8), sigma = Sigma, lower = rep(-2, 8), upper = rep(2, 8))
# x_nois = rtmvnorm(n, mean = rep(0, p-8), sigma = diag(1, p-8, p-8), lower = rep(-2, p-8), upper = rep(2, p-8))
# x = cbind(x_sig, x_nois)
Sigma = matrix(1, 5, 5)
for(j in 1:5){
for(k in 1:5){
Sigma[j, k] = rho^abs(j-k)
}
}
x_sig = rtmvnorm(n, mean = rep(0, 5), sigma = Sigma, lower = rep(-2, 5), upper = rep(2, 5))
x_nois = rtmvnorm(n, mean = rep(0, p-5), sigma = diag(1, p-5, p-5), lower = rep(-2, p-5), upper = rep(2, p-5))
x = cbind(x_sig, x_nois)
x = apply(x, 2, rescale)
f6 = function(t) cos(2 * pi * t) + sin(pi * t)
f = 3 * (3 * x[, 1] - 2)^2 + 8 * cos((3 * x[, 4] - 1.5) * pi / 5) + ifelse(x[, 5] < 0.5, 0, 1) + 2 * f6(x[, 2]) + 14 * exp(x[, 3])
surTime = rexp(n, exp(f))
cenTime = rexp(n, exp(-f) * runif(1, 4, 6))
y = cbind(time = apply(cbind(surTime, cenTime), 1, min), status = 1 * (surTime < cenTime))
# mean(te_y[,"status"])
out = list(x = x, f = f, y = y)
}
return(out)
}
tr = data_generation(n, p, response = "survival")
tr_x = tr$x
tr_y = tr$y
fit10 = try(cdcosso(tr_x, tr_y, family = 'Cox', gamma = 0.95, kernel = "spline", scale = T, algo = "CD",
lambda0 = exp(seq(log(2^{-10}), log(2^{10}), length.out = 20)),
lambda_theta = exp(seq(log(2^{-10}), log(2^{10}), length.out = 20))
), silent = TRUE)
fit10
#' and generates a predicted value for the test data.
#' This function uses the given test data to calculate predictions from the weights and biases generated by the model.
#'
#' @param n The number of observation of a example dataset.
#' @param p Dimension of a example dataset.
#' @param rho Correlation for first five significance variables.
#' @param response Type of response variable.
#'
#' @return a list containing the predicted value for the test data (f.new) and the transformed value of that predicted value (mu.new).
#' @export
data_generation = function(n, p, rho,
response = c("regression", "classification", "count", "survival", "interaction")){
f1 = function(t) t - 0.5
f2 = function(t) (2 * t - 1)^2 - 0.4
f3 = function(t) sin(2 * pi * t) / (2 - sin(pi * t))
f4 = function(t) 0.1*sin(2 * pi * t) + 0.2*cos(2 * pi * t) + 0.3*sin(2 * pi * t)^2 + 0.4*cos(2 * pi * t)^2 + 0.5*sin(2 * pi * t)^3 - 0.4
f5 = function(t) sin(pi * t^4) + t^4 - 0.4
if(missing(response))
type = "classification"
response = match.arg(response)
if(missing(n)) n = 200
if(missing(p)) p = 10
if(missing(rho)) rho = 0.5
if(p <= 5) stop("dimension size should be larger than 5.")
Sigma = matrix(rho, 5, 5)
diag(Sigma) = 1
x_sig = rmvnorm(n, sigma = Sigma)
x_nois = matrix(rnorm(n * (p-5)), n, p-5)
x = cbind(x_sig, x_nois)
x = apply(x, 2, pnorm)
# Set the outer margins
# par(oma = c(0, 0, 0, 0))
# Set the inner margin
# par(mar = c(4, 4, 3, 1))
# par(mfrow = c(1,5))
# plot(x[,1], f1(x[,1]), cex = .6, pch = 16, xlab = 'x1', ylab = 'f1')
# plot(x[,2], f2(x[,2]), cex = .6, pch = 16, xlab = 'x2', ylab = 'f2')
# plot(x[,3], f3(x[,3]), cex = .6, pch = 16, xlab = 'x3', ylab = 'f3')
# plot(x[,4], f4(x[,4]), cex = .6, pch = 16, xlab = 'x4', ylab = 'f4')
# plot(x[,5], f5(x[,5]), cex = .6, pch = 16, xlab = 'x5', ylab = 'f5')
# par(mfrow = c(1,1))
f = 5 * f1(x[,1]) + 2 * f2(x[,2]) + 3 * f3(x[,3]) + 6 * f4(x[,4]) + 4 * f5(x[,5])
# f = 5 * f1(x[,1]) + 4 * ((3 * x[, 2] - 2)^2 - 1) + 6 * f5(x[, 3]) + 2 * f4(x[, 4]) + 2 * f3(x[, 5])
if(response == "regression"){
f = f + rnorm(n, 0, 1)
out = list(x = x, y = f)
}
if(response == "classification"){
prob = exp(f)/(exp(f) + 1)
y = rbinom(n, 1, prob)
# plot(prob)
# print(table(y))
out = list(x = x, f = f, y = y)
}
if(response == "count"){
mu = exp(f/sqrt(2)/p)
y = rpois(n, mu)
out = list(x = x, f = f, y = y)
}
if(response == 'survival'){
# Sigma = matrix(1, 8, 8)
# for(j in 1:8){
#   for(k in 1:8){
#     Sigma[j, k] = rho^abs(j-k)
#   }
# }
# x_sig = rtmvnorm(n, mean = rep(0, 8), sigma = Sigma, lower = rep(-2, 8), upper = rep(2, 8))
# x_nois = rtmvnorm(n, mean = rep(0, p-8), sigma = diag(1, p-8, p-8), lower = rep(-2, p-8), upper = rep(2, p-8))
# x = cbind(x_sig, x_nois)
Sigma = matrix(1, 5, 5)
for(j in 1:5){
for(k in 1:5){
Sigma[j, k] = rho^abs(j-k)
}
}
x_sig = rtmvnorm(n, mean = rep(0, 5), sigma = Sigma, lower = rep(-2, 5), upper = rep(2, 5))
x_nois = rtmvnorm(n, mean = rep(0, p-5), sigma = diag(1, p-5, p-5), lower = rep(-2, p-5), upper = rep(2, p-5))
x = cbind(x_sig, x_nois)
x = apply(x, 2, rescale)
f6 = function(t) cos(2 * pi * t) + sin(pi * t)
f = 3 * (3 * x[, 1] - 2)^2 + 8 * cos((3 * x[, 4] - 1.5) * pi / 5) + ifelse(x[, 5] < 0.5, 0, 1) + 2 * f6(x[, 2]) + 13 * exp(x[, 3])
surTime = rexp(n, exp(f))
cenTime = rexp(n, exp(-f) * runif(1, 4, 6))
y = cbind(time = apply(cbind(surTime, cenTime), 1, min), status = 1 * (surTime < cenTime))
# mean(te_y[,"status"])
out = list(x = x, f = f, y = y)
}
return(out)
}
remove.packages("cdcosso")
devtools::install_github("jiieunshin/cdcosso")
out = matrix(0, 24, 13)
colnames(out) = c("n", "p", "method", "tp", "tp_se", "fp", "fp_se", "f1", "f1_se", "miss", "miss_se", "time", "time_se")
out = data.frame(out)
i=1
ll = 0
p = 100
# cat("\n iteration :", i, "\n")
set.seed(i)
tr = data_generation(n, p, response = "survival")
devtools::install_github("jiieunshin/cdcosso")
remove.packages("cdcosso")
devtools::install_github("jiieunshin/cdcosso")
library(cdcosso)
library(tmvtnorm)
library(glmnet)
library(cosso)
n = 200
te_n = 1000
p_sig = 5
p = 100
out = matrix(0, 24, 13)
colnames(out) = c("n", "p", "method", "tp", "tp_se", "fp", "fp_se", "f1", "f1_se", "miss", "miss_se", "time", "time_se")
out = data.frame(out)
i=1
ll = 0
tr = data_generation(n, p, response = "survival")
tr_x = tr$x
tr_y = tr$y
fit10 = try(cdcosso(tr_x, tr_y, family = 'Cox', gamma = 0.95, kernel = "spline", scale = T, algo = "CD",
lambda0 = exp(seq(log(2^{-10}), log(2^{10}), length.out = 20)),
lambda_theta = exp(seq(log(2^{-10}), log(2^{10}), length.out = 20))
), silent = TRUE)
fit10
out = matrix(0, 24, 13)
colnames(out) = c("n", "p", "method", "tp", "tp_se", "fp", "fp_se", "f1", "f1_se", "miss", "miss_se", "time", "time_se")
out = data.frame(out)
i=1
ll = 0
for(n in c(100, 200, 400)){
for(p in c(25, 50, 100)){ # signal 10%, 5%, 1%, 0.5%
# for(nb in c(12, 25, 50, 100)){
iter = 10
ll = ll + 1
en3_signal_varsel = en1_signal_varsel = matrix(0, iter, p_sig)
time3 = time10 = c()
en3_varsel = en1_varsel = c()
en3_tp = en3_fp = en1_tp = en1_fp = en3_f1 = en1_f1 = en3_rec = en1_rec = en3_pre = en1_pre = c()
en3_miss = en1_miss = c()
en3_time = en1_time = c()
# cat("----------------- \n")
for(i in 1:iter){
# cat("\n iteration :", i, "\n")
set.seed(i)
tr = data_generation(n, p, response = "survival")
tr_x = tr$x
tr_y = tr$y
te = data_generation(te_n, p, response = "survival")
te_x = te$x
te_y = te$y
# mean(te_y[,"status"])
t1 = system.time({
fit3 = try(cdcosso(tr_x, tr_y, family = 'Cox', gamma = 1, kernel = "spline", scale = T, algo = "CD",
lambda0 = exp(seq(log(2^{-10}), log(2^{10}), length.out = 20)),
lambda_theta = exp(seq(log(2^{-10}), log(2^{10}), length.out = 20))
), silent = TRUE)
})[3]  # lambda2를 크게 할수록  sparse, gamma를 크게 할수록 sparse
# true_var = c(1,0,0,1,0,0,1,0)
if(!(class(fit3) == 'try-error')){
true_var = c(rep(1, p_sig), rep(0, p-p_sig))
# true_var = c(1,0,0,1,0,0,1,0)
en3_signal_varsel[i, ] = ifelse(fit3$theta_step$theta.new[1:p_sig] > 0, 1, 0)
en3_true = ifelse(fit3$theta_step$theta.new > 0, 1, 0)
en3_varsel[i] = sum(en3_true)
en3_tp[i] = metric(true_var, en3_true)$tp
en3_fp[i] = metric(true_var, en3_true)$fp
en3_pre[i] = metric(true_var, en3_true)$precision
en3_rec[i] = metric(true_var, en3_true)$recall
en3_f1[i] = metric(true_var, en3_true)$f1_score
en3_pred = predict.cdcosso(fit3, te_x)
# en3_miss[i] = mean(te_y != ifelse(en3_pred$mu.new < 0.5, 0, 1))
# en3_miss[i] = mean((te_y - en3_pred$f.new)^2)
# en3_miss[i] = mean(-poisson()$dev.resids(te_y, en3_pred$mu.new, rep(1, te_n)))
en3_miss[i] = cosso::PartialLik(fit3$data$time, fit3$data$status, fit3$data$RiskSet, fit3$c_step$f.new)
en3_time[i] = mean(t1)
}
t2 = system.time({
fit10 = try(cdcosso(tr_x, tr_y, family = 'Cox', gamma = 0.95, kernel = "spline", scale = T, algo = "CD",
lambda0 = exp(seq(log(2^{-10}), log(2^{10}), length.out = 20)),
lambda_theta = exp(seq(log(2^{-10}), log(2^{10}), length.out = 20))
), silent = TRUE)
})[3]  # lambda2를 크게 할수록  sparse, gamma를 크게 할수록 sparse
if(!(class(fit10) == 'try-error')){
true_var = c(rep(1, p_sig), rep(0, p-p_sig))
en1_signal_varsel[i, ] = ifelse(fit10$theta_step$theta.new[1:p_sig] > 0, 1, 0)
en1_true = ifelse(fit10$theta_step$theta.new > 0, 1, 0)
en1_varsel[i] = sum(en1_true)
en1_tp[i] = metric(true_var, en1_true)$tp
en1_fp[i] = metric(true_var, en1_true)$fp
en1_pre[i] = metric(true_var, en1_true)$precision
en1_rec[i] = metric(true_var, en1_true)$recall
en1_f1[i] = metric(true_var, en1_true)$f1_score
en1_pred = predict.cdcosso(fit10, te_x)
# en1_miss[i] = mean(te_y != ifelse(en1_pred$mu.new < 0.5, 0, 1))
# en1_miss[i] = mean((te_y - en1_pred$f.new)^2)
# en1_miss[i] = mean(-poisson()$dev.resids(te_y, en1_pred$mu.new, rep(1, te_n)))
en1_miss[i] = cosso::PartialLik(fit10$data$time, fit10$data$status, fit10$data$RiskSet, fit10$c_step$f.new)
en1_time[i] = mean(t2)
}
}
out$n[ll] = n
out$p[ll] = p
out$method[[ll]] = "QP"
out$tp[ll] = round(mean(en3_tp, na.rm = TRUE), 4)
out$tp_se[ll] = round(sd(en3_tp, na.rm = TRUE)/sqrt(sum(!is.na(en3_tp))), 4)
out$fp[ll] = round(mean(en3_fp, na.rm = TRUE), 4)
out$fp_se[ll] = round(sd(en3_fp, na.rm = TRUE)/sqrt(sum(!is.na(en3_fp))), 4)
out$f1[ll] = round(mean(en3_f1, na.rm = TRUE), 4)
out$f1_se[ll] = round(sd(en3_f1, na.rm = TRUE)/sqrt(sum(!is.na(en3_f1))), 4)
out$miss[ll] = round(mean(en3_miss, na.rm = TRUE), 4)
out$miss_se[ll] = round(sd(en3_miss, na.rm = TRUE)/sqrt(sum(!is.na(en3_miss))), 4)
out$time[[ll]] = round(mean(en3_time, na.rm = TRUE), 4)
out$time_se[[ll]] = round(sd(en3_time, na.rm = TRUE)/sqrt(sum(!is.na(en3_time))), 4)
ll = ll + 1
out$n[ll] = n
out$p[ll] = p
out$method[[ll]] = "CD"
out$tp[ll] = round(mean(en1_tp, na.rm = TRUE), 4)
out$tp_se[ll] = round(sd(en1_tp, na.rm = TRUE)/sqrt(sum(!is.na(en1_tp))), 4)
out$fp[ll] = round(mean(en1_fp, na.rm = TRUE), 4)
out$fp_se[ll] = round(sd(en1_fp, na.rm = TRUE)/sqrt(sum(!is.na(en1_fp))), 4)
out$f1[ll] = round(mean(en1_f1, na.rm = TRUE), 4)
out$f1_se[ll] = round(sd(en1_f1, na.rm = TRUE)/sqrt(sum(!is.na(en1_f1))), 4)
out$miss[ll] = round(mean(en1_miss, na.rm = TRUE), 4)
out$miss_se[ll] = round(sd(en1_miss, na.rm = TRUE)/sqrt(sum(!is.na(en1_miss))), 4)
out$time[[ll]] = round(mean(en1_time, na.rm = TRUE), 4)
out$time_se[[ll]] = round(sd(en1_time, na.rm = TRUE)/sqrt(sum(!is.na(en1_time))), 4)
if(i == iter){
print(Sys.time())
cat("\n n :", n, ", p = ", p, "-------------------------- \n")
cat("\n iteration :", i, "\n")
cat('quadratic prog \n')
cat("length :", sum(!is.na(en3_miss)), "\n")
cat("time :", round(mean(en3_time, na.rm = TRUE), 4), "(", round(sd(en3_time, na.rm = TRUE)/sqrt(sum(!is.na(en3_time))), 4), ")", "\n")
cat('varsel :', colSums(en3_signal_varsel), mean(en3_varsel, na.rm = TRUE) ,"(", round(sd(en3_varsel, na.rm = TRUE)/sqrt(iter), 4), ")", "\n")
cat('tp :', round(mean(en3_tp, na.rm = TRUE), 4), "(", round(sd(en3_tp, na.rm = TRUE)/sqrt(sum(!is.na(en3_tp))), 4), ")", "\n")
cat('fp :', round(mean(en3_fp, na.rm = TRUE), 4), "(", round(sd(en3_fp, na.rm = TRUE)/sqrt(sum(!is.na(en3_fp))), 4), ")", "\n")
cat('precis :', round(mean(en3_pre, na.rm = TRUE), 4), "(", round(sd(en3_pre, na.rm = TRUE)/sqrt(sum(!is.na(en3_pre))), 4), ")", "\n")
cat('reccall:', round(mean(en3_rec, na.rm = TRUE), 4), "(", round(sd(en3_rec, na.rm = TRUE)/sqrt(sum(!is.na(en3_rec))), 4), ")", "\n")
cat('f1     :', round(mean(en3_f1, na.rm = TRUE), 4), "(", round(sd(en3_f1, na.rm = TRUE)/sqrt(sum(!is.na(en3_f1))), 4), ")", "\n")
cat('miss   :', round(mean(en3_miss, na.rm = TRUE), 4), "(", round(sd(en3_miss, na.rm = TRUE)/sqrt(sum(!is.na(en3_miss))), 4), ")", "\n")
# cat('time   :', round(mean(time3, na.rm = TRUE), 4), "(", round(sd(time3, na.rm = TRUE)/sqrt(sum(!is.na(time3))), 4), ")", "\n")
cat('coordinate descent \n')
cat("length :", sum(!is.na(en1_miss)), "\n")
cat("time :", round(mean(en1_time, na.rm = TRUE), 4), "(", round(sd(en1_time, na.rm = TRUE)/sqrt(sum(!is.na(en1_time))), 4), ")", "\n")
cat('varsel :', colSums(en1_signal_varsel), mean(en1_varsel, na.rm = TRUE) ,"(", round(sd(en1_varsel, na.rm = TRUE)/sqrt(iter), 4), ")", "\n")
cat('tp :', round(mean(en1_tp, na.rm = TRUE), 4), "(", round(sd(en1_tp, na.rm = TRUE)/sqrt(sum(!is.na(en1_tp))), 4), ")", "\n")
cat('fp :', round(mean(en1_fp, na.rm = TRUE), 4), "(", round(sd(en1_fp, na.rm = TRUE)/sqrt(sum(!is.na(en1_fp))), 4), ")", "\n")
cat('precis :', round(mean(en1_pre, na.rm = TRUE), 4), "(", round(sd(en1_pre, na.rm = TRUE)/sqrt(sum(!is.na(en1_pre))), 4), ")", "\n")
cat('reccall:', round(mean(en1_rec, na.rm = TRUE), 4), "(", round(sd(en1_rec, na.rm = TRUE)/sqrt(sum(!is.na(en1_rec))), 4), ")", "\n")
cat('f1     :', round(mean(en1_f1, na.rm = TRUE), 4), "(", round(sd(en1_f1, na.rm = TRUE)/sqrt(sum(!is.na(en1_f1))), 4), ")", "\n")
cat('miss   :', round(mean(en1_miss, na.rm = TRUE), 4), "(", round(sd(en1_miss, na.rm = TRUE)/sqrt(sum(!is.na(en1_miss))), 4), ")", "\n")
# cat('time   :', round(mean(time10, na.rm = TRUE), 4), "(", round(sd(time10, na.rm = TRUE)/sqrt(sum(!is.na(time10))), 4), ")", "\n")
}
}
}
fit10
en1_f1
out
