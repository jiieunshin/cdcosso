if(missing(response))
type = "classification"
response = match.arg(response)
if(missing(n)) n = 200
if(missing(p)) p = 10
if(missing(rho)) rho = 0.5
if(p <= 5) stop("dimension size should be larger than 5.")
Sigma = matrix(rho, 5, 5)
diag(Sigma) = 1
x_sig = pnorm(rmvnorm(n, sigma = Sigma))
x_nois = matrix(pnorm(rnorm(n * (p-5))), n, p-5)
x = cbind(x_sig, x_nois)
# Set the outer margins
# par(oma = c(0, 0, 0, 0))
# Set the inner margin
# par(mar = c(4, 4, 3, 1))
# par(mfrow = c(1,5))
# plot(x[,1], f1(x[,1]), cex = .6, pch = 16, xlab = 'x1', ylab = 'f1')
# plot(x[,2], f2(x[,2]), cex = .6, pch = 16, xlab = 'x2', ylab = 'f2')
# plot(x[,3], f3(x[,3]), cex = .6, pch = 16, xlab = 'x3', ylab = 'f3')
# plot(x[,4], f4(x[,4]), cex = .6, pch = 16, xlab = 'x4', ylab = 'f4')
# plot(x[,5], f5(x[,5]), cex = .6, pch = 16, xlab = 'x5', ylab = 'f5')
# par(mfrow = c(1,1))
f = 5 * f1(x[,1]) + 6 * f2(x[,2]) + 4 * f3(x[,3]) + 3 * f4(x[,4]) + 4 * f5(x[,5])
if(response == "regression"){
f = f + rnorm(n, 0, 1)
out = list(x = data.frame(x), y = f)
}
if(response == "classification"){
prob = exp(f)/(exp(f) + 1)
y = rbinom(n, 1, prob)
# plot(prob)
# print(table(y))
out = list(x = data.frame(x), f = f, y = y)
}
if(response == "count"){
mu = exp(f/sqrt(2)/p)
y = rpois(n, mu)
out = list(x = data.frame(x), f = f, y = y)
}
if(response == 'survival'){
f = 2 * f1(x[,1]) + 1 * f2(x[,2]) + 3 * f3(x[,3]) + 5 * f4(x[,4]) + 4 * f6(x[,5])
# f = 5 * f1(x[,1]) + 3 * f2(x[,2]) + 2 * f3(x[,3]) + 5 * f4(x[,4]) + 4 * f6(x[,5]) # 잘 된 세팅. 근데 FP구분을 못함
# f = 2 * f1(x[,1]) + 1 * f2(x[,2]) + 5 * f3(x[,3]) + 4 * f4(x[,4]) + 1 * f5(x[,5]) #두 번째 세팅
surTime = rexp(n, (exp(f)))
cenTime = rexp(n, (exp(-f) * runif(1, 8, 10)))
y = cbind(time = apply(cbind(surTime, cenTime), 1, min), status = 1 * (surTime < cenTime))
# mean(y[,"status"])
out = list(x = data.frame(x), f = f, y = y)
}
return(out)
}
#' and generates a predicted value for the test data.
#' This function uses the given test data to calculate predictions from the weights and biases generated by the model.
#'
#' @param n The number of observation of a example dataset.
#' @param p Dimension of a example dataset.
#' @param rho Correlation for first five significance variables.
#' @param response Type of response variable.
#'
#' @return a list containing the predicted value for the test data (f.new) and the transformed value of that predicted value (mu.new).
#' @export
data_generation = function(n, p, rho,
response = c("regression", "classification", "count", "survival", "interaction")){
f1 = function(t) t - 0.5
f2 = function(t) (2 * t - 1)^2 - 0.4
f3 = function(t) sin(2 * pi * t) / (2 - sin(pi * t))
f4 = function(t) 0.1*sin(2 * pi * t) + 0.2*cos(2 * pi * t) + 0.3*sin(2 * pi * t)^2 + 0.4*cos(2 * pi * t)^2 + 0.5*sin(2 * pi * t)^3 - 0.4
f5 = function(t) sin(pi * t^4) + t^4 - 0.4
f6 = function(t) exp(t^2) - 1.5
# f7 = function(t) 4 * cos((3 * t - 1.5) * pi / 5)
# f1 = function(t) 3*t - 1.5
# f2 = function(t) pi * sin(pi * t) - 2
# f3 = function(t) (cos(2 * t) + sin(7 * t)) - 0.5
# f4 = function(t) 2 * t^5 - 0.2
# f5 = function(t) (sin(6 * t)^{3} + cos(6 * t)^{9})
if(missing(response))
type = "classification"
response = match.arg(response)
if(missing(n)) n = 200
if(missing(p)) p = 10
if(missing(rho)) rho = 0.5
if(p <= 5) stop("dimension size should be larger than 5.")
Sigma = matrix(rho, 5, 5)
diag(Sigma) = 1
x_sig = pnorm(rmvnorm(n, sigma = Sigma))
x_nois = matrix(pnorm(rnorm(n * (p-5))), n, p-5)
x = cbind(x_sig, x_nois)
# Set the outer margins
# par(oma = c(0, 0, 0, 0))
# Set the inner margin
# par(mar = c(4, 4, 3, 1))
# par(mfrow = c(1,5))
# plot(x[,1], f1(x[,1]), cex = .6, pch = 16, xlab = 'x1', ylab = 'f1')
# plot(x[,2], f2(x[,2]), cex = .6, pch = 16, xlab = 'x2', ylab = 'f2')
# plot(x[,3], f3(x[,3]), cex = .6, pch = 16, xlab = 'x3', ylab = 'f3')
# plot(x[,4], f4(x[,4]), cex = .6, pch = 16, xlab = 'x4', ylab = 'f4')
# plot(x[,5], f5(x[,5]), cex = .6, pch = 16, xlab = 'x5', ylab = 'f5')
# par(mfrow = c(1,1))
f = 5 * f1(x[,1]) + 2 * f2(x[,2]) + 3 * f3(x[,3]) + 6 * f4(x[,4]) + 4 * f5(x[,5])
if(response == "regression"){
f = f + rnorm(n, 0, 1)
out = list(x = data.frame(x), y = f)
}
if(response == "classification"){
prob = exp(f)/(exp(f) + 1)
y = rbinom(n, 1, prob)
# plot(prob)
# print(table(y))
out = list(x = data.frame(x), f = f, y = y)
}
if(response == "count"){
mu = exp(f/sqrt(2)/p)
y = rpois(n, mu)
out = list(x = data.frame(x), f = f, y = y)
}
if(response == 'survival'){
f = 3 * f1(x[,1]) + 1 * f2(x[,2]) + 2 * f3(x[,3]) + 5 * f4(x[,4]) + 4 * f6(x[,5])
# f = 5 * f1(x[,1]) + 3 * f2(x[,2]) + 2 * f3(x[,3]) + 5 * f4(x[,4]) + 4 * f6(x[,5]) # 잘 된 세팅. 근데 FP구분을 못함
# f = 2 * f1(x[,1]) + 1 * f2(x[,2]) + 5 * f3(x[,3]) + 4 * f4(x[,4]) + 1 * f5(x[,5]) #두 번째 세팅
surTime = rexp(n, (exp(f)))
cenTime = rexp(n, (exp(-f) * runif(1, 8, 10)))
y = cbind(time = apply(cbind(surTime, cenTime), 1, min), status = 1 * (surTime < cenTime))
# mean(y[,"status"])
out = list(x = data.frame(x), f = f, y = y)
}
return(out)
}
out = matrix(0, 18, 13)
colnames(out) = c("n", "p", "method", "tp", "tp_se", "fp", "fp_se", "f1", "f1_se", "miss", "miss_se", "time", "time_se")
out = data.frame(out)
i=1
ll = 0
for(n in c(200, 400)){
for(p in c(25, 50, 100)){ # signal 10%, 5%, 1%, 0.5%
# for(nb in c(12, 25, 50, 100)){
iter = 10
ll = ll + 1
en3_signal_varsel = en1_signal_varsel = matrix(0, iter, p_sig)
time3 = time10 = c()
en3_varsel = en1_varsel = c()
en3_tp = en3_fp = en1_tp = en1_fp = en3_f1 = en1_f1 = en3_rec = en1_rec = en3_pre = en1_pre = c()
en3_miss = en1_miss = c()
en3_time = en1_time = c()
# cat("----------------- \n")
for(i in 1:iter){
# cat("\n iteration :", i, "\n")
set.seed(i)
tr = data_generation(n, p, response = "survival")
tr_x = tr$x
tr_y = tr$y
te = data_generation(te_n, p, response = "survival")
te_x = te$x
te_y = te$y
t1 = system.time({
fit3 = try(cdcosso(tr_x, tr_y, family = 'Cox', gamma = 1, kernel = "spline", scale = T, algo = "QP"), silent = TRUE)
})[3]  # lambda2를 크게 할수록  sparse, gamma를 크게 할수록 sparse
if(!(class(fit3) == 'try-error')){
true_var = c(rep(1, p_sig), rep(0, p-p_sig))
en3_signal_varsel[i, ] = ifelse(fit3$theta_step$theta.new[1:p_sig] > 0, 1, 0)
en3_true = ifelse(fit3$theta_step$theta.new > 0, 1, 0)
en3_varsel[i] = sum(en3_true)
en3_tp[i] = metric(true_var, en3_true)$tp
en3_fp[i] = metric(true_var, en3_true)$fp
en3_pre[i] = metric(true_var, en3_true)$precision
en3_rec[i] = metric(true_var, en3_true)$recall
en3_f1[i] = metric(true_var, en3_true)$f1_score
en3_pred = predict.cdcosso(fit3, te_x)
# en3_miss[i] = mean(te_y != ifelse(en3_pred$mu.new < 0.5, 0, 1))
# en3_miss[i] = mean((te_y - en3_pred$f.new)^2)
# en3_miss[i] = mean(-poisson()$dev.resids(te_y, en3_pred$mu.new, rep(1, te_n)))
en3_miss[i] = cosso::PartialLik(fit3$data$time, fit3$data$status, fit3$data$RistSet, fit3$c_step$f.new)
en3_time[i] = mean(t1)
}
t2 = system.time({
fit10 = try(cdcosso(tr_x, tr_y, family = 'Cox', gamma = 0.95, kernel = "spline", scale = T, algo = "CD"), silent = TRUE)
})[3]  # lambda2를 크게 할수록  sparse, gamma를 크게 할수록 sparse
if(!(class(fit10) == 'try-error')){
true_var = c(rep(1, p_sig), rep(0, p-p_sig))
en1_signal_varsel[i, ] = ifelse(fit10$theta_step$theta.new[1:p_sig] > 0, 1, 0)
en1_true = ifelse(fit10$theta_step$theta.new > 0, 1, 0)
en1_varsel[i] = sum(en1_true)
en1_tp[i] = metric(true_var, en1_true)$tp
en1_fp[i] = metric(true_var, en1_true)$fp
en1_pre[i] = metric(true_var, en1_true)$precision
en1_rec[i] = metric(true_var, en1_true)$recall
en1_f1[i] = metric(true_var, en1_true)$f1_score
en1_pred = predict.cdcosso(fit10, te_x)
# en1_miss[i] = mean(te_y != ifelse(en1_pred$mu.new < 0.5, 0, 1))
# en1_miss[i] = mean((te_y - en1_pred$f.new)^2)
# en1_miss[i] = mean(-poisson()$dev.resids(te_y, en1_pred$mu.new, rep(1, te_n)))
en1_miss[i] = cosso::PartialLik(fit10$data$time, fit10$data$status, fit10$data$RistSet, fit10$c_step$f.new)
en1_time[i] = mean(t2)
}
}
out$n[ll] = n
out$p[ll] = p
out$method[[ll]] = "QP"
out$tp[ll] = round(mean(en3_tp, na.rm = TRUE), 4)
out$tp_se[ll] = round(sd(en3_tp, na.rm = TRUE)/sqrt(sum(!is.na(en3_tp))), 4)
out$fp[ll] = round(mean(en3_fp, na.rm = TRUE), 4)
out$fp_se[ll] = round(sd(en3_fp, na.rm = TRUE)/sqrt(sum(!is.na(en3_fp))), 4)
out$f1[ll] = round(mean(en3_f1, na.rm = TRUE), 4)
out$f1_se[ll] = round(sd(en3_f1, na.rm = TRUE)/sqrt(sum(!is.na(en3_f1))), 4)
out$miss[ll] = round(mean(en3_miss, na.rm = TRUE), 4)
out$miss_se[ll] = round(sd(en3_miss, na.rm = TRUE)/sqrt(sum(!is.na(en3_miss))), 4)
out$time[[ll]] = round(mean(en3_time, na.rm = TRUE), 4)
out$time_se[[ll]] = round(sd(en3_time, na.rm = TRUE)/sqrt(sum(!is.na(en3_time))), 4)
ll = ll + 1
out$n[ll] = n
out$p[ll] = p
out$method[[ll]] = "CD"
out$tp[ll] = round(mean(en1_tp, na.rm = TRUE), 4)
out$tp_se[ll] = round(sd(en1_tp, na.rm = TRUE)/sqrt(sum(!is.na(en1_tp))), 4)
out$fp[ll] = round(mean(en1_fp, na.rm = TRUE), 4)
out$fp_se[ll] = round(sd(en1_fp, na.rm = TRUE)/sqrt(sum(!is.na(en1_fp))), 4)
out$f1[ll] = round(mean(en1_f1, na.rm = TRUE), 4)
out$f1_se[ll] = round(sd(en1_f1, na.rm = TRUE)/sqrt(sum(!is.na(en1_f1))), 4)
out$miss[ll] = round(mean(en1_miss, na.rm = TRUE), 4)
out$miss_se[ll] = round(sd(en1_miss, na.rm = TRUE)/sqrt(sum(!is.na(en1_miss))), 4)
out$time[[ll]] = round(mean(en1_time, na.rm = TRUE), 4)
out$time_se[[ll]] = round(sd(en1_time, na.rm = TRUE)/sqrt(sum(!is.na(en1_time))), 4)
if(i == iter){
print(Sys.time())
cat("\n n :", n, ", p = ", p, "-------------------------- \n")
cat("\n iteration :", i, "\n")
cat('quadratic prog \n')
cat("length :", sum(!is.na(en3_miss)), "\n")
cat("time :", round(mean(en3_time, na.rm = TRUE), 4), "(", round(sd(en3_time, na.rm = TRUE)/sqrt(sum(!is.na(en3_time))), 4), ")", "\n")
cat('varsel :', colSums(en3_signal_varsel), mean(en3_varsel, na.rm = TRUE) ,"(", round(sd(en3_varsel, na.rm = TRUE)/sqrt(iter), 4), ")", "\n")
cat('tp :', round(mean(en3_tp, na.rm = TRUE), 4), "(", round(sd(en3_tp, na.rm = TRUE)/sqrt(sum(!is.na(en3_tp))), 4), ")", "\n")
cat('fp :', round(mean(en3_fp, na.rm = TRUE), 4), "(", round(sd(en3_fp, na.rm = TRUE)/sqrt(sum(!is.na(en3_fp))), 4), ")", "\n")
cat('precis :', round(mean(en3_pre, na.rm = TRUE), 4), "(", round(sd(en3_pre, na.rm = TRUE)/sqrt(sum(!is.na(en3_pre))), 4), ")", "\n")
cat('reccall:', round(mean(en3_rec, na.rm = TRUE), 4), "(", round(sd(en3_rec, na.rm = TRUE)/sqrt(sum(!is.na(en3_rec))), 4), ")", "\n")
cat('f1     :', round(mean(en3_f1, na.rm = TRUE), 4), "(", round(sd(en3_f1, na.rm = TRUE)/sqrt(sum(!is.na(en3_f1))), 4), ")", "\n")
cat('miss   :', round(mean(en3_miss, na.rm = TRUE), 4), "(", round(sd(en3_miss, na.rm = TRUE)/sqrt(sum(!is.na(en3_miss))), 4), ")", "\n")
# cat('time   :', round(mean(time3, na.rm = TRUE), 4), "(", round(sd(time3, na.rm = TRUE)/sqrt(sum(!is.na(time3))), 4), ")", "\n")
cat('coordinate descent \n')
cat("length :", sum(!is.na(en1_miss)), "\n")
cat("time :", round(mean(en1_time, na.rm = TRUE), 4), "(", round(sd(en1_time, na.rm = TRUE)/sqrt(sum(!is.na(en1_time))), 4), ")", "\n")
cat('varsel :', colSums(en1_signal_varsel), mean(en1_varsel, na.rm = TRUE) ,"(", round(sd(en1_varsel, na.rm = TRUE)/sqrt(iter), 4), ")", "\n")
cat('tp :', round(mean(en1_tp, na.rm = TRUE), 4), "(", round(sd(en1_tp, na.rm = TRUE)/sqrt(sum(!is.na(en1_tp))), 4), ")", "\n")
cat('fp :', round(mean(en1_fp, na.rm = TRUE), 4), "(", round(sd(en1_fp, na.rm = TRUE)/sqrt(sum(!is.na(en1_fp))), 4), ")", "\n")
cat('precis :', round(mean(en1_pre, na.rm = TRUE), 4), "(", round(sd(en1_pre, na.rm = TRUE)/sqrt(sum(!is.na(en1_pre))), 4), ")", "\n")
cat('reccall:', round(mean(en1_rec, na.rm = TRUE), 4), "(", round(sd(en1_rec, na.rm = TRUE)/sqrt(sum(!is.na(en1_rec))), 4), ")", "\n")
cat('f1     :', round(mean(en1_f1, na.rm = TRUE), 4), "(", round(sd(en1_f1, na.rm = TRUE)/sqrt(sum(!is.na(en1_f1))), 4), ")", "\n")
cat('miss   :', round(mean(en1_miss, na.rm = TRUE), 4), "(", round(sd(en1_miss, na.rm = TRUE)/sqrt(sum(!is.na(en1_miss))), 4), ")", "\n")
# cat('time   :', round(mean(time10, na.rm = TRUE), 4), "(", round(sd(time10, na.rm = TRUE)/sqrt(sum(!is.na(time10))), 4), ")", "\n")
}
}
}
i
fit3
en3_f1
fit10
RiskSet = function (time, status)
{
uniqTime = sort(unique(time[status == 1]))
RiskSet = matrix(0, ncol = length(uniqTime), nrow = length(time))
for (k in 1:length(uniqTime)) {
risk.id = which(time >= uniqTime[k])
RiskSet[risk.id, k] = risk.id
}
return(RiskSet)
}
# mscale = wt
# cand.lambda = lambda0
cv.getc = function(K, time, status, mscale, cand.lambda, type, kparam, algo, show)
{
d = K$numK
n <- length(time)
len = length(cand.lambda)
R = array(NA, c(n, n, d))
for(j in 1:d){
R[, , j] = K$K[[j]]
}
Rtheta <- combine_kernel(R, mscale)
f.init = rep(0.5, n)
RS = RiskSet(time, status)
measure <- rep(0, length(cand.lambda))
for (k in 1:length(cand.lambda)){
if(algo == "CD"){
c.init = as.vector(glmnet(Rtheta, cbind(time = time, status = status), family = 'cox',
lambda = cand.lambda[k], alpha = 0, standardize = FALSE)$beta)
fit = getc.cd(Rtheta, c.init, time, status, cand.lambda[k], RS)
Rw = Rtheta * fit$w.new
XX = fit$zw.new - Rw %*% fit$cw.new - fit$b.new * sqrt(fit$w.new)
num = t(XX) %*% XX + 1
S = Rw %*% ginv(t(Rw) %*% Rw) %*% t(Rw)
den = (1 - sum(diag(S)) / n)^2 + 1
measure[k] <- as.vector( num / den / n )
# measure[k] <- cosso::PartialLik(time, status, RS, Rtheta %*% fit$c.new)
# W = outer(fit$gradient, fit$gradient)
# UHU = Rtheta %*% W %*% t(Rtheta)
# measure[k] <- cosso::PartialLik(time, status, RS, Rtheta %*% fit$c.new)
# + sum(status == 1)/n^2 * (sum(diag(UHU))/(n - 1) - sum(UHU)/(n^2 - n))
}
if(algo == "QP"){
c.init = as.vector(glmnet(Rtheta, cbind(time = time, status = status), family = 'cox',
lambda = cand.lambda[k], alpha = 0, standardize = FALSE)$beta)
fit = getc.QP(R, Rtheta, c.init, time, status, mscale, cand.lambda[k], RS)
measure[k] <- cosso::PartialLik(time, status, RS, Rtheta %*% fit$c.new) + sum(status == 1)/n^2 * (sum(diag(fit$UHU))/(n - 1) - sum(fit$UHU)/(n^2 - n))
# HH =  fit$H - 2 * cand.lambda[k] * Rtheta
# HHH = ginv(HH/cand.lambda[k] + Rtheta)
# GG = fit$G - 2 * cand.lambda[k] * Rtheta %*% fit$c.new
#
# z = (HHH %*% fit$c.new - GG) / cand.lambda[k]
# num = t(z - Rtheta %*% fit$c.new) %*% ginv(HH) %*% (z - Rtheta %*% fit$c.new)
# S = Rtheta %*% ginv(Rtheta + HH/cand.lambda[k])
# den = (1 - sum(diag(S)) / n)^2 + 1
# measure[k] <- as.vector( num / den / n )
}
}
id = which.min(measure)[1]
optlambda = cand.lambda[id]
# optimal lambda1
if(show) plot(log(cand.lambda), measure, main = "Cox family", xlab = expression("Log(" * lambda[0] * ")"), ylab = "partial likelihood", ylim = range(measure), pch = 15, col = 'red')
if(algo == "CD"){
c.init = as.vector(glmnet(Rtheta, cbind(time = time, status = status), family = 'cox',
lambda = optlambda, alpha = 0, standardize = FALSE)$beta)
fit = getc.cd(Rtheta, c.init, time, status, optlambda, RS)
out = list(measure = measure, R = R, f.new = Rtheta %*% fit$c.new, zw.new = fit$zw.new, w.new = fit$w.new,
b.new = fit$b.new, cw.new = fit$cw.new, c.new = fit$c.new, optlambda = optlambda, conv = TRUE)
}
if(algo == "QP"){
c.init = as.vector(glmnet(Rtheta, cbind(time = time, status = status), family = 'cox',
lambda = optlambda, alpha = 0, standardize = FALSE)$beta)
fit = getc.QP(R, Rtheta, c.init, time, status, mscale, optlambda, RS)
z.new = (fit$H %*% fit$c.new - fit$G)/optlambda
W.new = ginv(fit$H)
w.new = 1/diag(fit$H)
zw.new = z.new * sqrt(w.new)
cw.new = fit$c.new / sqrt(w.new)
b.new = sum((zw.new - Rtheta %*% cw.new) * sqrt(w.new)) / sum(w.new)
out = list(measure = measure, R = R, f.new = Rtheta %*% fit$c.new, W.new = W.new, w.new = w.new, zw.new = zw.new, cw.new = cw.new, c.new = fit$c.new, b.new = b.new,
optlambda = optlambda, conv = TRUE)
}
rm(K)
rm(Rtheta)
return(out)
}
getc.cd = function(Rtheta, c.init, time, status, lambda0, Risk)
{
n = ncol(Rtheta)
wz = calculate_wz_for_c(c.init, Rtheta, time, status, Risk)
w = wz$weight
z = wz$z
b = 0
zw = z * sqrt(w)
Rw = Rtheta * w
cw = c.init
cw.new = temp = c.init / sqrt(w)
sw = sqrt(w)
fit = .Call("c_step", zw, Rw, cw, sw, n, lambda0, PACKAGE = "cdcosso")
b.new = fit$b.new
c.new = fit$c.new
cw.new = fit$cw.new
return(list(Rw = Rw, gradient = wz$gradient, zw.new = zw, w.new = w, sw.new = sw, b.new = b.new, c.new = c.new, cw.new = cw.new))
}
getc.QP = function (R, Rtheta, c.init, time, status, mscale, lambda0, RS)
{
n = length(time)
p = length(mscale)
GH = cosso::gradient.Hessian.C(c.init, R, R, time, status, mscale, lambda0, RS)
c.new = as.numeric(cosso::My_solve(GH$H, GH$H %*% c.init - GH$G))
UHU = Rtheta %*% cosso::My_solve(GH$H, t(Rtheta))
return(list(c.new = c.new, G = GH$G, H = GH$H, UHU = UHU))
}
calculate_wz_for_c = function(c.init, R, time, status, RS){
n = length(time)
Grad.Term = weight = z = rep(0, n)
for (k in 1:n) {
Sum.exp.eta.Grad = Sum.exp.eta.Hess = 0
id = which(RS[k,] > 0)
eta = as.numeric(R[k,] %*% c.init)
exp.eta = exp(eta)
for(r in id){
Sum.exp.eta = sum(exp(R[RS[,r],] %*% c.init))
Sum.exp.eta.Grad = Sum.exp.eta.Grad + exp.eta / Sum.exp.eta # {j in R_i} exp(R_j c)
Sum.exp.eta.Hess = Sum.exp.eta.Hess + ( exp.eta * Sum.exp.eta - exp.eta^2 ) / Sum.exp.eta^2
}
Grad.Term[k] = status[k] - Sum.exp.eta.Grad
weight[k] = Sum.exp.eta.Hess
z[k] = eta + (Grad.Term[k] + 0.1) / (weight[k] + 0.1)
}
return(list(z = z, gradient = Grad.Term, weight = weight))
}
# model = getc_cvfit
# lambda0 = getc_cvfit$optlambda
# mscale = wt
cv.gettheta = function (model, x, time, status, mscale, lambda0, lambda_theta, gamma, type, kparam, algo){
n = length(time)
d = length(mscale)
IDmat = model$IDmat
RS = RiskSet(time, status)
# solve theta
G <- matrix(0, nrow(model$R[, ,1]), d)
for (j in 1:d) {
G[, j] = model$R[, , j] %*% model$c.new * (mscale[j]^(-2))
}
if(algo == "QP") lambda_theta = exp(seq(log(1e-4), log(40), length.out = length(lambda_theta)))
len = length(lambda_theta)
measure <- rep(0, len)
save_theta <- list()
for (k in 1:len) {
if(algo == "CD"){
init.theta = rep(1, d)
Gw = G * sqrt(model$w.new)
uw = model$zw.new - model$b.new * sqrt(model$w.new) - (n/2) * lambda0 * model$cw.new
theta.new = .Call("theta_step", Gw, uw, n, d, init.theta, lambda_theta[k], gamma)
save_theta[[k]] <- theta.new
# fit = gettheta.cd(init.theta, G, time, status, model$b.new, (n/2) * lambda0 * model$cw.new, lambda_theta[k], gamma, RS)
# save_theta[[k]] <- fit$theta.new
theta.adj <- rescale_theta(theta.new)
Gw = G * sqrt(model$w.new)
XX = model$zw.new - Gw %*% theta.adj
num = t(XX) %*% XX + 1
den = (1 - sum(diag( Gw %*% ginv( t(Gw) %*% Gw) %*% t(Gw) )) / n)^2 + 1
measure[k] <- as.vector(num / den / n)
# measure[k] = cosso::PartialLik(time, status, RS, G %*% theta.adj) / (1 - sum(theta.new != 0) / n)^2 / n
# measure[k] <- cosso::PartialLik(time, status, RS, G %*% theta.adj)
}
if(algo == "QP"){
init.theta = rep(1, d)
fit = gettheta.QP(init.theta, model$c.new, G, time, status, lambda0, lambda_theta[k], RS)
save_theta[[k]] <- fit$theta.new
theta.adj <- rescale_theta(fit$theta.new)
measure[k] <- cosso::PartialLik(time, status, RS, G %*% theta.adj) + sum(status == 1)/n^2 * (sum(diag(fit$UHU))/(n - 1) - sum(fit$UHU)/(n^2 - n))
# measure[k] = cosso::PartialLik(time, status, RS, G %*% theta.adj) / (1 - sum(fit$theta.new != 0) / n)^2 / n
}
}
id = which.min(measure)[1]
optlambda = lambda_theta[id]
# plotting error bar
xrange = log(lambda_theta)
plot(xrange, measure, main = "Cox family", xlab = expression("Log(" * lambda[theta] * ")"), ylab = "partial likelihood", ylim = range(measure), pch = 15, col = 'red')
if(algo == "CD"){
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = save_theta[[id]])
# fit = gettheta.cd(init.theta, G, time, status, model$b.new, (n/2) * lambda0 * model$cw.new, optlambda, gamma, RS)
# out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = fit$theta.new)
}
if(algo == "QP"){
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = save_theta[[id]])
# fit = gettheta.QP(init.theta, model$c.new, G, time, status, lambda0, optlambda, RS)
# out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = fit$theta.new)
}
return(out)
}
gettheta.cd = function(init.theta, G, time, status, bhat, const, lambda_theta, gamma, Risk){
n = nrow(G)
d = ncol(G)
r = lambda_theta * gamma * n
wz = calculate_wz_for_theta(init.theta, G, time, status, Risk)
w = wz$weight
z = wz$z
uw = (z * sqrt(w)) - bhat * sqrt(w) - const
Gw = G * sqrt(w)
theta.new = .Call("theta_step", Gw, uw, n, d, init.theta, lambda_theta, gamma)
theta.new = ifelse(theta.new <= 1e-6, 0, theta.new)
return(list(z.new = z, gradient = wz$gradient, w.new = w, theta.new = theta.new))
}
calculate_wz_for_theta = function(init.theta, G, time, status, RS){
n = length(time)
Grad.Term = weight = z = rep(0, n)
for (k in 1:n) {
Sum.exp.eta.Grad = Sum.exp.eta.Hess = 0
id = which(RS[k,] > 0)
eta = as.numeric(G[k,] %*% init.theta)
exp.eta = exp(eta)
for(r in id){
Sum.exp.eta = sum(exp(G[RS[,r],] %*% init.theta))
Sum.exp.eta.Grad = Sum.exp.eta.Grad + exp.eta / Sum.exp.eta # {j in R_i} exp(R_j c)
Sum.exp.eta.Hess = Sum.exp.eta.Hess + ( exp.eta * Sum.exp.eta - exp.eta^2 ) / Sum.exp.eta^2
}
Grad.Term[k] = status[k] - Sum.exp.eta.Grad
weight[k] = Sum.exp.eta.Hess
z[k] = eta + (Grad.Term[k] + 0.1) / (weight[k] + 0.1)
}
return(list(z = z, gradient = Grad.Term, weight = weight))
}
gettheta.QP = function(init.theta, c.hat, G, time, status, lambda0, lambda_theta, Risk){
n = nrow(G)
p = ncol(G)
Hess.FullNumer.unScale = array(NA, dim = c(length(init.theta),
length(init.theta),
n)
)
for (i in 1:n) Hess.FullNumer.unScale[, , i] = G[i, ] %*% t(G[i, ])
loop = 0
iter.diff = Inf
old.Theta = init.theta
while (loop < 15 & iter.diff > 1e-04) {
loop = loop + 1
GH = cosso::gradient.Hessian.Theta(old.Theta, c.hat, G, G,
lambda0, lambda_theta, time, status, Risk, Hess.FullNumer.unScale)
if(min(eigen(GH$H)$value) < 0)
GH$H = GH$H + max(1e-07, 1.5 * abs(min(eigen(GH$H)$value))) * diag(length(old.Theta))
dvec = -(GH$G - GH$H %*% old.Theta)
Amat = t(rbind(diag(p), rep(-1, p)))
bvec = c(rep(0, p), -lambda_theta)
new.Theta = cosso::My_solve.QP(GH$H, dvec, Amat, bvec)
new.Theta[new.Theta < 1e-07] = 0
iter.diff = mean(abs(new.Theta - old.Theta))
old.Theta = new.Theta
}
UHU = G %*% My_solve(GH$H, t(G))
return(list(theta.new = new.Theta, G = GH$G, H = GH$H, UHU = UHU))
}
fit3 = try(cdcosso(tr_x, tr_y, family = 'Cox', gamma = 1, kernel = "spline", scale = T, algo = "QP"), silent = TRUE)
fit3
fit10 = try(cdcosso(tr_x, tr_y, family = 'Cox', gamma = 0.95, kernel = "spline", scale = T, algo = "CD"), silent = TRUE)
fit10
