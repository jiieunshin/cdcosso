# f = f1(x[,1]) + f2(x[,2]) + f3(x[,3]) + f4(x[,4]) + f5(x[,5])
# V_sig = var(f1(x[,1])) + var(f2(x[,2])) + var(f3(x[,3])) + var(f4(x[,4])) + var(f5(x[,5]))
# sd = sqrt(var(f) / SNR)
# print(sd)
x_nois = pnorm(matrix(rnorm(n * (p-5), 0, sd/sqrt(p-5)), n, (p-5)))
x = cbind(x, x_nois)
# Set the outer margins
# par(oma = c(0, 0, 0, 0))
# Set the inner margin
# par(mar = c(4, 4, 3, 1))
# par(mfrow = c(1,5))
# plot(x[,1], f1(x[,1]), cex = .6, pch = 16, xlab = 'x1', ylab = 'f1')
# plot(x[,2], f2(x[,2]), cex = .6, pch = 16, xlab = 'x2', ylab = 'f2')
# plot(x[,3], f3(x[,3]), cex = .6, pch = 16, xlab = 'x3', ylab = 'f3')
# plot(x[,4], f4(x[,4]), cex = .6, pch = 16, xlab = 'x4', ylab = 'f4')
# plot(x[,5], f5(x[,5]), cex = .6, pch = 16, xlab = 'x5', ylab = 'f5')
# par(mfrow = c(1,1))
if(response == "regression"){
out = list(x = x, y = f)
}
if(response == "classification"){
prob = exp(f)/(exp(f) + 1)
y = rbinom(n, 1, prob)
# plot(prob)
# print(table(y))
out = list(x = x, f = f, y = y)
}
if(response == "count"){
# f = f1(x[,1])/2 + f2(x[,2]) + f3(x[,3]) + f4(x[,4])/2 + f5(x[,5])
# V_sig = var(f1(x[,1])) + var(f2(x[,2])) + var(f3(x[,3])) + var(f4(x[,4])) + var(f5(x[,5]))
# sd = sqrt(var(f) / SNR)
# x_nois = pnorm(matrix(rnorm(n * (p-5), 0, sd/sqrt(p-5)), n, (p-5)))
# x = cbind(x, x_nois)
mu = exp(f)
y = rpois(n, mu)
out = list(x = x, f = f, y = y)
}
if(response == 'survival'){
# Sigma = matrix(1, 8, 8)
# for(j in 1:8){
#   for(k in 1:8){
#     Sigma[j, k] = rho^abs(j-k)
#   }
# }
#
# x_sig = rtmvnorm(n, mean = rep(0, 8), sigma = Sigma, lower = rep(-2, 8), upper = rep(2, 8))
# x_nois = rtmvnorm(n, mean = rep(0, p-8), sigma = diag(1, p-8, p-8), lower = rep(-2, p-8), upper = rep(2, p-8))
# x = cbind(x_sig, x_nois)
# x = apply(x, 2, rescale)
# Sigma = matrix(1, 5, 5)
# for(j in 1:5){
#   for(k in 1:5){
#     Sigma[j, k] = rho^abs(j-k)
#   }
# }
#
# x_sig = rtmvnorm(n, mean = rep(0, 5), sigma = Sigma, lower = rep(-2, 5), upper = rep(2, 5))
# x_nois = rtmvnorm(n, mean = rep(0, p-5), sigma = diag(1, p-5, p-5), lower = rep(-2, p-5), upper = rep(2, p-5))
# x = cbind(x_sig, x_nois)
# x = apply(x, 2, rescale)
#
# f6 = function(t) cos(2 * pi * t) + sin(pi * t)
# f = 3 * (3 * x[, 1] - 2)^2 +  7 * cos((3 * x[, 3] - 1.5) * pi / 5) + ifelse(x[, 5] < 0.5, 0, 1) + 1 * f6(x[, 2]) + 11 * (exp(x[, 4]) - 3)
# f = 3 * (3 * x[, 1] - 2)^2 + 8 * cos((3 * x[, 3] - 1.5) * pi / 5) + ifelse(x[, 5] < 0.5, 0, 1) + 2 * f6(x[, 2]) + 11 * (exp(x[, 4]) - 2)
# f = 3 * (3 * x[, 1] - 2)^2 + 8 * cos((3 * x[, 3] - 1.5) * pi / 5) + 9 * (exp(x[, 5]) - 2) + 1 * f6(x[, 2]) + 5 * f4(x[, 4])
# SNR = sqrt(var(f) / 4)
# f = f + rnorm(n, 0, SNR)
surTime = rexp(n, exp(f))
cenTime = rexp(n, exp(-f) * runif(1, 4, 6))
y = cbind(time = apply(cbind(surTime, cenTime), 1, min), status = 1 * (surTime < cenTime))
# 14.003
# mean(tr_y[,"status"])
out = list(x = x, f = f, y = y)
}
return(out)
}
tr = data_generation(n, p, SNR = 8, response = "classification")
tr_x = tr$x
tr_y = tr$y
# table(tr_y)
te = data_generation(te_n, p, SNR = 8, response = "classification")
te_x = te$x
te_y = te$y
t1 = system.time({
fit3 = try(cdcosso(tr_x, tr_y, family = 'binomial', gamma = 1, kernel = "spline", scale = F, algo = "CD"), silent = TRUE)
})[3]  # lambda2를 크게 할수록  sparse, gamma를 크게 할수록 sparse
fit3
d = length(fit3$theta_step$theta.new)
# true_var = c(rep(1, p_sig2, rep(0, d-p_sig2)))
true_var = c(rep(1, p_sig), rep(0, p-p_sig))
en3_signal_varsel[i, ] = ifelse(fit3$theta_step$theta.new[1:p_sig] > 0, 1, 0)
en3_true = ifelse(fit3$theta_step$theta.new > 0, 1, 0)
en3_varsel[i] = sum(en3_true)
en3_tp[i] = metric(true_var, en3_true)$tp
en3_fp[i] = metric(true_var, en3_true)$fp
en3_pre[i] = metric(true_var, en3_true)$precision
en3_rec[i] = metric(true_var, en3_true)$recall
en3_f1[i] = metric(true_var, en3_true)$f1_score
en3_pred = predict.cdcosso(fit3, te_x)
mean(te_y != ifelse(en3_pred$mu.new < 0.5, 0, 1))
predict.cdcosso = function(model, testx)
{
family = model$family
if(family == "gaussian") obj = gaussian()
if(family == "binomial") obj = binomial()
if(family == "poisson") obj = poisson()
tr_n = length(model$data$basis.id)
te_n <- dim(testx)[1]
if(class(testx)[1] == "data.frame") testx = matrix(unlist(testx), nrow = te_n)
testx = apply(testx, 2, rescale)
K = make_anovaKernel(testx, model$data$x, model$data$kernel, model$data$kparam)
d = K$numK
R = array(NA, c(te_n, tr_n, d))
for(j in 1:d){
R[, , j] = K$K[[j]][, model$data$basis.id]
}
Rtheta <- wsGram(R, model$theta_step$theta.new/model$data$wt^2)
f.new = c(Rtheta %*% model$c_step$c.new + model$c_step$b.new)
rm(K)
rm(R)
if(family != "Cox"){
out = list(f.new = f.new, mu.new = obj$linkinv(f.new))
}
if(family == "Cox"){
out = list(K.new = Rtheta, f.new = f.new)
}
return(out)
}
make_kernel = function (x, y, type)
{
n1 <- nrow(x)
n2 <- nrow(y)
d <- ncol(x)
K <- array(0, c(n1, n2, d))
for (j in 1:d) {
K[, , j] <- kernelMatrix(x, y, type)
}
return(K)
}
spline_kernel = function(x, y)
{
x = as.matrix(x)
y = as.matrix(y)
K1x = (x - 1 / 2)
K1y = (y - 1 / 2)
K2x = (K1x^2 - 1 / 12) / 2
K2y = (K1y^2 - 1 / 12) / 2
ax = x %x% matrix(1, 1, nrow(y))
ay = y %x% matrix(1, 1, nrow(x))
b = abs(ax - t(ay))
K1 = K1x %x% t(K1y)
K2 = K2x %x% t(K2y) - ((b - 1 / 2)^4 - (b - 1 / 2)^2 / 2 + 7 / 240) / 24
list(K1 = K1, K2 = K2)
}
cat_kernel = function(x, y)
{
x = as.matrix(x)
y = as.matrix(y)
n1 <- length(x)
n2 <- length(y)
x <- rep(x, times = n2)
y <- rep(y, each = n1)
L <- length(unique(c(x, y)))
K <- matrix(L * (x == y) - 1, n1, n2)
return(K)
}
kernelMatrix = function(x, y, type, kparam = 1.0) {
x = as.matrix(x)
y = as.matrix(y)
p = ncol(x)
if (ncol(x) == 0) {
x = matrix(0, nrow = nrow(x), ncol = 1)
}
if (ncol(y) == 0) {
y = matrix(0, nrow = nrow(y), ncol = 1)
}
if (type == "poly" | type == "poly2") {
K = (x %*% t(y) + 1.0)^kparam
}
if(type == "gaussian" | type == "gaussian2") {
normx = rowSums(x^2)
normy = rowSums(y^2)
temp = x %*% t(y)
temp = (-2.0 * temp) + outer(normx, rep(1.0, nrow(y)), "*") + outer(rep(1.0, nrow(x)), normy, "*")
K = exp(-temp * kparam)
# obj = kernelMatrix(rbfdot(sigma = kparam), x, y)
}
if (type == "spline" | type == "spline2") {
K = 0
for (d in 1:p) {
K_temp = spline_kernel(x[, d, drop = FALSE], y[, d, drop = FALSE])
K = K + K_temp$K1 + K_temp$K2
}
}
if (type == "linear" | type == "linear2") {
K = tcrossprod(x, y)
}
return(K)
}
make_anovaKernel = function(x, y, type, kparam, scale)
{
# if (length(unique(c(A, B))) <= 6)
#   K_temp <- cat_kernel(A, B)
# else K_temp <- spline_kernel(A, B)
x = as.matrix(x)
y = as.matrix(y)
dimx = ncol(x)
# calculate anova kernels for two-way interactions
if (type == "spline") {
numK = dimx
anova_kernel = vector(mode = "list", numK)
kernelCoord = vector(mode = "list", numK)
index = 0
for (d in 1:dimx) {
index = index + 1
A = x[, d, drop = FALSE]
B = y[, d, drop = FALSE]
if (length(unique(c(A, B))) <= 6){
K_temp <- cat_kernel(A, B)
anova_kernel[[index]] = K_temp
} else{
K_temp = spline_kernel(A, B)
anova_kernel[[index]] = (K_temp$K1 + K_temp$K2)
}
kernelCoord[[index]] = paste("x", d, sep = "")
}
} else if (type == 'spline2') {
numK = dimx + dimx * (dimx - 1) / 2
anova_kernel = vector(mode = "list", numK)
kernelCoord = vector(mode = "list", numK)
index = 0
for (d in 1:dimx) {
index = index + 1
A = x[, d, drop = FALSE]
B = y[, d, drop = FALSE]
if (length(unique(c(A, B))) <= 6){
K_temp <- cat_kernel(A, B)
anova_kernel[[index]] = K_temp
} else{
K_temp = spline_kernel(A, B)
anova_kernel[[index]] = (K_temp$K1 + K_temp$K2)
}
kernelCoord[[index]] = paste("x", d, sep = "")
}
for (i in 1:(dimx - 1)) {
for (j in (i + 1):dimx) {
index = index + 1
A = anova_kernel[[i]]
B = anova_kernel[[j]]
anova_kernel[[index]] = A * B
kernelCoord[[index]] = paste("x", i, " x", j, sep = "")
}
}
} else if (type == "gaussian2") {
numK = dimx + dimx * (dimx - 1) / 2
anova_kernel = vector(mode = "list", numK)
kernelCoord = vector(mode = "list", numK)
index = 0
for (d in 1:dimx) {
index = index + 1
A = x[, d, drop = FALSE]
B = y[, d, drop = FALSE]
if (length(unique(c(A, B))) <= 6){
K_temp <- cat_kernel(A, B)
anova_kernel[[index]] = K_temp
} else{
anova_kernel[[index]] = kernelMatrix(A, B, type, kparam)
}
kernelCoord[[index]] = paste("x", d, sep = "")
}
for (i in 1:(dimx - 1)) {
for (j in (i + 1):dimx) {
index = index + 1
A = anova_kernel[[i]]
B = anova_kernel[[j]]
anova_kernel[[index]] = A * B
kernelCoord[[index]] = paste("x", i, " x", j, sep = "")
}
}
} else { # calculate anova kernels for main effects
numK = dimx
anova_kernel = vector(mode = "list", numK)
kernelCoord = vector(mode = "list", numK)
for (d in 1:dimx) {
A = x[, d, drop = FALSE]
B = y[, d, drop = FALSE]
if (length(unique(c(A, B))) <= 6){
K_temp <- cat_kernel(A, B)
anova_kernel[[d]] = K_temp
} else{
anova_kernel[[d]] = kernelMatrix(A, B, type, kparam)
}
kernelCoord[[d]] = paste("x", d, sep = "")
}
}
return(list(x = x, K = anova_kernel, coord = kernelCoord, numK = numK, kernel = type, kparam = kparam))
}
rescale = function (x)
{
if (length(unique(x)) > 6)
return((x - min(x))/(max(x) - min(x)))
else return(x)
}
combine_kernel = function (Gramat, mscale)
{
n1 <- dim(Gramat)[1]
n2 <- dim(Gramat)[2]
d <- dim(Gramat)[3]
KK <- matrix(0, n1, n2)
for (j in 1:d) KK = KK + mscale[j] * Gramat[, , j]
return(KK)
}
rescale_theta = function (x)
{
d = length(x)
if(sum(x == 0) == d) x = rep(1e-10, d)
return(x)
}
cvsplitID = function (n, folds, y, family)
{
fsize <- floor(n/folds)
splits <- fsize * rep(1, folds)
nextra <- n - folds * fsize
if (nextra > 0) {
splits[1:nextra] <- splits[1:nextra] + 1
}
if(family != "binomial"){
randid <- sample(1:n, n)
IDmat <- matrix(NA, ncol = folds, nrow = ceiling(n/folds))
IDmat[, 1] <- randid[1:splits[1]]
for (i in 2:folds) {
tempid <- randid[(cumsum(splits)[i - 1] + 1):(cumsum(splits)[i])]
length(tempid) <- ceiling(n/folds)
IDmat[, i] <- tempid
}
}
if(family == "binomial"){
if(is.null(y)) stop("The input of y is essential.")
# Separate indices for 0s and 1s
idx_0 <- which(y == 0)
idx_1 <- which(y == 1)
n0 <- length(idx_0)
n1 <- length(idx_1)
# Compute fold sizes for each class
fsize_0 <- floor(n0 / folds)
fsize_1 <- floor(n1 / folds)
splits_0 <- fsize_0 * rep(1, folds)
splits_1 <- fsize_1 * rep(1, folds)
nextra_0 <- n0 - folds * fsize_0
nextra_1 <- n1 - folds * fsize_1
if (nextra_0 > 0) splits_0[1:nextra_0] <- splits_0[1:nextra_0] + 1
if (nextra_1 > 0) splits_1[1:nextra_1] <- splits_1[1:nextra_1] + 1
randid_0 <- sample(idx_0, n0)
randid_1 <- sample(idx_1, n1)
IDmat <- matrix(NA, ncol = folds, nrow = ceiling(n / folds))
# Assign 0s and 1s to folds
for (i in 1:folds) {
if(i == 1){
tempid_0 <- randid_0[1:(cumsum(splits_0)[i])]
tempid_1 <- randid_1[1:(cumsum(splits_1)[i])]
} else{
tempid_0 <- randid_0[(cumsum(splits_0)[i - 1] + 1):(cumsum(splits_0)[i])]
tempid_1 <- randid_1[(cumsum(splits_1)[i - 1] + 1):(cumsum(splits_1)[i])]
}
tempid <- c(tempid_0, tempid_1)
length(tempid) <- ceiling(n / folds)
IDmat[, i] <- tempid
}
}
return(IDmat)
}
KL = function(f, obj){
if(obj$family == "gaussian") B = f^2/2
if(obj$family == "binomial") B = log(1 + exp(f))
if(obj$family == "poisson") B = exp(f)
return(mean(-(obj$linkinv(f) * f) + B))
}
en3_pred = predict.cdcosso(fit3, te_x)
mean(te_y != ifelse(en3_pred$mu.new < 0.5, 0, 1))
en3_pred
plot(en3_pred)
plot(en3_pred$mu.new)
fit10 = try(cdcosso(tr_x, tr_y, family = 'binomial', gamma = 0.95, kernel = "spline", scale = F, algo = "CD"), silent = TRUE)
fit10
tr = data_generation(n, p, SNR = 15, response = "classification")
tr_x = tr$x
tr_y = tr$y
# table(tr_y)
te = data_generation(te_n, p, SNR = 15, response = "classification")
te_x = te$x
te_y = te$y
t1 = system.time({
fit3 = try(cdcosso(tr_x, tr_y, family = 'binomial', gamma = 1, kernel = "spline", scale = F, algo = "CD"), silent = TRUE)
})[3]  # lambda2를 크게 할수록  sparse, gamma를 크게 할수록 sparse
fit3
# for(nb in c(12, 25, 50, 100)){
iter = 10
ll = ll + 1
en3_signal_varsel = en1_signal_varsel = matrix(0, iter, p_sig)
time3 = time10 = c()
en3_varsel = en1_varsel = c()
en3_tp = en3_fp = en1_tp = en1_fp = en3_f1 = en1_f1 = en3_rec = en1_rec = en3_pre = en1_pre = c()
en3_miss = en1_miss = c()
en3_time = en1_time = c()
# cat("----------------- \n")
for(i in 1:iter){
# cat("\n iteration :", i, "\n")
set.seed(i)
tr = data_generation(n, p, SNR = 15, response = "classification")
tr_x = tr$x
tr_y = tr$y
# table(tr_y)
te = data_generation(te_n, p, SNR = 15, response = "classification")
te_x = te$x
te_y = te$y
t1 = system.time({
fit3 = try(cdcosso(tr_x, tr_y, family = 'binomial', gamma = 1, kernel = "spline", scale = F, algo = "CD"), silent = TRUE)
})[3]  # lambda2를 크게 할수록  sparse, gamma를 크게 할수록 sparse
if(!(class(fit3) == 'try-error')){
d = length(fit3$theta_step$theta.new)
# true_var = c(rep(1, p_sig2, rep(0, d-p_sig2)))
true_var = c(rep(1, p_sig), rep(0, p-p_sig))
en3_signal_varsel[i, ] = ifelse(fit3$theta_step$theta.new[1:p_sig] > 0, 1, 0)
en3_true = ifelse(fit3$theta_step$theta.new > 0, 1, 0)
en3_varsel[i] = sum(en3_true)
en3_tp[i] = metric(true_var, en3_true)$tp
en3_fp[i] = metric(true_var, en3_true)$fp
en3_pre[i] = metric(true_var, en3_true)$precision
en3_rec[i] = metric(true_var, en3_true)$recall
en3_f1[i] = metric(true_var, en3_true)$f1_score
en3_pred = predict.cdcosso(fit3, te_x)
en3_miss[i] = mean(te_y != ifelse(en3_pred$mu.new < 0.5, 0, 1))
# en3_miss[i] = mean((te_y - en3_pred$f.new)^2)
# en3_miss[i] = mean(-poisson()$dev.resids(te_y, en3_pred$mu.new, rep(1, te_n)))
en3_time[i] = mean(t1)
# plot(en3_pred$mu.new)
}
t2 = system.time({
fit10 = try(cdcosso(tr_x, tr_y, family = 'binomial', gamma = 0.95, kernel = "spline", scale = F, algo = "CD"), silent = TRUE)
})[3]  # lambda2를 크게 할수록  sparse, gamma를 크게 할수록 sparse
if(!(class(fit10) == 'try-error')){
d = length(fit10$theta_step$theta.new)
true_var = c(rep(1, p_sig), rep(0, p-p_sig))
en1_signal_varsel[i, ] = ifelse(fit10$theta_step$theta.new[1:p_sig] > 0, 1, 0)
en1_true = ifelse(fit10$theta_step$theta.new > 0, 1, 0)
en1_varsel[i] = sum(en1_true)
en1_tp[i] = metric(true_var, en1_true)$tp
en1_fp[i] = metric(true_var, en1_true)$fp
en1_pre[i] = metric(true_var, en1_true)$precision
en1_rec[i] = metric(true_var, en1_true)$recall
en1_f1[i] = metric(true_var, en1_true)$f1_score
en1_pred = predict.cdcosso(fit10, te_x)
en1_miss[i] = mean(te_y != ifelse(en1_pred$mu.new < 0.5, 0, 1))
# en1_miss[i] = mean((te_y - en1_pred$f.new)^2)
# en1_miss[i] = mean(-poisson()$dev.resids(te_y, en1_pred$mu.new, rep(1, te_n)))
en1_time[i] = mean(t2)
}
}
fit10
mean(en1_f1)
en1_f1
en3_f1
en1_miss
remove.packages("cdcosso")
devtools::install_github("jiieunshin/cdcosso")
library(cdcosso)
library(tmvtnorm)
library(glmnet)
library(cosso)
library(MASS)
n = 100
te_n = 1000
p_sig = 5
p = 100
out = matrix(0, 24, 14)
colnames(out) = c("n", "p", "gamma", "tp", "tp_se", "fp", "fp_se", "f1", "f1_se", "test", "miss", "miss_se", "time", "time_se")
out = data.frame(out)
i=1
ll = 0
# for(nb in c(12, 25, 50, 100)){
iter = 10
ll = ll + 1
en3_signal_varsel = en1_signal_varsel = matrix(0, iter, p_sig)
time3 = time10 = c()
en3_varsel = en1_varsel = c()
en3_tp = en3_fp = en1_tp = en1_fp = en3_f1 = en1_f1 = en3_rec = en1_rec = en3_pre = en1_pre = c()
en3_miss = en1_miss = c()
en3_time = en1_time = c()
# cat("\n iteration :", i, "\n")
set.seed(i)
tr = data_generation(n, p, SNR = 15, response = "classification")
tr_x = tr$x
tr_y = tr$y
# table(tr_y)
te = data_generation(te_n, p, SNR = 15, response = "classification")
te_x = te$x
te_y = te$y
t1 = system.time({
fit3 = try(cdcosso(tr_x, tr_y, family = 'binomial', gamma = 1, kernel = "spline", scale = F, algo = "CD"), silent = TRUE)
})[3]  # lambda2를 크게 할수록  sparse, gamma를 크게 할수록 sparse
fit3
tr = data_generation(n, p, SNR = 8, response = "classification")
tr_x = tr$x
tr_y = tr$y
# table(tr_y)
te = data_generation(te_n, p, SNR = 8, response = "classification")
te_x = te$x
te_y = te$y
t1 = system.time({
fit3 = try(cdcosso(tr_x, tr_y, family = 'binomial', gamma = 1, kernel = "spline", scale = F, algo = "CD"), silent = TRUE)
})[3]  # lambda2를 크게 할수록  sparse, gamma를 크게 할수록 sparse
fit3
