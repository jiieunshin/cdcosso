if(algo == "CD"){
# theta.new = nng.cd(Gw, uw, theta = init.theta, optlambda, gamma)
theta.new = .Call("Cnng", Gw, uw, n, d, init.theta, optlambda, gamma)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
if(algo == "QP"){
theta.new = nng.QP(model$zw.new, model$b.new, model$cw.new, model$w.new, G,
init.theta, lambda0, optlambda, gamma, obj)
f.new = c(G %*% as.matrix(theta.new))
out = list(cv_error = measure, optlambda_theta = optlambda, gamma = gamma, theta.new = theta.new, f.new = f.new)
}
return(out)
}
# zw = model$zw.new[trainID]
# b = model$b.new
# sw = model$sw.new[trainID]
# cw = model$cw.new[trainID]
# w = model$w.new[trainID]
# G = tr_G
# y = y[trainID]
nng.cd = function (Gw, uw, theta, lambda_theta, gamma)
{
n = nrow(Gw)
d = ncol(Gw)
r = lambda_theta * gamma * n
theta.new = rep(0, d)
for(i in 1:20){
for(j in 1:d){
theta.new[j] = 2 * sum((uw - Gw[,-j] %*% theta[-j]) * Gw[,j])
theta.new[j] = ifelse(theta.new[j] > 0 & r < abs(theta.new[j]), theta.new[j], 0)
theta.new[j] = theta.new[j] / sum(Gw[,j]^2)
loss = abs(theta[j] - theta.new[j])
conv = max(loss) < 1e-6
if(i != 1 & conv) break
theta = theta.new
}
}
if(i == 1 & !conv){
theta = rep(0, d)
}
# else if(sum(theta.new = 0) == d){
#   theta = theta.new / sd(theta.new)
# }
# print(theta)
# if(sum(theta == 0) != d) theta = theta / sd(theta)
return(theta)
}
nng.QP = function (zw, b, cw, w, G, theta, lambda0, lambda_theta, gamma, obj)
{
n = nrow(G)
d = ncol(G)
Gw = G * sqrt(w)
uw = zw - b * sqrt(w) - (n/2) * lambda0 * cw
# print(algo)
Amat = diag(1, d)
bvec = rep(0, d)
for(i in 1:20){
Dmat = 2 * (t(Gw) %*% Gw  + diag(lambda_theta * (1-gamma), d))
dvec = c(2 * t(uw) %*% Gw - gamma * lambda_theta)
# dvec = ifelse(dvec > 0 & abs(dvec) > lambda_theta * gamma, dvec, 0)
# theta.new = c(ginv(Dmat) %*% dvec)
theta.new <- solve.QP(Dmat, dvec, t(Amat), bvec)$solution
theta.new[theta.new < 1e-10] <- 0
if(sum(theta.new == 0) < d) theta.new = theta.new / sd(theta.new)
loss = abs(theta-theta.new)
conv = max(loss) < 1e-10
if(conv) break
theta = theta.new
}
return(theta.new)
}
######################
# object = fit3
# testx = te_x
KLD = function(f, y, family = "binomial"){
if(family == 'poisson') D = function(f, y) exp(f) - y*f
if(family == 'binomial') D = function(f, y) log(exp(1-f)+1) - y*f
if(family == 'Cox') D = function(f, y) log(exp(1-f)+1) - y*f
return(D(f, y))
}
predict.cdcosso = function(object, testx)
{
testx = apply(testx, 2, rescale)
K = make_anovaKernel(testx, object$data$x, object$data$kernel, object$data$kparam)
tr_n = dim(object$data$x)[1]
te_n <- dim(testx)[1]
d = K$numK
R = array(NA, c(te_n, tr_n, d))
for(j in 1:d){
R[, , j] = K$K[[j]]
}
wt = rep(1, d)
Rtheta <- wsGram(R, object$theta_step$theta.new/wt^2)
# if(object$algorithm == "QP"){
#   sdx <- sqrt(drop(rep(1, te_n) %*% (Rtheta^2))/(tr_n - 1))
#   c.new = object$c_step$c.new / sdx
# } else if(object$algorithm == "CD"){
# }
c.new = object$c_step$c.new
f.new = c(Rtheta %*% c.new + object$c_step$b.new)
mu.new = object$object$linkinv(f.new)
return(list(f.new = f.new, mu.new = mu.new))
}
make_kernel = function (x, y, type)
{
n1 <- nrow(x)
n2 <- nrow(y)
d <- ncol(x)
K <- array(0, c(n1, n2, d))
for (j in 1:d) {
K[, , j] <- kernelMatrix(x, y, type)
}
return(K)
}
spline_kernel = function(x, y)
{
x = as.matrix(x)
y = as.matrix(y)
K1x = (x - 1 / 2)
K1y = (y - 1 / 2)
K2x = (K1x^2 - 1 / 12) / 2
K2y = (K1y^2 - 1 / 12) / 2
ax = x %x% matrix(1, 1, nrow(y))
ay = y %x% matrix(1, 1, nrow(x))
b = abs(ax - t(ay))
K1 = K1x %x% t(K1y)
K2 = K2x %x% t(K2y) - ((b - 1 / 2)^4 - (b - 1 / 2)^2 / 2 + 7 / 240) / 24
list(K1 = K1, K2 = K2)
}
kernelMatrix = function(x, y, type, kparam = 1.0) {
x = as.matrix(x)
y = as.matrix(y)
p = ncol(x)
if (ncol(x) == 0) {
x = matrix(0, nrow = nrow(x), ncol = 1)
}
if (ncol(y) == 0) {
y = matrix(0, nrow = nrow(y), ncol = 1)
}
if (type == "poly") {
K = (x %*% t(y) + 1.0)^kparam
}
if(type == "gaussian" | type == "gaussian2") {
normx = rowSums(x^2)
normy = rowSums(y^2)
temp = x %*% t(y)
temp = (-2.0 * temp) + outer(normx, rep(1.0, nrow(y)), "*") + outer(rep(1.0, nrow(x)), normy, "*")
K = exp(-temp * kparam)
# obj = kernelMatrix(rbfdot(sigma = kparam), x, y)
}
if (type == "spline") {
K = 0
for (d in 1:p) {
K_temp = spline_kernel(x[, d, drop = FALSE], y[, d, drop = FALSE])
K = K + K_temp$K1 + K_temp$K2
}
}
if (type == "linear") {
K = tcrossprod(x, y)
}
if (type == "anova_gaussian") {
K = 0
for (d in 1:p) {
A = x[, d, drop = FALSE]
B = y[, d, drop = FALSE]
K_temp = kernelMatrix(A, B, type = "gaussian", kparam = kparam)
K = K + K_temp
}
}
return(K)
}
make_anovaKernel = function(x, y, type, kparam)
{
x = as.matrix(x)
y = as.matrix(y)
dimx = ncol(x)
# calculate anova kernels for main effects
if (type == "spline") {
# assign the number of anova kernels
numK = 2 * dimx
# list of kernel matrices
anova_kernel = vector(mode = "list", numK)
# list of kernel coordinate indices
kernelCoord = vector(mode = "list", numK)
index = 0
for (d in 1:dimx) {
index = index + 1
A = x[, d, drop = FALSE]
B = y[, d, drop = FALSE]
K_temp = spline_kernel(A, B)
anova_kernel[[index]] = K_temp$K1
kernelCoord[[index]] = paste("x", d, " linear", sep="")
index = index + 1
anova_kernel[[index]] = K_temp$K2
kernelCoord[[index]] = paste("x", d, " smooth", sep="")
}
} else if (type == 'spline2') {
numK = (2 * dimx) + (2 * dimx * (2 * dimx - 1) / 2 - dimx)
anova_kernel = vector(mode = "list", numK)
kernelCoord = vector(mode = "list", numK)
index = 0
# main effects
for (d in 1:dimx) {
index = index + 1
A = x[, d, drop = FALSE]
B = y[, d, drop = FALSE]
K_temp = spline_kernel(A, B)
anova_kernel[[index]] = K_temp$K1
kernelCoord[[index]] = paste("x", d, " linear", sep = "")
index = index + 1
anova_kernel[[index]] = K_temp$K2
kernelCoord[[index]] = paste("x", d, " smooth", sep = "")
}
# two-way interactions
for (i in 1:(dimx - 1)) {
for (j in (i + 1):dimx) {
index = index + 1
A_linear = as.matrix(anova_kernel[[2 * i - 1]])
A_smooth = as.matrix(anova_kernel[[2 * i]])
B_linear = as.matrix(anova_kernel[[2 * j - 1]])
B_smooth = as.matrix(anova_kernel[[2 * j]])
anova_kernel[[index]] = A_linear * B_linear
kernelCoord[[index]] = paste("x", i, " linear,", " x", j, " linear", sep = "")
index = index + 1
anova_kernel[[index]] = A_linear * B_smooth
kernelCoord[[index]] = paste("x", i, " linear,", " x", j, " smooth", sep = "")
index = index + 1
anova_kernel[[index]] = A_smooth * B_linear
kernelCoord[[index]] = paste("x", i, " smooth,", " x", j, " linear", sep = "")
index = index + 1
anova_kernel[[index]] = A_smooth * B_smooth
kernelCoord[[index]] = paste("x", i, " smooth,", " x", j, " smooth", sep = "")
}
}
} else if (type == "spline-t") {
numK = dimx
anova_kernel = vector(mode = "list", numK)
kernelCoord = vector(mode = "list", numK)
index = 0
for (d in 1:dimx) {
index = index + 1
A = x[, d, drop = FALSE]
B = y[, d, drop = FALSE]
K_temp = spline_kernel(A, B)
anova_kernel[[index]] = (K_temp$K1 + K_temp$K2)
kernelCoord[[index]] = paste("x", d, sep = "")
}
} else if (type == 'spline-t2') {
numK = dimx + dimx * (dimx - 1) / 2
anova_kernel = vector(mode = "list", numK)
kernelCoord = vector(mode = "list", numK)
index = 0
for (d in 1:dimx) {
index = index + 1
A = x[, d, drop = FALSE]
B = y[, d, drop = FALSE]
K_temp = spline_kernel(A, B)
anova_kernel[[index]] = (K_temp$K1 + K_temp$K2)
kernelCoord[[index]] = paste("x", d, sep = "")
}
for (i in 1:(dimx - 1)) {
for (j in (i + 1):dimx) {
index = index + 1
A = anova_kernel[[i]]
B = anova_kernel[[j]]
anova_kernel[[index]] = A * B
kernelCoord[[index]] = paste("x", i, " x", j, sep = "")
}
}
} else if (type == "gaussian2") {
numK = dimx + dimx * (dimx - 1) / 2
anova_kernel = vector(mode = "list", numK)
kernelCoord = vector(mode = "list", numK)
index = 0
for (d in 1:dimx) {
index = index + 1
A = x[, d, drop = FALSE]
B = y[, d, drop = FALSE]
anova_kernel[[index]] = kernelMatrix(A, B, type, kparam)
kernelCoord[[index]] = paste("x", d, sep = "")
}
for (i in 1:(dimx - 1)) {
for (j in (i + 1):dimx) {
index = index + 1
A = anova_kernel[[i]]
B = anova_kernel[[j]]
anova_kernel[[index]] = A * B
kernelCoord[[index]] = paste("x", i, " x", j, sep = "")
}
}
} else {
numK = dimx
anova_kernel = vector(mode = "list", numK)
kernelCoord = vector(mode = "list", numK)
for (d in 1:dimx) {
A = x[, d, drop = FALSE]
B = y[, d, drop = FALSE]
anova_kernel[[d]] = kernelMatrix(A, B, type, kparam)
kernelCoord[[d]] = paste("x", d, sep = "")
}
}
return(list(x = x, K = anova_kernel, coord = kernelCoord, numK = numK, kernel = type, kparam = kparam))
}
# is used to combine anova kernel matrices with weights determined by theta values. The default theta vector is the vector of ones.
combine_kernel = function(anova_kernel, theta = rep(1, anova_kernel$numK))
{
K = 0
for (d in 1:anova_kernel$numK) {
K = (K + theta[d] * anova_kernel$K[[d]])
}
return(K)
}
rescale = function (x)
{
if (length(unique(x)) > 6)
return((x - min(x))/(max(x) - min(x)))
else return(x)
}
wsGram = function (Gramat, mscale)
{
n1 <- dim(Gramat)[1]
n2 <- dim(Gramat)[2]
d <- dim(Gramat)[3]
KK <- matrix(0, n1, n2)
for (j in 1:d) KK = KK + mscale[j] * Gramat[, , j]
return(KK)
}
rescale = function (x)
{
if (length(unique(x)) > 6)
return((x - min(x))/(max(x) - min(x)))
else return(x)
}
cvsplitID = function (n, folds)
{
fsize <- floor(n/folds)
splits <- fsize * rep(1, folds)
nextra <- n - folds * fsize
if (nextra > 0) {
splits[1:nextra] <- splits[1:nextra] + 1
}
randid <- sample(1:n, n)
IDmat <- matrix(NA, ncol = folds, nrow = ceiling(n/folds))
IDmat[, 1] <- randid[1:splits[1]]
for (i in 2:folds) {
tempid <- randid[(cumsum(splits)[i - 1] + 1):(cumsum(splits)[i])]
length(tempid) <- ceiling(n/folds)
IDmat[, i] <- tempid
}
return(IDmat)
}
rescale_theta = function(theta, scale = FALSE){
d = length(theta)
if(sum(theta == 0) == d){
theta = rep(1e-10, d)
} else{
if(scale) theta = theta / sd(theta)
if(!scale) theta = theta
}
return(theta)
}
cdcosso.glm = function (x, y, wt, lambda0, lambda_theta, gamma, obj, nfolds, one.std, type, kparam, algo)
{
n = length(y)
d = length(wt)
par(mfrow = c(2,2))
# initiation
# init.theta = as.vector(glmnet(x, y, family = "binomial", lambda = lambda_theta[2], gamma = 0)$beta)
init.theta = rep(1, d)
# solve (theta) - 1st
sspline_cvfit = cv.sspline(x, y, init.theta/wt^2, nfolds, lambda0, obj, one.std, type, kparam, algo) ## 초기값 설정. 수정할 함수
optlambda0 = sspline_cvfit$optlambda
# solve (b, c) - 1st
nng_fit = cv.nng(sspline_cvfit, x, y, wt, init.theta, optlambda0, lambda_theta, gamma, nfolds, obj, one.std, algo)
theta.new = rescale_theta(nng_fit$theta.new, FALSE)
print(nng_fit$theta.new)
# solve (theta) - 2nd
sspline_cvfit = cv.sspline(x, y, theta.new/wt^2, nfolds, lambda0, obj, one.std, type, kparam, algo) ## 초기값 설정. 수정할 함수
nng_fit = cv.nng(sspline_cvfit, x, y, wt, init.theta, sspline_cvfit$optlambda, lambda_theta, gamma, nfolds, obj, one.std, algo)
theta.new = rescale_theta(nng_fit$theta.new, FALSE)
print(nng_fit$theta.new)
par(mfrow = c(1,1))
if(algo == "CD")
out = list(data = list(x = x, y = y, R = sspline_cvfit$R, kernel = type, kparam = kparam),
tune = list(lambda0 = lambda0, lambda_theta = lambda_theta, gamma = gamma),
c_step = sspline_cvfit,
theta_step = nng_fit,
object = obj,
algorithm = algo)
if(algo == "QP")
out = list(data = list(x = x, y = y, R = sspline_cvfit$R, kernel = type, kparam = kparam),
tune = list(lambda0 = lambda0, lambda_theta = lambda_theta, gamma = gamma),
c_step = sspline_cvfit,
theta_step = nng_fit,
object = obj,
algorithm = algo)
class(out) = "cosso"
return(out)
}
# x = tr_x
# y = tr_y
# family = 'binomial'
# gamma = 0.8
# kernel = "gaussian"
# one.std = TRUE
# scale = T
# wt = rep(1, ncol(x))
# kparam = 1
# nfolds =5
cdcosso = function (x, y, family = c("gaussian", "binomial", "poisson", "negbin", "svm", "Cox"),
kernel = c("linear", "gaussian", "poly", "spline", "anova_gaussian", "gaussian2"),
algo = c("CD", "QP"), wt = rep(1, ncol(x)),
kparam = 1, lambda0, lambda_theta, M, gamma = 0.3, nfolds = 5, one.std = TRUE, scale = TRUE, cpus)
{
n = nrow(x)
colnames(x) = NULL
rownames(x) = NULL
if(class(x)[1] == "data.frame")
x = as.matrix(x)
# family
family = match.arg(family)
if(family == "gaussian")
obj = gaussian()
if(family == "binomial")
obj =  binomial()
if(family == "poisson")
obj = poisson()
if(family == "negbin"){
link = poisson()$linkfun
# if(missing(init.disp)){
#   init.distp = NA
# }
obj = list(disp = NA, link = link)
}
if(missing(kernel))
type = 'gaussian'
else
type = match.arg(kernel)
if(missing(algo))
algo = "CD"
if(missing(lambda0)){
lambda0 = exp(seq(log(2^{-40}), log(2^{10}), length.out = 40))
}
if(missing(lambda_theta))
lambda_theta = exp(seq(log(2^{-40}), log(2^{4}), length.out = 40))
if (scale){   # min-max scale
x = apply(x, 2, rescale)
}
if (family == "Cox" & !all(match(c("time", "status"), dimnames(y)[[2]], 0))) {
stop("Cox model requires a matrix with columns 'time' and 'status' as a response")
}
objnm = ifelse(family == 'gaussian' | family == 'binomial' | family == 'poisson', 'glm', family)
# fitting
out = switch(objnm,
glm = cdcosso.glm(x, y, wt, lambda0, lambda_theta, gamma, obj, nfolds, one.std, type, kparam, algo)
# Cox = cdcosso.cox(x, y[, "time"], y[, "status"], lambda0, lambda_theta, gamma)
# Negbin, svm 추가
)
return(out)
}
### 실행 #######################################
i=1
iter = 10
time3 = time10 = c()
en3_varsel = en1_varsel = c()
en3_f1 = en1_f1 = en3_rec = en1_rec = en3_pre = en1_pre = c()
en3_miss = en1_miss = c()
en3_time = en1_time = c()
# cat("----------------- \n")
for(i in 1:iter){
cat("\n iteration :", i, "\n")
set.seed(i)
split_id = train_test_split(y, 0.3)
tr_x = X[split_id$train_id,]
tr_y = y[split_id$train_id]
te_x = X[split_id$test_id,]
te_y = y[split_id$test_id]
# t1 = system.time({
#   fit3 = try(cdcosso(tr_x, tr_y, family = 'binomial', gamma = 0.8, kernel = "gaussian", one.std = FALSE, scale = T, algo = "QP"), silent = TRUE)
# })  # lambda2를 크게 할수록  sparse, gamma를 크게 할수록 sparse
t2 = system.time({
fit10 = try(cdcosso(tr_x, tr_y, family = 'binomial', gamma = 0.8, kernel = "gaussian", scale = T, one.std = FALSE, algo = "CD"), silent = TRUE)
})  # lambda2를 크게 할수록  sparse, gamma를 크게 할수록 sparse
# if(!(class(fit3) == 'try-error')){
#   time3[i] = t1[3]
#   en3_varsel[i] = sum(ifelse(fit3$theta_step$theta.new > 0, 1, 0))
#   en3_pred = predict.cdcosso(fit3, te_x)
#   en3_miss[i] = mean(te_y != ifelse(en3_pred$mu.new <= 0.5, 0, 1))
# }
if(!(class(fit10) == 'try-error')){
time10[i] = t2[3]
en1_varsel[i] = sum(ifelse(fit10$theta_step$theta.new > 0, 1, 0))
en1_pred = predict.cdcosso(fit10, te_x)
en1_miss[i] = mean(te_y != ifelse(en1_pred$mu.new <= 0.5, 0, 1))
}
# if(i == iter){
print(Sys.time())
cat("\n n :", nrow(tr_x), ", p = ", ncol(tr_x), "-------------------------- \n")
cat("\n iteration :", i, "\n")
cat('(gamma=0.7) \n')
cat("length :", sum(!is.na(en3_miss)), "\n")
cat('sel_Var:', round(mean(en3_varsel, na.rm = TRUE), 4), "(", round(sd(en3_varsel, na.rm = TRUE)/sqrt(sum(!is.na(en3_varsel))), 4), ")", "\n")
cat('miss   :', round(mean(en3_miss, na.rm = TRUE), 4), "(", round(sd(en3_miss, na.rm = TRUE)/sqrt(sum(!is.na(en3_miss))), 4), ")", "\n")
cat('time   :', round(mean(time3, na.rm = TRUE), 4), "(", round(sd(time3, na.rm = TRUE)/sqrt(sum(!is.na(time3))), 4), ")", "\n")
cat('(gamma=1) \n')
cat("length :", sum(!is.na(en1_miss)), "\n")
cat('sel_Var:', round(mean(en1_varsel, na.rm = TRUE), 4), "(", round(sd(en1_varsel, na.rm = TRUE)/sqrt(sum(!is.na(en1_varsel))), 4), ")", "\n")
cat('miss   :', round(mean(en1_miss, na.rm = TRUE), 4), "(", round(sd(en1_miss, na.rm = TRUE)/sqrt(sum(!is.na(en1_miss))), 4), ")", "\n")
cat('time   :', round(mean(time10, na.rm = TRUE), 4), "(", round(sd(time10, na.rm = TRUE)/sqrt(sum(!is.na(time10))), 4), ")", "\n")
# }
}
